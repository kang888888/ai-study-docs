// ä¸ºæ–°åˆ›å»ºçš„æ–‡æ¡£æ·»åŠ æ¶æ„å›¾è§£å’Œä»£ç ç¤ºä¾‹
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const knowledgeDir = path.join(__dirname, '../src/data/knowledge');

// éœ€è¦å¢å¼ºçš„æ–‡æ¡£é…ç½®
const enhancements = [
  {
    file: 'DiT.json',
    diagram: {
      type: 'architecture',
      title: 'DiTæ¶æ„',
      caption: 'DiTæ¶æ„å›¾'
    },
    code: {
      title: 'DiTæ¨¡å‹ä½¿ç”¨',
      language: 'python',
      code: `from diffusers import DiffusionPipeline
import torch

# åŠ è½½DiTæ¨¡å‹
pipe = DiffusionPipeline.from_pretrained("facebook/dit-base")

# ç”Ÿæˆè§†é¢‘
prompt = "A beautiful sunset over the ocean"
video = pipe(prompt, num_inference_steps=50).images[0]`
    }
  },
  {
    file: 'æ•°æ®å¹¶è¡Œ.json',
    diagram: {
      type: 'architecture',
      title: 'æ•°æ®å¹¶è¡ŒåŸç†',
      caption: 'æ•°æ®å¹¶è¡ŒåŸç†'
    },
    code: {
      title: 'PyTorchæ•°æ®å¹¶è¡Œ',
      language: 'python',
      code: `import torch
import torch.nn as nn
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

# åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
dist.init_process_group(backend='nccl')

# åˆ›å»ºæ¨¡å‹
model = nn.Linear(10, 1)
model = model.cuda()
model = DDP(model)

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    for batch in dataloader:
        outputs = model(batch)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()`
    }
  },
  {
    file: 'æ¨¡å‹å¹¶è¡Œ.json',
    diagram: {
      type: 'architecture',
      title: 'æ¨¡å‹å¹¶è¡ŒåŸç†',
      caption: 'æ¨¡å‹å¹¶è¡ŒåŸç†'
    },
    code: {
      title: 'æ¨¡å‹å¹¶è¡Œç¤ºä¾‹',
      language: 'python',
      code: `import torch
import torch.nn as nn
from torch.nn.parallel import parallel_apply

# å°†æ¨¡å‹æ‹†åˆ†åˆ°å¤šä¸ªGPU
device_ids = [0, 1]
model_part1 = nn.Sequential(...).to(device_ids[0])
model_part2 = nn.Sequential(...).to(device_ids[1])

# å‰å‘ä¼ æ’­
def forward(input):
    intermediate = model_part1(input)
    output = model_part2(intermediate)
    return output`
    }
  },
  {
    file: 'æµæ°´çº¿å¹¶è¡Œ.json',
    diagram: {
      type: 'flow',
      title: 'æµæ°´çº¿å¹¶è¡Œæµç¨‹',
      caption: 'æµæ°´çº¿å¹¶è¡Œæµç¨‹'
    },
    code: {
      title: 'æµæ°´çº¿å¹¶è¡Œç¤ºä¾‹',
      language: 'python',
      code: `import torch
from torch.distributed.pipeline.sync import Pipe

# åˆ›å»ºæ¨¡å‹åˆ†æ®µ
model = nn.Sequential(
    nn.Linear(10, 20),
    nn.Linear(20, 30),
    nn.Linear(30, 1)
)

# åˆ›å»ºæµæ°´çº¿
model = Pipe(model, chunks=4)

# è®­ç»ƒ
output = model(input)`
    }
  },
  {
    file: 'å›¾ä¼˜åŒ–.json',
    diagram: {
      type: 'architecture',
      title: 'è®¡ç®—å›¾ä¼˜åŒ–',
      caption: 'è®¡ç®—å›¾ä¼˜åŒ–'
    },
    code: {
      title: 'TensorRTå›¾ä¼˜åŒ–',
      language: 'python',
      code: `import tensorrt as trt

# åˆ›å»ºTensorRTå¼•æ“
builder = trt.Builder(logger)
network = builder.create_network()
parser = trt.OnnxParser(network, logger)

# è§£æONNXæ¨¡å‹
parser.parse_from_file("model.onnx")

# æ„å»ºä¼˜åŒ–å¼•æ“
builder.max_batch_size = 1
builder.max_workspace_size = 1 << 30
engine = builder.build_cuda_engine(network)`
    }
  },
  {
    file: 'é‡åŒ–æ¨ç†.json',
    diagram: {
      type: 'comparison',
      title: 'é‡åŒ–å¯¹æ¯”',
      caption: 'é‡åŒ–å¯¹æ¯”'
    },
    code: {
      title: 'INT8é‡åŒ–æ¨ç†',
      language: 'python',
      code: `import torch
from torch.quantization import quantize_dynamic

# åŠ è½½æ¨¡å‹
model = torch.load("model.pth")

# åŠ¨æ€é‡åŒ–
quantized_model = quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# æ¨ç†
with torch.no_grad():
    output = quantized_model(input)`
    }
  },
  {
    file: 'æ¨¡å‹å‰ªæ.json',
    diagram: {
      type: 'architecture',
      title: 'æ¨¡å‹å‰ªææµç¨‹',
      caption: 'æ¨¡å‹å‰ªææµç¨‹'
    },
    code: {
      title: 'æ¨¡å‹å‰ªæç¤ºä¾‹',
      language: 'python',
      code: `import torch
import torch.nn.utils.prune as prune

# åˆ›å»ºæ¨¡å‹
model = nn.Linear(10, 1)

# å‰ªæ
prune.l1_unstructured(model, name="weight", amount=0.2)

# æ°¸ä¹…ç§»é™¤å‰ªæ
prune.remove(model, "weight")`
    }
  },
  {
    file: 'æ™ºèƒ½ä½“æ¡†æ¶.json',
    diagram: {
      type: 'architecture',
      title: 'æ™ºèƒ½ä½“æ¡†æ¶æ¶æ„',
      caption: 'æ™ºèƒ½ä½“æ¡†æ¶æ¶æ„'
    },
    code: {
      title: 'LangGraphç¤ºä¾‹',
      language: 'python',
      code: `from langgraph.graph import StateGraph, END

# å®šä¹‰çŠ¶æ€å›¾
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("agent", agent_node)
workflow.add_node("tools", tool_node)

# æ·»åŠ è¾¹
workflow.add_edge("agent", "tools")
workflow.add_edge("tools", END)

# ç¼–è¯‘å¹¶è¿è¡Œ
app = workflow.compile()
result = app.invoke({"messages": [("user", "Hello")]})`
    }
  },
  {
    file: 'å·¥å…·è°ƒç”¨.json',
    diagram: {
      type: 'flow',
      title: 'å·¥å…·è°ƒç”¨æµç¨‹',
      caption: 'å·¥å…·è°ƒç”¨æµç¨‹'
    },
    code: {
      title: 'Function Callingç¤ºä¾‹',
      language: 'python',
      code: `from openai import OpenAI

client = OpenAI()

# å®šä¹‰å·¥å…·
tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get weather information",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string"}
            }
        }
    }
}]

# è°ƒç”¨æ¨¡å‹
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "What's the weather in Beijing?"}],
    tools=tools
)`
    }
  },
  {
    file: 'å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ.json',
    diagram: {
      type: 'architecture',
      title: 'å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¶æ„',
      caption: 'å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¶æ„'
    },
    code: {
      title: 'å¤šæ™ºèƒ½ä½“åä½œç¤ºä¾‹',
      language: 'python',
      code: `from crewai import Agent, Task, Crew

# åˆ›å»ºæ™ºèƒ½ä½“
researcher = Agent(
    role='Researcher',
    goal='Research information',
    backstory='Expert researcher'
)

writer = Agent(
    role='Writer',
    goal='Write content',
    backstory='Expert writer'
)

# åˆ›å»ºä»»åŠ¡
task1 = Task(description='Research topic', agent=researcher)
task2 = Task(description='Write article', agent=writer)

# åˆ›å»ºå›¢é˜Ÿ
crew = Crew(agents=[researcher, writer], tasks=[task1, task2])
result = crew.kickoff()`
    }
  },
  {
    file: 'Transformers.json',
    diagram: {
      type: 'architecture',
      title: 'Transformersæ¡†æ¶',
      caption: 'Transformersæ¡†æ¶'
    },
    code: {
      title: 'ä½¿ç”¨Pipeline',
      language: 'python',
      code: `from transformers import pipeline

# åˆ›å»ºPipeline
classifier = pipeline("sentiment-analysis")

# ä½¿ç”¨Pipeline
result = classifier("I love this product!")
print(result)`
    }
  },
  {
    file: 'Accelerate.json',
    diagram: {
      type: 'architecture',
      title: 'Accelerateæ¶æ„',
      caption: 'Accelerateæ¶æ„'
    },
    code: {
      title: 'Accelerateä½¿ç”¨',
      language: 'python',
      code: `from accelerate import Accelerator

# åˆå§‹åŒ–Accelerator
accelerator = Accelerator()

# å‡†å¤‡æ¨¡å‹å’Œæ•°æ®
model, optimizer, dataloader = accelerator.prepare(
    model, optimizer, dataloader
)

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    for batch in dataloader:
        outputs = model(batch)
        loss = criterion(outputs, targets)
        accelerator.backward(loss)
        optimizer.step()`
    }
  },
  {
    file: 'æ€§èƒ½åˆ†æ.json',
    diagram: {
      type: 'architecture',
      title: 'æ€§èƒ½åˆ†ææµç¨‹',
      caption: 'æ€§èƒ½åˆ†ææµç¨‹'
    },
    code: {
      title: 'PyTorch Profiler',
      language: 'python',
      code: `import torch
from torch.profiler import profile, record_function, ProfilerActivity

# ä½¿ç”¨Profiler
with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    record_shapes=True
) as prof:
    with record_function("model_inference"):
        output = model(input)

# æŸ¥çœ‹ç»“æœ
print(prof.key_averages().table(sort_by="cuda_time_total"))`
    }
  },
  {
    file: 'Space-Time Latent Patch.json',
    diagram: {
      type: 'architecture',
      title: 'Space-Time Latent Patchæ¶æ„',
      caption: 'Space-Time Latent Patchæ¶æ„'
    },
    code: {
      title: 'è§†é¢‘ç¼–ç ç¤ºä¾‹',
      language: 'python',
      code: `import torch
import torch.nn as nn

# Space-Time Latent Patchç¼–ç 
class STLPEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.patch_embed = nn.Conv3d(3, 768, kernel_size=(2, 16, 16))
    
    def forward(self, video):
        # æå–æ—¶ç©ºè¡¥ä¸
        patches = self.patch_embed(video)
        return patches`
    }
  },
  {
    file: 'Whisper.json',
    diagram: {
      type: 'architecture',
      title: 'Whisperæ¶æ„',
      caption: 'Whisperæ¶æ„'
    },
    code: {
      title: 'Whisperä½¿ç”¨',
      language: 'python',
      code: `import whisper

# åŠ è½½æ¨¡å‹
model = whisper.load_model("base")

# è½¬å½•éŸ³é¢‘
result = model.transcribe("audio.mp3")
print(result["text"])`
    }
  },
  {
    file: 'AudioLM.json',
    diagram: {
      type: 'architecture',
      title: 'AudioLMæ¶æ„',
      caption: 'AudioLMæ¶æ„'
    },
    code: {
      title: 'AudioLMç”Ÿæˆ',
      language: 'python',
      code: `import torch
from audiolm import AudioLM

# åŠ è½½æ¨¡å‹
model = AudioLM.from_pretrained("google/audiolm")

# ç”ŸæˆéŸ³é¢‘
audio = model.generate(prompt="A piano melody", duration=5.0)`
    }
  },
  {
    file: 'GPT-4o Omni.json',
    diagram: {
      type: 'architecture',
      title: 'GPT-4o Omniæ¶æ„',
      caption: 'GPT-4o Omniæ¶æ„'
    },
    code: {
      title: 'å¤šæ¨¡æ€è°ƒç”¨',
      language: 'python',
      code: `from openai import OpenAI

client = OpenAI()

# å¤šæ¨¡æ€è°ƒç”¨
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "user", "content": [
            {"type": "text", "text": "What's in this image?"},
            {"type": "image_url", "image_url": {"url": "image.jpg"}}
        ]}
    ]
)`
    }
  },
  {
    file: 'æ ¼å¼è½¬æ¢.json',
    diagram: {
      type: 'flow',
      title: 'æ ¼å¼è½¬æ¢æµç¨‹',
      caption: 'æ ¼å¼è½¬æ¢æµç¨‹'
    },
    code: {
      title: 'æ ¼å¼è½¬æ¢ç¤ºä¾‹',
      language: 'python',
      code: `import json
import pandas as pd

# JSONLè½¬Parquet
def jsonl_to_parquet(jsonl_file, parquet_file):
    data = []
    with open(jsonl_file, 'r') as f:
        for line in f:
            data.append(json.loads(line))
    df = pd.DataFrame(data)
    df.to_parquet(parquet_file)`
    }
  },
  {
    file: 'è´¨é‡è¯„ä¼°.json',
    diagram: {
      type: 'architecture',
      title: 'è´¨é‡è¯„ä¼°æµç¨‹',
      caption: 'è´¨é‡è¯„ä¼°æµç¨‹'
    },
    code: {
      title: 'æ•°æ®è´¨é‡è¯„ä¼°',
      language: 'python',
      code: `from datasets import load_dataset
from evaluate import load

# åŠ è½½æ•°æ®é›†
dataset = load_dataset("dataset_name")

# è¯„ä¼°è´¨é‡
accuracy = evaluate_accuracy(dataset)
diversity = evaluate_diversity(dataset)
consistency = evaluate_consistency(dataset)`
    }
  },
  {
    file: 'æ•°æ®ç®¡ç†.json',
    diagram: {
      type: 'architecture',
      title: 'æ•°æ®ç®¡ç†æ¶æ„',
      caption: 'æ•°æ®ç®¡ç†æ¶æ„'
    },
    code: {
      title: 'æ•°æ®ç‰ˆæœ¬ç®¡ç†',
      language: 'python',
      code: `import dvc.api

# ä½¿ç”¨DVCç®¡ç†æ•°æ®ç‰ˆæœ¬
data = dvc.api.read(
    'data/dataset.csv',
    repo='https://github.com/user/repo',
    rev='v1.0'
)`
    }
  }
];

// å¤„ç†æ¯ä¸ªæ–‡æ¡£
enhancements.forEach(({ file, diagram, code }) => {
  const filePath = path.join(knowledgeDir, file);
  
  if (!fs.existsSync(filePath)) {
    console.log(`âŒ æ–‡ä»¶ä¸å­˜åœ¨: ${file}`);
    return;
  }
  
  try {
    const content = fs.readFileSync(filePath, 'utf-8');
    const doc = JSON.parse(content);
    
    let sections = doc.content || [];
    let hasChanges = false;
    
    // æ£€æŸ¥æ˜¯å¦å·²æœ‰æ¶æ„å›¾è§£
    const hasDiagram = sections.some(s => 
      s.title && s.title.includes('æ¶æ„å›¾è§£')
    );
    
    // æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»£ç ç¤ºä¾‹
    const hasCode = sections.some(s => 
      s.title && (s.title.includes('ä»£ç ç¤ºä¾‹') || s.title.includes('ğŸ’»'))
    );
    
    // æ‰¾åˆ°åº”ç”¨åœºæ™¯çš„ä½ç½®
    let appSceneIndex = sections.findIndex(s => 
      s.title && (s.title.includes('åº”ç”¨åœºæ™¯') || s.title.includes('ğŸš€ åº”ç”¨åœºæ™¯'))
    );
    
    // æ·»åŠ æ¶æ„å›¾è§£ï¼ˆåœ¨åº”ç”¨åœºæ™¯ä¹‹å‰ï¼‰
    if (!hasDiagram && diagram) {
      const diagramSection = {
        type: "section",
        title: "ğŸ“Š æ¶æ„å›¾è§£",
        content: [
          {
            type: "diagram-gallery",
            images: [
              {
                type: "svg-d3",
                component: "GenericDiagram",
                caption: diagram.caption,
                width: 1000,
                height: 800,
                interactive: true,
                props: {
                  type: diagram.type,
                  title: diagram.title
                }
              }
            ]
          }
        ]
      };
      
      if (appSceneIndex >= 0) {
        sections.splice(appSceneIndex, 0, diagramSection);
      } else {
        sections.push(diagramSection);
      }
      hasChanges = true;
    }
    
    // æ·»åŠ ä»£ç ç¤ºä¾‹ï¼ˆåœ¨æœ€åï¼‰
    if (!hasCode && code) {
      const codeSection = {
        type: "section",
        title: "ğŸ’» Python ä»£ç ç¤ºä¾‹",
        content: [
          {
            type: "code-box",
            title: code.title,
            language: code.language,
            code: code.code
          }
        ]
      };
      sections.push(codeSection);
      hasChanges = true;
    }
    
    // ä¿å­˜æ–‡ä»¶
    if (hasChanges) {
      doc.content = sections;
      const newContent = JSON.stringify(doc, null, 2);
      fs.writeFileSync(filePath, newContent, 'utf-8');
      console.log(`âœ… ${file}: å·²æ·»åŠ æ¶æ„å›¾è§£å’Œä»£ç ç¤ºä¾‹`);
    } else {
      console.log(`â­ï¸  ${file}: æ— éœ€ä¿®æ”¹`);
    }
    
  } catch (error) {
    console.error(`âŒ å¤„ç† ${file} æ—¶å‡ºé”™:`, error.message);
  }
});

console.log('\nâœ… æ‰¹é‡å¢å¼ºå®Œæˆï¼');
