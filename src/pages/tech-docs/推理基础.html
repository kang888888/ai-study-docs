<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>推理基础</title>
    <script>
        window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']] }, options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] } };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    <!-- 公共样式 -->
    <link rel="stylesheet" href="../common/styles.css">
</head>
<body>
    <div class="container">
        <h1>推理基础</h1>
        <p class="tagline">理解大语言模型推理的核心概念，掌握推理与训练的区别，了解关键性能指标。</p>

        <div class="meta-grid">
            <div class="meta-card"><h3>推理 vs 训练</h3><p>推理只需要前向传播，不需要反向传播和参数更新。</p></div>
            <div class="meta-card"><h3>关键指标</h3><p>延迟、吞吐量、内存占用。</p></div>
            <div class="meta-card"><h3>优化方向</h3><p>模型层面、计算层面、系统层面。</p></div>
            <div class="meta-card"><h3>推理框架</h3><p>vLLM、TensorRT-LLM、llama.cpp、FasterTransformer。</p></div>
        </div>

        <div class="section">
            <h2>📖 什么是推理？</h2>
            <p><strong>推理（Inference）</strong>是使用训练好的模型进行预测的过程。与训练不同，推理只需要前向传播，不需要反向传播和参数更新。</p>
            
            <table style="width:100%; border-collapse:collapse; margin-top:20px;">
                <tr style="border-bottom:1px solid rgba(255,255,255,0.1);">
                    <th style="padding:12px; text-align:left; color:#c7d2fe;">特性</th>
                    <th style="padding:12px; text-align:left; color:#c7d2fe;">训练</th>
                    <th style="padding:12px; text-align:left; color:#c7d2fe;">推理</th>
                </tr>
                <tr style="border-bottom:1px solid rgba(255,255,255,0.05);">
                    <td style="padding:12px;">目标</td>
                    <td style="padding:12px;">学习参数</td>
                    <td style="padding:12px;">使用模型预测</td>
                </tr>
                <tr style="border-bottom:1px solid rgba(255,255,255,0.05);">
                    <td style="padding:12px;">过程</td>
                    <td style="padding:12px;">前向+反向传播</td>
                    <td style="padding:12px;">仅前向传播</td>
                </tr>
                <tr style="border-bottom:1px solid rgba(255,255,255,0.05);">
                    <td style="padding:12px;">内存</td>
                    <td style="padding:12px;">需要存储梯度</td>
                    <td style="padding:12px;">不需要梯度</td>
                </tr>
                <tr style="border-bottom:1px solid rgba(255,255,255,0.05);">
                    <td style="padding:12px;">精度</td>
                    <td style="padding:12px;">通常FP32/BF16</td>
                    <td style="padding:12px;">可以INT8/INT4</td>
                </tr>
                <tr>
                    <td style="padding:12px;">关注点</td>
                    <td style="padding:12px;">收敛速度</td>
                    <td style="padding:12px;">延迟和吞吐量</td>
                </tr>
            </table>
        </div>

        <div class="section">
            <h2>🎯 推理的关键指标</h2>
            
            <h3 style="color:#c7d2fe; margin-top:20px;">1. 延迟（Latency）</h3>
            <ul>
                <li><strong>首字延迟（TTFT）</strong>：生成第一个token的时间</li>
                <li><strong>每字延迟（TPT）</strong>：生成每个token的平均时间</li>
                <li><strong>总延迟</strong>：完整响应的时间</li>
            </ul>

            <h3 style="color:#c7d2fe; margin-top:20px;">2. 吞吐量（Throughput）</h3>
            <p>单位时间内处理的token数量：</p>
            <div class="math-box">
                <p>$$\text{吞吐量} = \frac{\text{批大小} \times \text{序列长度}}{\text{总时间}}$$</p>
                <p>单位：tokens/second</p>
            </div>

            <h3 style="color:#c7d2fe; margin-top:20px;">3. 内存占用</h3>
            <ul>
                <li>模型权重</li>
                <li>激活值</li>
                <li>KV缓存</li>
                <li>临时缓冲区</li>
            </ul>
        </div>

        <div class="section">
            <h2>🔧 推理流程</h2>
            
            <h3 style="color:#c7d2fe; margin-top:20px;">自回归生成</h3>
            <ol>
                <li>输入提示（Prompt）</li>
                <li>模型生成第一个token</li>
                <li>将生成的token加入输入</li>
                <li>重复步骤2-3，直到生成结束标记</li>
            </ol>
            <p><strong>特点</strong>：逐个生成token，每次生成都需要完整前向传播，可以缓存已计算的KV值。</p>
        </div>

        <div class="section">
            <h2>📊 推理优化方向</h2>
            
            <h3 style="color:#c7d2fe; margin-top:20px;">1. 模型层面</h3>
            <ul>
                <li><strong>量化</strong>：FP32 → FP16/BF16 → INT8 → INT4</li>
                <li><strong>剪枝</strong>：移除冗余参数</li>
                <li><strong>知识蒸馏</strong>：训练小模型</li>
            </ul>

            <h3 style="color:#c7d2fe; margin-top:20px;">2. 计算层面</h3>
            <ul>
                <li><strong>算子融合</strong>：合并多个操作</li>
                <li><strong>图优化</strong>：常量折叠、死代码消除</li>
            </ul>

            <h3 style="color:#c7d2fe; margin-top:20px;">3. 系统层面</h3>
            <ul>
                <li><strong>批处理</strong>：动态批处理、连续批处理</li>
                <li><strong>缓存</strong>：KV缓存、激活值缓存</li>
            </ul>
        </div>

        <div class="section">
            <h2>🛠️ 推理框架</h2>
            <ul>
                <li><strong>vLLM</strong>：高效的注意力机制、PagedAttention、连续批处理</li>
                <li><strong>TensorRT-LLM</strong>：NVIDIA优化、算子融合、量化支持</li>
                <li><strong>llama.cpp</strong>：CPU优化、GGUF格式、量化推理</li>
                <li><strong>FasterTransformer</strong>：高性能实现、多种优化</li>
            </ul>
        </div>
    </div>
    <!-- 公共脚本 -->
    <script src="../common/tech-document.js"></script>
</body>
</html>

