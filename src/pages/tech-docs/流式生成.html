<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æµå¼ç”Ÿæˆï¼ˆStreaming Generationï¼‰</title>
    <script>
        window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']] }, options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] } };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    <!-- å…¬å…±æ ·å¼ -->
    <link rel="stylesheet" href="../common/styles.css">
</head>
<body>
    <div class="container">
        <h1>æµå¼ç”Ÿæˆï¼ˆStreaming Generationï¼‰</h1>
        <p class="tagline">å®æ—¶é€tokenç”Ÿæˆå’Œè¿”å›æ–‡æœ¬çš„æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒã€‚</p>

        <div class="meta-grid">
            <div class="meta-card"><h3>æ ¸å¿ƒç‰¹ç‚¹</h3><p>å®æ—¶ç”Ÿæˆã€ä½å»¶è¿Ÿã€è¿æ¥ç®¡ç†ã€æ€§èƒ½ä¼˜åŒ–ã€‚</p></div>
            <div class="meta-card"><h3>å®ç°æ–¹å¼</h3><p>SSEã€WebSocketã€ç”Ÿæˆå™¨æ¨¡å¼ã€‚</p></div>
            <div class="meta-card"><h3>å…³é”®æŒ‡æ ‡</h3><p>é¦–tokenæ—¶é—´ã€ååé‡ã€å»¶è¿Ÿã€‚</p></div>
            <div class="meta-card"><h3>åº”ç”¨åœºæ™¯</h3><p>å¯¹è¯ç³»ç»Ÿã€æ–‡æœ¬åˆ›ä½œã€ä»£ç ç”Ÿæˆç­‰ã€‚</p></div>
        </div>

        <div class="section">
            <h2>âš™ï¸ å®ç°æ–¹å¼</h2>
            <ul>
                <li><strong>Server-Sent Events (SSE)</strong>ï¼šHTTPé•¿è¿æ¥ï¼ŒæœåŠ¡å™¨æ¨é€æ•°æ®</li>
                <li><strong>WebSocket</strong>ï¼šåŒå‘é€šä¿¡ï¼Œæ”¯æŒæ›´å¤æ‚çš„äº¤äº’</li>
                <li><strong>ç”Ÿæˆå™¨æ¨¡å¼</strong>ï¼šä½¿ç”¨Pythonç”Ÿæˆå™¨é€tokenç”Ÿæˆ</li>
            </ul>
        </div>

        <div class="section">
            <h2>ğŸ”§ ä¸»è¦æŠ€æœ¯</h2>
            
            <h3 style="color:#fbbf24; margin-top:20px;">1. Server-Sent Events (SSE)</h3>
            <ul>
                <li><strong>ç‰¹ç‚¹</strong>ï¼šHTTPé•¿è¿æ¥ï¼ŒæœåŠ¡å™¨æ¨é€æ•°æ®</li>
                <li><strong>ä¼˜åŠ¿</strong>ï¼šç®€å•æ˜“ç”¨ï¼Œæµè§ˆå™¨åŸç”Ÿæ”¯æŒ</li>
                <li><strong>åŠ£åŠ¿</strong>ï¼šå•å‘é€šä¿¡ï¼ŒåŠŸèƒ½æœ‰é™</li>
            </ul>

            <h3 style="color:#fbbf24; margin-top:20px;">2. WebSocket</h3>
            <ul>
                <li><strong>ç‰¹ç‚¹</strong>ï¼šåŒå‘é€šä¿¡ï¼Œæ”¯æŒå¤æ‚äº¤äº’</li>
                <li><strong>ä¼˜åŠ¿</strong>ï¼šåŠŸèƒ½å¼ºå¤§ï¼Œé€‚åˆéœ€è¦ç”¨æˆ·è¾“å…¥çš„åœºæ™¯</li>
                <li><strong>åŠ£åŠ¿</strong>ï¼šå®ç°å¤æ‚ï¼Œéœ€è¦é¢å¤–åè®®</li>
            </ul>

            <h3 style="color:#fbbf24; margin-top:20px;">3. ç”Ÿæˆå™¨æ¨¡å¼</h3>
            <ul>
                <li><strong>ç‰¹ç‚¹</strong>ï¼šä½¿ç”¨Pythonç”Ÿæˆå™¨é€tokenç”Ÿæˆ</li>
                <li><strong>ä¼˜åŠ¿</strong>ï¼šç®€å•é«˜æ•ˆï¼Œæ¡†æ¶æ”¯æŒè‰¯å¥½</li>
                <li><strong>åŠ£åŠ¿</strong>ï¼šéœ€è¦æ¡†æ¶æ”¯æŒ</li>
            </ul>
        </div>

        <div class="section">
            <h2>ğŸ’» ä»£ç ç¤ºä¾‹</h2>
            <div class="code-box">
                <h3>ä½¿ç”¨ç”Ÿæˆå™¨å®ç°æµå¼ç”Ÿæˆ</h3>
                <pre><code class="language-python">from transformers import AutoTokenizer, AutoModelForCausalLM

def generate_stream(model, tokenizer, prompt, max_length=100):
    """æµå¼ç”Ÿæˆæ–‡æœ¬"""
    inputs = tokenizer(prompt, return_tensors="pt")
    input_ids = inputs.input_ids
    
    for _ in range(max_length):
        # ç”Ÿæˆä¸‹ä¸€ä¸ªtoken
        with torch.no_grad():
            outputs = model(input_ids)
            logits = outputs.logits[:, -1, :]
            next_token = torch.argmax(logits, dim=-1)
        
        # è§£ç å¹¶è¿”å›token
        token_text = tokenizer.decode(next_token, skip_special_tokens=True)
        yield token_text
        
        # æ›´æ–°input_ids
        input_ids = torch.cat([input_ids, next_token.unsqueeze(-1)], dim=-1)
        
        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
        if next_token.item() == tokenizer.eos_token_id:
            break

# ä½¿ç”¨ç¤ºä¾‹
for token in generate_stream(model, tokenizer, "Hello"):
    print(token, end="", flush=True)</code></pre>
            </div>

            <div class="code-box">
                <h3>FastAPIæµå¼å“åº”</h3>
                <pre><code class="language-python">from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

@app.post("/stream")
async def stream_generate(prompt: str):
    """æµå¼ç”ŸæˆAPI"""
    def generate():
        for token in generate_stream(model, tokenizer, prompt):
            yield f"data: {token}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream"
    )</code></pre>
            </div>
        </div>

        <div class="section">
            <h2>ğŸ“Š å…³é”®æŒ‡æ ‡</h2>
            <ul>
                <li><strong>é¦–tokenæ—¶é—´ï¼ˆTTFTï¼‰</strong>ï¼šä»è¯·æ±‚åˆ°ç¬¬ä¸€ä¸ªtokenè¿”å›çš„æ—¶é—´ï¼Œç›®æ ‡ < 200ms</li>
                <li><strong>ååé‡</strong>ï¼šæ¯ç§’ç”Ÿæˆçš„tokenæ•°é‡</li>
                <li><strong>å»¶è¿Ÿ</strong>ï¼šæ¯ä¸ªtokençš„ç”Ÿæˆæ—¶é—´ï¼Œä¿è¯æµç•…åº¦</li>
            </ul>
        </div>
    </div>
    <!-- å…¬å…±è„šæœ¬ -->
    <script src="../common/tech-document.js"></script>
</body>
</html>

