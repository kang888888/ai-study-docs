<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ChatGLM (æ™ºè°±AI) - æ¶æ„è¯¦è§£</title>
    <!-- MathJax for mathematical formulas -->
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Prism.js for code highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    <!-- å…¬å…±æ ·å¼ -->
    <link rel="stylesheet" href="../common/styles.css">
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ChatGLM (æ™ºè°±AI)</h1>
            <p>æ™ºè°±AIå¼€æºçš„ä¸­è‹±åŒè¯­å¯¹è¯æ¨¡å‹</p>
        </div>
        <div class="content">
            
            <div class="section">
                <h2>ğŸ“– æ ¸å¿ƒæ¦‚å¿µ</h2>
                <div class="desc-box">
                    <p>æ™ºè°±AIå¼€æºçš„ä¸­è‹±åŒè¯­å¯¹è¯æ¨¡å‹ï¼ŒåŸºäºGLMï¼ˆGeneral Language Modelï¼‰æ¶æ„ã€‚é‡‡ç”¨æ··åˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨ä¸­æ–‡ç†è§£å’Œç”Ÿæˆä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</p>
                </div>
            </div>
            <div class="section features">
                <h2>ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹</h2>
                <ul>
                    <li>ä¸­æ–‡ä¼˜åŒ–ï¼šåœ¨å¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™ä¸Šè®­ç»ƒï¼Œä¸­æ–‡èƒ½åŠ›çªå‡º</li>
                    <li>GLMæ¶æ„ï¼šæ··åˆè‡ªå›å½’å’Œè‡ªç¼–ç çš„é¢„è®­ç»ƒç›®æ ‡</li>
                    <li>å·¥å…·è°ƒç”¨ï¼šChatGLM3æ”¯æŒFunction Calling</li>
                    <li>å¤šæ¨¡æ€ï¼šGLM-4æ”¯æŒå›¾åƒç†è§£</li>
                    <li>å¼€æºå¯å•†ç”¨ï¼š6Bå‚æ•°ï¼Œå¯åœ¨æ¶ˆè´¹çº§GPUä¸Šè¿è¡Œ</li>
                </ul>
            </div>
            <div class="section">
                <h2>âš™ï¸ å…³é”®æŠ€æœ¯</h2>
                <div class="tech-box"><p><strong>GLMæ¶æ„ã€åŒå‘æ³¨æ„åŠ›ã€æ—‹è½¬ä½ç½®ç¼–ç ã€Flash Attention</strong></p></div>
            </div>
            <div class="section">
                <h2>ğŸš€ åº”ç”¨åœºæ™¯</h2>
                <div class="app-box"><p>ä¸­æ–‡å¯¹è¯ã€çŸ¥è¯†é—®ç­”ã€ä»£ç ç”Ÿæˆã€å·¥å…·è°ƒç”¨ã€å¤šæ¨¡æ€ç†è§£</p></div>
            </div>

            <div class="section">
                <h2>ğŸ“ æ•°å­¦åŸç†</h2>
                <div class="math-box">
                    <h3>GLM é¢„è®­ç»ƒç›®æ ‡</h3>
                    <div class="math-formula">
                        <p>GLM ç»“åˆè‡ªå›å½’å’Œè‡ªç¼–ç ï¼š</p>
                        <p>$$L = -\sum_{i \in M} \log P(x_i | x_{\backslash M}, M)$$</p>
                        <p>å…¶ä¸­ $M$ æ˜¯è¢«æ©ç çš„è¿ç»­spanï¼Œæ¨¡å‹éœ€è¦è‡ªå›å½’åœ°é¢„æµ‹è¿™äº›span</p>
                    </div>
                </div>
                <div class="math-box">
                    <h3>åŒå‘æ³¨æ„åŠ›</h3>
                    <div class="math-formula">
                        <p>ChatGLMä½¿ç”¨åŒå‘æ³¨æ„åŠ›ï¼Œå¯ä»¥åŒæ—¶åˆ©ç”¨å‰åæ–‡ä¿¡æ¯ï¼š</p>
                        <p>$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$</p>
                        <p>ä¸GPTçš„å•å‘æ³¨æ„åŠ›ä¸åŒï¼ŒChatGLMå¯ä»¥åŒå‘ç†è§£ä¸Šä¸‹æ–‡</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>ğŸ’» Python ä»£ç ç¤ºä¾‹</h2>
                <div class="code-box">
                    <h3>ä½¿ç”¨ Transformers åº“åŠ è½½ ChatGLM</h3>
                    <pre><code class="language-python">from transformers import AutoTokenizer, AutoModel
import torch

# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
model_path = "THUDM/chatglm-6b"  # éœ€è¦HuggingFaceè®¿é—®æƒé™
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().cuda()

# å¯¹è¯
query = "ä½ å¥½"
response, history = model.chat(tokenizer, query, history=[])
print(response)

# ç»§ç»­å¯¹è¯
query = "ä»‹ç»ä¸€ä¸‹æ·±åº¦å­¦ä¹ "
response, history = model.chat(tokenizer, query, history=history)
print(response)</code></pre>
                </div>
            </div>
        </div>
    </div>
    <!-- å…¬å…±è„šæœ¬ -->
    <script src="../common/tech-document.js"></script>
</body>
</html>

