<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CLIP (Contrastive Language-Image Pre-training) - æ¶æ„è¯¦è§£</title>
    <!-- MathJax for mathematical formulas -->
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Prism.js for code highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    <!-- å…¬å…±æ ·å¼ -->
    <link rel="stylesheet" href="../common/styles.css">
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>CLIP (Contrastive Language-Image Pre-training)</h1>
            <p>å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹</p>
        </div>
        <div class="content">
            
            <div class="section">
                <h2>ğŸ“– æ ¸å¿ƒæ¦‚å¿µ</h2>
                <div class="desc-box">
                    <p>OpenAIæå‡ºçš„å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å°†å›¾åƒå’Œæ–‡æœ¬æ˜ å°„åˆ°åŒä¸€ä¸ªå…±äº«çš„ç‰¹å¾ç©ºé—´ã€‚åœ¨4äº¿å¯¹å›¾æ–‡æ•°æ®ä¸Šè®­ç»ƒï¼Œå…·æœ‰å¼ºå¤§çš„é›¶æ ·æœ¬åˆ†ç±»èƒ½åŠ›ã€‚</p>
                </div>
            </div>
            <div class="section features">
                <h2>ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹</h2>
                <ul>
                    <li>å¯¹æ¯”å­¦ä¹ ï¼šæœ€å¤§åŒ–åŒ¹é…å›¾æ–‡å¯¹çš„ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–ä¸åŒ¹é…å¯¹çš„ç›¸ä¼¼åº¦</li>
                    <li>åŒå¡”æ¶æ„ï¼šImage Encoderï¼ˆResNet/ViTï¼‰+ Text Encoderï¼ˆTransformerï¼‰</li>
                    <li>é›¶æ ·æœ¬åˆ†ç±»ï¼šæ— éœ€å¾®è°ƒå³å¯è¿›è¡Œå›¾åƒåˆ†ç±»ï¼ˆåªéœ€æä¾›ç±»åˆ«åç§°ï¼‰</li>
                    <li>è¯­ä¹‰å¯¹é½ï¼šæ‰“é€šè§†è§‰ä¸è¯­è¨€çš„è¯­ä¹‰ç©ºé—´</li>
                    <li>å¤šæ¨¡æ€åŸºçŸ³ï¼šæ˜¯DALL-Eã€Stable Diffusionç­‰ç”Ÿæˆæ¨¡å‹çš„Text Encoder</li>
                </ul>
            </div>
            <div class="section">
                <h2>âš™ï¸ å…³é”®æŠ€æœ¯</h2>
                <div class="tech-box"><p><strong>å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰ã€ä½™å¼¦ç›¸ä¼¼åº¦ã€æ¸©åº¦å‚æ•°ï¼ˆTemperatureï¼‰ã€å¯¹æ¯”æŸå¤±</strong></p></div>
            </div>
            <div class="section">
                <h2>ğŸš€ åº”ç”¨åœºæ™¯</h2>
                <div class="app-box"><p>ä»¥æ–‡æœå›¾ã€é›¶æ ·æœ¬å›¾åƒåˆ†ç±»ã€å›¾åƒæè¿°ç”Ÿæˆã€å¤šæ¨¡æ€æ£€ç´¢ã€æ–‡ç”Ÿå›¾å¼•å¯¼</p></div>
            </div>
            <div class="section">
                <h2>ğŸ“Š æ¶æ„å›¾è§£</h2>
                <div class="diagram-gallery">
                    <div class="diagram-item"><img src="CLIP_Matching_Visualization.png" alt="CLIPåŒ¹é…å¯è§†åŒ–" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">CLIPåŒ¹é…å¯è§†åŒ–</div></div>
                </div>
            </div>

            <div class="section">
                <h2>ğŸ“ æ•°å­¦åŸç†</h2>
                <div class="math-box">
                    <h3>å¯¹æ¯”å­¦ä¹ æŸå¤±</h3>
                    <div class="math-formula">
                        <p>CLIP ä½¿ç”¨å¯¹ç§°çš„å¯¹æ¯”æŸå¤±ï¼š</p>
                        <p>$$L = -\frac{1}{N}\sum_{i=1}^{N}\left[\log\frac{\exp(\text{sim}(I_i, T_i) / \tau)}{\sum_{j=1}^{N}\exp(\text{sim}(I_i, T_j) / \tau)} + \log\frac{\exp(\text{sim}(T_i, I_i) / \tau)}{\sum_{j=1}^{N}\exp(\text{sim}(T_i, I_j) / \tau)}\right]$$</p>
                        <p>å…¶ä¸­ï¼š</p>
                        <ul style="list-style: none; padding-left: 20px;">
                            <li>$I_i$ æ˜¯ç¬¬ $i$ ä¸ªå›¾åƒçš„åµŒå…¥</li>
                            <li>$T_i$ æ˜¯ç¬¬ $i$ ä¸ªæ–‡æœ¬çš„åµŒå…¥</li>
                            <li>$\text{sim}(I, T) = I^T T / ||I|| ||T||$ æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦</li>
                            <li>$\tau$ æ˜¯æ¸©åº¦å‚æ•°</li>
                        </ul>
                    </div>
                </div>
                <div class="math-box">
                    <h3>ä½™å¼¦ç›¸ä¼¼åº¦</h3>
                    <div class="math-formula">
                        <p>è®¡ç®—å›¾åƒå’Œæ–‡æœ¬åµŒå…¥çš„ç›¸ä¼¼åº¦ï¼š</p>
                        <p>$$\text{sim}(I, T) = \frac{I \cdot T}{||I|| \cdot ||T||} = \cos(\theta)$$</p>
                        <p>å…¶ä¸­ $\theta$ æ˜¯å‘é‡ä¹‹é—´çš„å¤¹è§’</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>ğŸ’» Python ä»£ç ç¤ºä¾‹</h2>
                <div class="code-box">
                    <h3>ä½¿ç”¨ CLIP è¿›è¡Œå›¾åƒ-æ–‡æœ¬åŒ¹é…</h3>
                    <pre><code class="language-python">import torch
import clip
from PIL import Image

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# å‡†å¤‡å›¾åƒå’Œæ–‡æœ¬
image = preprocess(Image.open("image.jpg")).unsqueeze(0).to(device)
text = clip.tokenize(["a photo of a cat", "a photo of a dog"]).to(device)

# ç¼–ç 
with torch.no_grad():
    image_features = model.encode_image(image)
    text_features = model.encode_text(text)
    
    # å½’ä¸€åŒ–
    image_features = image_features / image_features.norm(dim=-1, keepdim=True)
    text_features = text_features / text_features.norm(dim=-1, keepdim=True)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    logits_per_image = (100.0 * image_features @ text_features.T)
    probs = logits_per_image.softmax(dim=-1)

print(f"å›¾åƒä¸æ–‡æœ¬çš„ç›¸ä¼¼åº¦æ¦‚ç‡: {probs}")

# é›¶æ ·æœ¬åˆ†ç±»
class_names = ["cat", "dog", "bird", "car", "tree"]
text_inputs = torch.cat([clip.tokenize(f"a photo of a {c}") for c in class_names]).to(device)

with torch.no_grad():
    text_features = model.encode_text(text_inputs)
    text_features = text_features / text_features.norm(dim=-1, keepdim=True)
    
    logits_per_image = (100.0 * image_features @ text_features.T)
    probs = logits_per_image.softmax(dim=-1)

predicted_class = class_names[probs.argmax().item()]
print(f"é¢„æµ‹ç±»åˆ«: {predicted_class}")</code></pre>
                </div>
                <div class="code-box">
                    <h3>æ‰‹åŠ¨å®ç° CLIP å¯¹æ¯”æŸå¤±</h3>
                    <pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class CLIPLoss(nn.Module):
    """CLIP å¯¹æ¯”æŸå¤±"""
    def __init__(self, temperature=0.07):
        super(CLIPLoss, self).__init__()
        self.temperature = temperature
    
    def forward(self, image_features, text_features):
        """
        å‚æ•°:
            image_features: [batch_size, embed_dim]
            text_features: [batch_size, embed_dim]
        """
        # å½’ä¸€åŒ–
        image_features = F.normalize(image_features, dim=-1)
        text_features = F.normalize(text_features, dim=-1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        logits = torch.matmul(image_features, text_features.T) / self.temperature
        
        # åˆ›å»ºæ ‡ç­¾ï¼ˆå¯¹è§’çº¿ä¸º1ï¼Œè¡¨ç¤ºåŒ¹é…ï¼‰
        labels = torch.arange(logits.size(0), device=logits.device)
        
        # å¯¹ç§°æŸå¤±
        loss_i2t = F.cross_entropy(logits, labels)
        loss_t2i = F.cross_entropy(logits.T, labels)
        
        loss = (loss_i2t + loss_t2i) / 2
        
        return loss

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    batch_size = 32
    embed_dim = 512
    
    # æ¨¡æ‹Ÿå›¾åƒå’Œæ–‡æœ¬ç‰¹å¾
    image_features = torch.randn(batch_size, embed_dim)
    text_features = torch.randn(batch_size, embed_dim)
    
    # è®¡ç®—æŸå¤±
    criterion = CLIPLoss(temperature=0.07)
    loss = criterion(image_features, text_features)
    
    print(f"CLIP æŸå¤±: {loss.item():.4f}")</code></pre>
                </div>
            </div>
        </div>
    </div>
    <!-- å›¾ç‰‡æ”¾å¤§å¼¹çª— -->
    <div id="imageModal" class="image-modal" onclick="closeImageModal()">
        <span class="image-modal-close" onclick="event.stopPropagation(); closeImageModal()">&times;</span>
        <img id="modalImage" class="image-modal-content" src="" alt="">
        <div id="modalCaption" class="image-modal-caption"></div>
    </div>
    <script>
        function openImageModal(img) {
            const modal = document.getElementById('imageModal');
            const modalImg = document.getElementById('modalImage');
            const modalCaption = document.getElementById('modalCaption');
            modal.classList.add('active');
            modalImg.src = img.src;
            modalCaption.textContent = img.alt || '';
            modalImg.onclick = function(e) { e.stopPropagation(); };
        }
        function closeImageModal() {
            document.getElementById('imageModal').classList.remove('active');
        }
        document.addEventListener('keydown', function(e) {
            if (e.key === 'Escape') closeImageModal();
        });
    </script>
    <!-- å…¬å…±è„šæœ¬ -->
    <script src="../common/tech-document.js"></script>
</body>
</html>

