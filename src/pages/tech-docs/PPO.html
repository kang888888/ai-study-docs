<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PPOï¼ˆProximal Policy Optimizationï¼‰è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–</title>
    <script>
        window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']] }, options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] } };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    <!-- å…¬å…±æ ·å¼ -->
    <link rel="stylesheet" href="../common/styles.css">
</head>
<body>
    <div class="container">
        <h1>PPOï¼šè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–</h1>
        <p class="tagline">é€šè¿‡è£å‰ªæœºåˆ¶é™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ï¼Œç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼Œæ˜¯RLHFè®­ç»ƒçš„æ ¸å¿ƒç®—æ³•ã€‚</p>

        <div class="meta-grid">
            <div class="meta-card"><h3>æ ¸å¿ƒæ€æƒ³</h3><p>ä½¿ç”¨è£å‰ªæœºåˆ¶é˜²æ­¢ç­–ç•¥æ›´æ–°è¿‡å¤§ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šæ€§ã€‚</p></div>
            <div class="meta-card"><h3>ä¸»è¦ä¼˜åŠ¿</h3><p>è®­ç»ƒç¨³å®šã€æ ·æœ¬é«˜æ•ˆã€å®ç°ç®€å•ã€å¹¿æ³›åº”ç”¨ã€‚</p></div>
            <div class="meta-card"><h3>é€‚ç”¨åœºæ™¯</h3><p>RLHFè®­ç»ƒã€ç­–ç•¥ä¼˜åŒ–ä»»åŠ¡ã€è¿ç»­åŠ¨ä½œç©ºé—´ã€‚</p></div>
            <div class="meta-card"><h3>æŠ€æœ¯è¦ç‚¹</h3><p>è£å‰ªæœºåˆ¶ã€é‡è¦æ€§é‡‡æ ·ã€å¤šè½®æ›´æ–°ã€KLæ•£åº¦çº¦æŸã€‚</p></div>
        </div>

        <div class="section">
            <h2>âš™ï¸ æ ¸å¿ƒåŸç†</h2>
            <ul>
                <li><strong>è£å‰ªæœºåˆ¶</strong>ï¼šä½¿ç”¨è£å‰ªé™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ï¼Œé˜²æ­¢è¿‡åº¦æ›´æ–°</li>
                <li><strong>é‡è¦æ€§é‡‡æ ·</strong>ï¼šä½¿ç”¨æ—§ç­–ç•¥çš„æ ·æœ¬ä¼°è®¡æ–°ç­–ç•¥çš„æœŸæœ›</li>
                <li><strong>å¤šè½®æ›´æ–°</strong>ï¼šå¯¹åŒä¸€æ‰¹æ•°æ®å¤šæ¬¡æ›´æ–°ï¼Œæé«˜æ ·æœ¬æ•ˆç‡</li>
                <li><strong>KLæ•£åº¦çº¦æŸ</strong>ï¼šéšå¼æˆ–æ˜¾å¼çº¦æŸç­–ç•¥æ›´æ–°å¹…åº¦</li>
            </ul>
        </div>

        <div class="section">
            <h2>ğŸ“ æ•°å­¦åŸç†</h2>
            <div class="math-box">
                <h3>PPO-Clipç›®æ ‡å‡½æ•°</h3>
                <div class="math-formula">
                    <p>$$L^{CLIP}(\theta) = \mathbb{E}[\min(r_t(\theta) A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) A_t)]$$</p>
                    <p>å…¶ä¸­ï¼š</p>
                    <ul>
                        <li>$r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{old}(a_t|s_t)}$ï¼šé‡è¦æ€§é‡‡æ ·æ¯”ç‡</li>
                        <li>$A_t$ï¼šä¼˜åŠ¿å‡½æ•°</li>
                        <li>$\epsilon$ï¼šè£å‰ªå‚æ•°ï¼ˆé€šå¸¸0.1-0.2ï¼‰</li>
                    </ul>
                </div>
            </div>
            <div class="math-box">
                <h3>ä¼˜åŠ¿å‡½æ•°ä¼°è®¡ï¼ˆGAEï¼‰</h3>
                <div class="math-formula">
                    <p>$$A_t = \delta_t + (\gamma\lambda)\delta_{t+1} + (\gamma\lambda)^2\delta_{t+2} + \cdots$$</p>
                    <p>å…¶ä¸­ $\delta_t = r_t + \gamma V(s_{t+1}) - V(s_t)$</p>
                </div>
            </div>
            <div class="math-box">
                <h3>æ€»æŸå¤±å‡½æ•°ï¼ˆRLHFä¸­ï¼‰</h3>
                <div class="math-formula">
                    <p>$$L_{total} = L_{CLIP} - c_1 L_{VF} + c_2 L_{KL}$$</p>
                    <p>åŒ…å«ç­–ç•¥æŸå¤±ã€ä»·å€¼å‡½æ•°æŸå¤±å’ŒKLæ•£åº¦æƒ©ç½šé¡¹ã€‚</p>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>ğŸ’» ä»£ç ç¤ºä¾‹</h2>
            <div class="code-box">
                <h3>ä½¿ç”¨ TRL è¿›è¡Œ PPO è®­ç»ƒ</h3>
                <pre><code class="language-python">from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead
from transformers import AutoTokenizer

config = PPOConfig(
    model_name="meta-llama/Llama-2-7b-hf",
    learning_rate=1e-5,
    batch_size=64,
    ppo_epochs=4,
    kl_penalty=0.1
)

tokenizer = AutoTokenizer.from_pretrained(config.model_name)
model = AutoModelForCausalLMWithValueHead.from_pretrained(
    config.model_name,
    load_in_4bit=True,
    device_map="auto"
)

ppo_trainer = PPOTrainer(
    config,
    model,
    tokenizer,
    dataset=rlhf_dataset
)

# è®­ç»ƒå¾ªç¯
for epoch in range(config.ppo_epochs):
    for batch in dataloader:
        # ç”Ÿæˆå“åº”
        responses = model.generate(batch['prompt'])
        
        # è®¡ç®—å¥–åŠ±
        rewards = reward_model(responses)
        
        # PPOæ›´æ–°
        ppo_trainer.step(responses, rewards)</code></pre>
            </div>
        </div>

        <div class="section">
            <h2>ğŸ¯ åœ¨RLHFä¸­çš„åº”ç”¨</h2>
            <p>PPOæ˜¯RLHFç¬¬ä¸‰é˜¶æ®µçš„æ ¸å¿ƒç®—æ³•ï¼Œç”¨äºä¼˜åŒ–ç­–ç•¥æ¨¡å‹ï¼š</p>
            <ol>
                <li><strong>ç­–ç•¥æ¨¡å‹ç”Ÿæˆå“åº”</strong>ï¼šä½¿ç”¨å½“å‰ç­–ç•¥ç”Ÿæˆå¤šä¸ªå“åº”</li>
                <li><strong>å¥–åŠ±æ¨¡å‹è¯„åˆ†</strong>ï¼šä½¿ç”¨å¥–åŠ±æ¨¡å‹å¯¹å“åº”è¿›è¡Œè¯„åˆ†</li>
                <li><strong>è®¡ç®—ä¼˜åŠ¿å‡½æ•°</strong>ï¼šä½¿ç”¨GAEä¼°è®¡ä¼˜åŠ¿å‡½æ•°</li>
                <li><strong>PPOæ›´æ–°ç­–ç•¥</strong>ï¼šä½¿ç”¨PPO-Clipæ›´æ–°ç­–ç•¥å‚æ•°</li>
            </ol>
        </div>

        <div class="section">
            <h2>âš™ï¸ è¶…å‚æ•°è®¾ç½®</h2>
            <ul>
                <li><strong>Îµï¼ˆè£å‰ªå‚æ•°ï¼‰</strong>ï¼š0.1-0.2</li>
                <li><strong>å­¦ä¹ ç‡</strong>ï¼š1e-6åˆ°1e-5</li>
                <li><strong>æ‰¹æ¬¡å¤§å°</strong>ï¼šæ ¹æ®èµ„æºè°ƒæ•´</li>
                <li><strong>æ›´æ–°è½®æ•°</strong>ï¼š3-10è½®</li>
            </ul>
        </div>
    </div>
    <!-- å…¬å…±è„šæœ¬ -->
    <script src="../common/tech-document.js"></script>
</body>
</html>

