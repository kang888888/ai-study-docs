<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer - æ¶æ„è¯¦è§£</title>
    <!-- MathJax for mathematical formulas -->
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Prism.js for code highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    
    <!-- å…¬å…±æ ·å¼ -->
    <link rel="stylesheet" href="../common/styles.css">
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Transformer</h1>
            <p>åŸºäºSelf-Attentionæœºåˆ¶çš„é©å‘½æ€§æ¶æ„</p>
        </div>
        <div class="content">
            
            <div class="section">
                <h2>ğŸ“– æ ¸å¿ƒæ¦‚å¿µ</h2>
                <div class="desc-box">
                    <p>åŸºäºSelf-Attentionæœºåˆ¶çš„é©å‘½æ€§æ¶æ„ï¼Œå®Œå…¨æ‘’å¼ƒäº†å¾ªç¯å’Œå·ç§¯ç»“æ„ã€‚é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ç›´æ¥å»ºæ¨¡åºåˆ—ä¸­ä»»æ„ä¸¤ä¸ªä½ç½®çš„å…³ç³»ï¼Œæ˜¯å½“å‰æ‰€æœ‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPTã€BERTã€LLaMAï¼‰çš„åŸºçŸ³ã€‚</p>
                </div>
            </div>
            <div class="section features">
                <h2>ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹</h2>
                <ul>
                    <li>Self-Attentionï¼šç›´æ¥è®¡ç®—åºåˆ—ä¸­ä»»æ„ä½ç½®ä¹‹é—´çš„å…³ç³»ï¼ŒO(nÂ²)å¤æ‚åº¦</li>
                    <li>å¹¶è¡Œè®¡ç®—ï¼šæ‰€æœ‰ä½ç½®åŒæ—¶è®¡ç®—ï¼Œè®­ç»ƒé€Ÿåº¦è¿œè¶…RNN/LSTM</li>
                    <li>ä½ç½®ç¼–ç ï¼šé€šè¿‡æ­£å¼¦/ä½™å¼¦æˆ–å¯å­¦ä¹ çš„ä½ç½®ç¼–ç ä¿ç•™åºåˆ—é¡ºåºä¿¡æ¯</li>
                    <li>å¤šå¤´æ³¨æ„åŠ›ï¼šä»å¤šä¸ªå­ç©ºé—´æ•æ‰ä¸åŒçš„è¯­ä¹‰å…³ç³»</li>
                    <li>Encoder-Decoderç»“æ„ï¼šç¼–ç å™¨ç†è§£è¾“å…¥ï¼Œè§£ç å™¨ç”Ÿæˆè¾“å‡º</li>
                </ul>
            </div>
            <div class="section">
                <h2>âš™ï¸ å…³é”®æŠ€æœ¯</h2>
                <div class="tech-box"><p><strong>Multi-Head Attentionã€ä½ç½®ç¼–ç ã€æ®‹å·®è¿æ¥ã€Layer Normalizationã€Feed-Forward Network</strong></p></div>
            </div>
            <div class="section">
                <h2>ğŸš€ åº”ç”¨åœºæ™¯</h2>
                <div class="app-box"><p>æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆã€å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT/BERTï¼‰ã€å›¾åƒåˆ†ç±»ï¼ˆViTï¼‰ã€è¯­éŸ³è¯†åˆ«</p></div>
            </div>
            <div class="section">
                <h2>ğŸ“Š æ¶æ„å›¾è§£</h2>
                <div class="diagram-gallery">
                    <div class="diagram-item"><img src="Transformeræ¶æ„å›¾.png" alt="Transformeræ¶æ„å›¾" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">Transformeræ¶æ„å›¾</div></div>
                    <div class="diagram-item"><img src="æ³¨æ„åŠ›æœºåˆ¶.png" alt="æ³¨æ„åŠ›æœºåˆ¶" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">æ³¨æ„åŠ›æœºåˆ¶</div></div>
                    <div class="diagram-item"><img src="ä½ç½®ç¼–ç .png" alt="ä½ç½®ç¼–ç " onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">ä½ç½®ç¼–ç </div></div>
                    <div class="diagram-item"><img src="Attention_Variants_Visualization.png" alt="Attentionå˜ä½“å¯è§†åŒ–" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">Attentionå˜ä½“å¯è§†åŒ–</div></div>
                    <div class="diagram-item"><img src="RoPEä½ç½®ç¼–ç .svg" alt="RoPEä½ç½®ç¼–ç " onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">RoPEä½ç½®ç¼–ç </div></div>
                    <div class="diagram-item"><img src="RoPEè¯¦ç»†ä½œç”¨.svg" alt="RoPEè¯¦ç»†ä½œç”¨" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">RoPEå¯¹å„åºåˆ—ä½ç½®ã€å„ç»´åº¦çš„ä½œç”¨</div></div>
                    <div class="diagram-item"><img src="æ³¨æ„åŠ›æœºåˆ¶å˜ä½“.svg" alt="æ³¨æ„åŠ›æœºåˆ¶å˜ä½“" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">MHAã€GQAã€MQAã€MLAå¯¹æ¯”</div></div>
                    <div class="diagram-item"><img src="RMSNorm.svg" alt="RMSNorm" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">RMSNormå½’ä¸€åŒ–</div></div>
                    <div class="diagram-item"><img src="SwiGLU.svg" alt="SwiGLU" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">SwiGLUæ¿€æ´»å‡½æ•°</div></div>
                    <div class="diagram-item"><img src="ALiBiä½ç½®ç¼–ç .svg" alt="ALiBiä½ç½®ç¼–ç " onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">ALiBiä½ç½®ç¼–ç </div></div>
                    <div class="diagram-item"><img src="å½’ä¸€åŒ–æ–¹æ³•å¯¹æ¯”.svg" alt="å½’ä¸€åŒ–æ–¹æ³•å¯¹æ¯”" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">BatchNormå’ŒLayerNormå¯¹æ¯”</div></div>
                    <div class="diagram-item"><img src="Pre-normå’ŒPost-norm.svg" alt="Pre-normå’ŒPost-norm" onclick="openImageModal(this)" onerror="this.parentElement.style.display='none'"><div class="caption">Pre-normå’ŒPost-norm</div></div>
                </div>
            </div>

            <div class="section">
                <h2>ğŸ“ æ•°å­¦åŸç†</h2>
                <div class="math-box">
                    <h3>Scaled Dot-Product Attention</h3>
                    <div class="math-formula">
                        <p>æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒå…¬å¼ï¼š</p>
                        <p>$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$</p>
                        <p>å…¶ä¸­ï¼š</p>
                        <ul style="list-style: none; padding-left: 20px;">
                            <li>$Q$ æ˜¯æŸ¥è¯¢çŸ©é˜µ (Query)</li>
                            <li>$K$ æ˜¯é”®çŸ©é˜µ (Key)</li>
                            <li>$V$ æ˜¯å€¼çŸ©é˜µ (Value)</li>
                            <li>$d_k$ æ˜¯é”®çš„ç»´åº¦ï¼Œç”¨äºç¼©æ”¾</li>
                        </ul>
                    </div>
                </div>
                <div class="math-box">
                    <h3>Multi-Head Attention</h3>
                    <div class="math-formula">
                        <p>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼š</p>
                        <p>$$\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O$$</p>
                        <p>$$\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$</p>
                        <p>å…¶ä¸­ $h$ æ˜¯æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼Œæ¯ä¸ªå¤´æœ‰ç‹¬ç«‹çš„æƒé‡çŸ©é˜µ $W_i^Q, W_i^K, W_i^V$</p>
                    </div>
                </div>
                <div class="math-box">
                    <h3>ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰</h3>
                    <div class="math-formula">
                        <p>æ­£å¼¦ä½ç½®ç¼–ç ï¼š</p>
                        <p>$$PE_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right)$$</p>
                        <p>$$PE_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right)$$</p>
                        <p>å…¶ä¸­ $pos$ æ˜¯ä½ç½®ï¼Œ$i$ æ˜¯ç»´åº¦ç´¢å¼•ï¼Œ$d_{model}$ æ˜¯æ¨¡å‹ç»´åº¦</p>
                    </div>
                </div>
                <div class="math-box">
                    <h3>Feed-Forward Network</h3>
                    <div class="math-formula">
                        <p>å‰é¦ˆç½‘ç»œï¼š</p>
                        <p>$$\text{FFN}(x) = \max(0, xW_1 + b_1)W_2 + b_2$$</p>
                        <p>é€šå¸¸ $d_{ff} = 4 \times d_{model}$</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>ğŸ’» Python ä»£ç ç¤ºä¾‹</h2>
                <div class="code-box">
                    <h3>ä½¿ç”¨ PyTorch å®ç° Transformer</h3>
                    <pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
import math

class MultiHeadAttention(nn.Module):
    """å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶"""
    def __init__(self, d_model, num_heads):
        super(MultiHeadAttention, self).__init__()
        assert d_model % num_heads == 0
        
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        
        # çº¿æ€§å˜æ¢å±‚
        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)
    
    def scaled_dot_product_attention(self, Q, K, V, mask=None):
        """ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›"""
        # Q, K, V shape: (batch_size, num_heads, seq_len, d_k)
        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)
        
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
        
        attention_weights = F.softmax(scores, dim=-1)
        output = torch.matmul(attention_weights, V)
        
        return output, attention_weights
    
    def forward(self, query, key, value, mask=None):
        batch_size = query.size(0)
        
        # çº¿æ€§å˜æ¢å¹¶é‡å¡‘ä¸ºå¤šå¤´
        Q = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        K = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        V = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        
        # æ³¨æ„åŠ›è®¡ç®—
        attention_output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)
        
        # æ‹¼æ¥å¤šå¤´
        attention_output = attention_output.transpose(1, 2).contiguous().view(
            batch_size, -1, self.d_model
        )
        
        # è¾“å‡ºæŠ•å½±
        output = self.W_o(attention_output)
        
        return output

class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           (-math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        
        self.register_buffer('pe', pe)
    
    def forward(self, x):
        # x shape: (seq_len, batch_size, d_model)
        x = x + self.pe[:x.size(0), :]
        return x

class TransformerBlock(nn.Module):
    """Transformer ç¼–ç å™¨å—"""
    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):
        super(TransformerBlock, self).__init__()
        
        self.attention = MultiHeadAttention(d_model, num_heads)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        
        self.feed_forward = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.ReLU(),
            nn.Linear(d_ff, d_model)
        )
        
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x, mask=None):
        # è‡ªæ³¨æ„åŠ› + æ®‹å·®è¿æ¥
        attn_output = self.attention(x, x, x, mask)
        x = self.norm1(x + self.dropout(attn_output))
        
        # å‰é¦ˆç½‘ç»œ + æ®‹å·®è¿æ¥
        ff_output = self.feed_forward(x)
        x = self.norm2(x + self.dropout(ff_output))
        
        return x

class Transformer(nn.Module):
    """å®Œæ•´çš„ Transformer æ¨¡å‹"""
    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_len=5000, dropout=0.1):
        super(Transformer, self).__init__()
        
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.pos_encoding = PositionalEncoding(d_model, max_len)
        
        self.layers = nn.ModuleList([
            TransformerBlock(d_model, num_heads, d_ff, dropout)
            for _ in range(num_layers)
        ])
        
        self.dropout = nn.Dropout(dropout)
        self.fc_out = nn.Linear(d_model, vocab_size)
    
    def forward(self, x, mask=None):
        # è¯åµŒå…¥
        x = self.embedding(x) * math.sqrt(self.embedding.embedding_dim)
        x = x.transpose(0, 1)  # (seq_len, batch_size, d_model)
        
        # ä½ç½®ç¼–ç 
        x = self.pos_encoding(x)
        x = self.dropout(x)
        
        # Transformer å±‚
        for layer in self.layers:
            x = layer(x, mask)
        
        # è½¬å› (batch_size, seq_len, d_model)
        x = x.transpose(0, 1)
        
        # è¾“å‡ºå±‚
        output = self.fc_out(x)
        
        return output

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæ¨¡å‹
    model = Transformer(
        vocab_size=10000,
        d_model=512,
        num_heads=8,
        num_layers=6,
        d_ff=2048
    )
    
    # æ¨¡æ‹Ÿè¾“å…¥ (batch_size=32, seq_len=50)
    x = torch.randint(0, 10000, (32, 50))
    
    # å‰å‘ä¼ æ’­
    output = model(x)
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")  # [32, 50, 10000]</code></pre>
                </div>
                <div class="code-box">
                    <h3>ä½¿ç”¨ NumPy æ‰‹åŠ¨å®ç°æ³¨æ„åŠ›æœºåˆ¶</h3>
                    <pre><code class="language-python">import numpy as np

def scaled_dot_product_attention(Q, K, V, mask=None):
    """
    ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›
    
    å‚æ•°:
        Q: æŸ¥è¯¢çŸ©é˜µ (..., seq_len_q, d_k)
        K: é”®çŸ©é˜µ (..., seq_len_k, d_k)
        V: å€¼çŸ©é˜µ (..., seq_len_v, d_v)
        mask: æ©ç çŸ©é˜µ
    """
    d_k = Q.shape[-1]
    
    # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
    scores = np.matmul(Q, K.transpose(-2, -1)) / np.sqrt(d_k)
    
    # åº”ç”¨æ©ç 
    if mask is not None:
        scores = np.where(mask == 0, -1e9, scores)
    
    # Softmax
    attention_weights = np.exp(scores - np.max(scores, axis=-1, keepdims=True))
    attention_weights = attention_weights / np.sum(attention_weights, axis=-1, keepdims=True)
    
    # åŠ æƒæ±‚å’Œ
    output = np.matmul(attention_weights, V)
    
    return output, attention_weights

def positional_encoding(max_len, d_model):
    """ç”Ÿæˆä½ç½®ç¼–ç """
    pe = np.zeros((max_len, d_model))
    
    for pos in range(max_len):
        for i in range(0, d_model, 2):
            pe[pos, i] = np.sin(pos / (10000 ** (2 * i / d_model)))
            if i + 1 < d_model:
                pe[pos, i + 1] = np.cos(pos / (10000 ** (2 * i / d_model)))
    
    return pe

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»º Q, K, V
    batch_size, seq_len, d_k = 2, 10, 64
    Q = np.random.randn(batch_size, seq_len, d_k)
    K = np.random.randn(batch_size, seq_len, d_k)
    V = np.random.randn(batch_size, seq_len, d_k)
    
    # è®¡ç®—æ³¨æ„åŠ›
    output, attention_weights = scaled_dot_product_attention(Q, K, V)
    print(f"æ³¨æ„åŠ›è¾“å‡ºå½¢çŠ¶: {output.shape}")  # (2, 10, 64)
    print(f"æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attention_weights.shape}")  # (2, 10, 10)
    
    # ç”Ÿæˆä½ç½®ç¼–ç 
    pe = positional_encoding(max_len=100, d_model=512)
    print(f"ä½ç½®ç¼–ç å½¢çŠ¶: {pe.shape}")  # (100, 512)</code></pre>
                </div>
            </div>
        </div>
    </div>
    <!-- å›¾ç‰‡æ”¾å¤§å¼¹çª— -->
    <div id="imageModal" class="image-modal" onclick="closeImageModal()">
        <span class="image-modal-close" onclick="event.stopPropagation(); closeImageModal()">&times;</span>
        <img id="modalImage" class="image-modal-content" src="" alt="">
        <div id="modalCaption" class="image-modal-caption"></div>
    </div>
    <script>
        function openImageModal(img) {
            const modal = document.getElementById('imageModal');
            const modalImg = document.getElementById('modalImage');
            const modalCaption = document.getElementById('modalCaption');
            modal.classList.add('active');
            modalImg.src = img.src;
            modalCaption.textContent = img.alt || '';
            modalImg.onclick = function(e) { e.stopPropagation(); };
        }
        function closeImageModal() {
            document.getElementById('imageModal').classList.remove('active');
        }
        document.addEventListener('keydown', function(e) {
            if (e.key === 'Escape') closeImageModal();
        });
    </script>
    <!-- å…¬å…±è„šæœ¬ -->
    <script src="../common/tech-document.js"></script>
</body>
</html>

