{
  "title": "ä»£ç ç”ŸæˆåŸºå‡†",
  "subtitle": "HumanEvalã€MBPPç­‰ä»£ç ç”Ÿæˆä¸æ‰§è¡Œæ­£ç¡®æ€§è¯„ä¼°åŸºå‡†ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "ä»£ç ç”ŸæˆåŸºå‡†åˆ†ç±»",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "comparison",
                "title": "ä»£ç ç”ŸæˆåŸºå‡†åˆ†ç±»",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "Pass@kè¯„ä¼°æµç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "Pass@kè¯„ä¼°æµç¨‹",
                "data": null
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨HumanEvalåŸºå‡†",
          "language": "python",
          "code": "from datasets import load_dataset\nimport subprocess\nimport tempfile\nimport os\n\n# åŠ è½½HumanEvalæ•°æ®é›†\nhuman_eval = load_dataset(\"openai_humaneval\")\n\nprint(f\"HumanEvalåŒ…å« {len(human_eval['test'])} ä¸ªç¼–ç¨‹é—®é¢˜\")\n\n# æŸ¥çœ‹ç¤ºä¾‹\n example = human_eval['test'][0]\nprint(f\"ä»»åŠ¡ID: {example['task_id']}\")\nprint(f\"æç¤º: {example['prompt']}\")\nprint(f\"æµ‹è¯•ç”¨ä¾‹: {example['test']}\")\n\ndef evaluate_code_execution(code, test_cases):\n    \"\"\"è¯„ä¼°ä»£ç æ‰§è¡Œæ˜¯å¦æ­£ç¡®\"\"\"\n    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶\n    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n        f.write(code)\n        temp_file = f.name\n    \n    try:\n        # æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹\n        result = subprocess.run(\n            ['python', temp_file],\n            input=test_cases,\n            capture_output=True,\n            text=True,\n            timeout=5\n        )\n        \n        # æ£€æŸ¥æ˜¯å¦é€šè¿‡\n        return result.returncode == 0\n    except subprocess.TimeoutExpired:\n        return False\n    finally:\n        os.unlink(temp_file)\n\ndef pass_at_k(n, c, k):\n    \"\"\"è®¡ç®—Pass@kæŒ‡æ ‡\"\"\"\n    if n - c < k:\n        return 1.0\n    \n    numerator = 1.0\n    denominator = 1.0\n    for i in range(k):\n        numerator *= (n - c - i)\n        denominator *= (n - i)\n    \n    return 1.0 - numerator / denominator\n\nprint(f\"HumanEvalè¯„ä¼°å®Œæˆ\")"
        },
        {
          "type": "code-box",
          "title": "ä½¿ç”¨MBPPåŸºå‡†",
          "language": "python",
          "code": "from datasets import load_dataset\n\n# MBPP (Mostly Basic Python Problems)\nmbpp = load_dataset(\"mbpp\")\n\nprint(f\"MBPPè®­ç»ƒé›†: {len(mbpp['train'])} é—®é¢˜\")\nprint(f\"MBPPæµ‹è¯•é›†: {len(mbpp['test'])} é—®é¢˜\")\nprint(f\"MBPPéªŒè¯é›†: {len(mbpp['validation'])} é—®é¢˜\")\n\n# æŸ¥çœ‹ç¤ºä¾‹\n example = mbpp['test'][0]\nprint(f\"ä»»åŠ¡: {example['text']}\")\nprint(f\"ä»£ç : {example['code']}\")\nprint(f\"æµ‹è¯•ç”¨ä¾‹: {example['test_list']}\")\n\ndef evaluate_mbpp(model, dataset):\n    \"\"\"è¯„ä¼°æ¨¡å‹åœ¨MBPPä¸Šçš„è¡¨ç°\"\"\"\n    passed = 0\n    total = 0\n    \n    for example in dataset['test']:\n        prompt = example['text']\n        test_cases = example['test_list']\n        \n        # æ¨¡å‹ç”Ÿæˆä»£ç \n        generated_code = model.generate_code(prompt)\n        \n        # æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹\n        if evaluate_code_execution(generated_code, test_cases):\n            passed += 1\n        total += 1\n    \n    pass_rate = passed / total if total > 0 else 0.0\n    return pass_rate\n\nprint(f\"MBPPè¯„ä¼°å®Œæˆ\")"
        }
      ]
    }
  ]
}
