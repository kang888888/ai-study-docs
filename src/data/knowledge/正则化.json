{
  "title": "æ­£åˆ™åŒ– (Regularization)",
  "subtitle": "é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ ¸å¿ƒæŠ€æœ¯",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "æ­£åˆ™åŒ–æ˜¯ä¸€ç±»ç”¨äºé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆçš„æŠ€æœ¯ï¼Œé€šè¿‡åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ æƒ©ç½šé¡¹æˆ–ä¿®æ”¹æ¨¡å‹ç»“æ„ï¼Œé™åˆ¶æ¨¡å‹å¤æ‚åº¦ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ ä¸»è¦ç±»å‹",
      "content": [
        {
          "type": "features",
          "items": [
            "L1æ­£åˆ™åŒ–ï¼ˆLassoï¼‰ï¼šä½¿ç”¨æƒé‡çš„ç»å¯¹å€¼ä¹‹å’Œä½œä¸ºæƒ©ç½šé¡¹ï¼Œå€¾å‘äºäº§ç”Ÿç¨€ç–æƒé‡",
            "L2æ­£åˆ™åŒ–ï¼ˆRidge/æƒé‡è¡°å‡ï¼‰ï¼šä½¿ç”¨æƒé‡çš„å¹³æ–¹å’Œä½œä¸ºæƒ©ç½šé¡¹ï¼Œä½¿æƒé‡è¶‹å‘äºå°å€¼",
            "Dropoutï¼šè®­ç»ƒæ—¶éšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥ç»å…ƒï¼Œå‡å°‘ç¥ç»å…ƒé—´çš„å…±é€‚åº”",
            "DropConnectï¼šéšæœºæ–­å¼€éƒ¨åˆ†è¿æ¥è€Œéç¥ç»å…ƒ",
            "Early Stoppingï¼šç›‘æ§éªŒè¯é›†æ€§èƒ½ï¼Œæå‰åœæ­¢è®­ç»ƒ",
            "æ•°æ®å¢å¼ºï¼šé€šè¿‡å˜æ¢å¢åŠ è®­ç»ƒæ•°æ®å¤šæ ·æ€§",
            "æ ‡ç­¾å¹³æ»‘ï¼šè½¯åŒ–ç¡¬æ ‡ç­¾ï¼Œå‡å°‘æ¨¡å‹è¿‡åº¦è‡ªä¿¡"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "L1/L2æ­£åˆ™åŒ–ã€Dropoutã€æƒé‡è¡°å‡ã€Early Stoppingã€æ ‡ç­¾å¹³æ»‘ã€æ•°æ®å¢å¼º"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "é˜²æ­¢è¿‡æ‹Ÿåˆã€æé«˜æ³›åŒ–èƒ½åŠ›ã€æ¨¡å‹å‹ç¼©ï¼ˆL1ç¨€ç–åŒ–ï¼‰ã€è®­ç»ƒç¨³å®šæ€§æå‡"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æ­£åˆ™åŒ–æ–¹æ³•å¯¹æ¯”",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "concept",
                "title": "æ­£åˆ™åŒ–æ–¹æ³•å¯¹æ¯”"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "L2æ­£åˆ™åŒ–ï¼ˆæƒé‡è¡°å‡ï¼‰",
          "formulas": [
            {
              "text": "L2æ­£åˆ™åŒ–åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ æƒé‡çš„å¹³æ–¹å’Œï¼š"
            },
            {
              "display": "L_{total} = L_{data} + \\lambda \\sum_{i} w_i^2"
            },
            {
              "text": "å…¶ä¸­ $\\lambda$ æ˜¯æ­£åˆ™åŒ–ç³»æ•°ï¼Œæ§åˆ¶æ­£åˆ™åŒ–å¼ºåº¦",
              "inline": "\\lambda"
            },
            {
              "text": "æ¢¯åº¦æ›´æ–°æ—¶ï¼Œæƒé‡ä¼šé¢å¤–è¡°å‡ï¼š"
            },
            {
              "display": "w_i \\leftarrow w_i - \\eta \\left(\\frac{\\partial L}{\\partial w_i} + 2\\lambda w_i\\right)"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "L1æ­£åˆ™åŒ–ï¼ˆLassoï¼‰",
          "formulas": [
            {
              "text": "L1æ­£åˆ™åŒ–ä½¿ç”¨æƒé‡çš„ç»å¯¹å€¼ä¹‹å’Œï¼š"
            },
            {
              "display": "L_{total} = L_{data} + \\lambda \\sum_{i} |w_i|"
            },
            {
              "text": "L1æ­£åˆ™åŒ–å€¾å‘äºäº§ç”Ÿç¨€ç–è§£ï¼Œå³è®¸å¤šæƒé‡å˜ä¸º0ï¼Œå®ç°ç‰¹å¾é€‰æ‹©"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "Dropout",
          "formulas": [
            {
              "text": "è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªç¥ç»å…ƒä»¥æ¦‚ç‡ $p$ è¢«ä¿ç•™ï¼š"
            },
            {
              "display": "h_i^{train} = \\begin{cases} \\frac{h_i}{1-p} & \\text{with prob } 1-p \\\\ 0 & \\text{with prob } p \\end{cases}"
            },
            {
              "text": "æ¨ç†æ—¶ï¼Œæ‰€æœ‰ç¥ç»å…ƒéƒ½æ¿€æ´»ï¼Œä½†è¾“å‡ºéœ€è¦ç¼©æ”¾ï¼š"
            },
            {
              "display": "h_i^{test} = h_i"
            },
            {
              "text": "è®­ç»ƒæ—¶é™¤ä»¥ $(1-p)$ æ˜¯ä¸ºäº†ä¿æŒæœŸæœ›å€¼ä¸å˜"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "PyTorch ä¸­çš„æ­£åˆ™åŒ–å®ç°",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# 1. L2æ­£åˆ™åŒ–ï¼ˆæƒé‡è¡°å‡ï¼‰\n# åœ¨ä¼˜åŒ–å™¨ä¸­è®¾ç½® weight_decay å‚æ•°\nmodel = nn.Linear(10, 1)\noptimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001)\n\n# 2. L1æ­£åˆ™åŒ–ï¼ˆæ‰‹åŠ¨å®ç°ï¼‰\ndef l1_regularization(model, lambda_l1):\n    l1_loss = 0\n    for param in model.parameters():\n        l1_loss += torch.sum(torch.abs(param))\n    return lambda_l1 * l1_loss\n\n# è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨\nfor epoch in range(100):\n    # å‰å‘ä¼ æ’­\n    output = model(input)\n    loss = criterion(output, target)\n    \n    # æ·»åŠ L1æ­£åˆ™åŒ–\n    l1_loss = l1_regularization(model, lambda_l1=0.001)\n    total_loss = loss + l1_loss\n    \n    # åå‘ä¼ æ’­\n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n\n# 3. Dropoutå±‚\nclass MLPWithDropout(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.5):\n        super(MLPWithDropout, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.dropout1 = nn.Dropout(dropout_rate)\n        self.fc2 = nn.Linear(hidden_size, hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n        self.fc3 = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.dropout1(x)  # è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒï¼Œæ¨ç†æ—¶è‡ªåŠ¨å…³é—­\n        x = torch.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n# 4. æ ‡ç­¾å¹³æ»‘\nclass LabelSmoothingLoss(nn.Module):\n    def __init__(self, num_classes, smoothing=0.1):\n        super(LabelSmoothingLoss, self).__init__()\n        self.num_classes = num_classes\n        self.smoothing = smoothing\n        self.confidence = 1.0 - smoothing\n    \n    def forward(self, pred, target):\n        log_probs = torch.nn.functional.log_softmax(pred, dim=1)\n        true_dist = torch.zeros_like(log_probs)\n        true_dist.fill_(self.smoothing / (self.num_classes - 1))\n        true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n        return torch.mean(torch.sum(-true_dist * log_probs, dim=1))\n\n# ä½¿ç”¨ç¤ºä¾‹\nmodel = MLPWithDropout(784, 256, 10, dropout_rate=0.5)\ncriterion = LabelSmoothingLoss(num_classes=10, smoothing=0.1)\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
        }
      ]
    }
  ]
}