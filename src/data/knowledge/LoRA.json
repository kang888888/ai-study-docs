{
  "title": "LoRAï¼ˆLow-Rank Adaptationï¼‰ä½ç§©é€‚åº”å¾®è°ƒ",
  "subtitle": "é€šè¿‡ä½ç§©çŸ©é˜µåˆ†è§£åœ¨å†»ç»“å¤§æ¨¡å‹ä¸»å¹²çš„æƒ…å†µä¸‹æ³¨å…¥å°‘é‡å¯è®­ç»ƒå‚æ•°ï¼Œå®ç°æå…·æ€§ä»·æ¯”çš„å‚æ•°é«˜æ•ˆå¾®è°ƒã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "LoRA æ’å…¥æ³¨æ„åŠ›çŸ©é˜µ",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "LoRA æ’å…¥æ³¨æ„åŠ›çŸ©é˜µ",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "è®­ç»ƒä¸æ¨ç†æµç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "è®­ç»ƒä¸æ¨ç†æµç¨‹",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "å‚æ•°æ•ˆç‡å¯¹æ¯”",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "å‚æ•°æ•ˆç‡å¯¹æ¯”",
                "data": null
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "ä½ç§©åˆ†è§£",
          "formulas": [
            {
              "text": "LoRA å°†æƒé‡æ›´æ–°è¡¨ç¤ºä¸ºï¼š"
            },
            {
              "display": "W = W_0 + \\Delta W, \\quad \\Delta W = B A, \\; rank(A) = rank(B) = r \\ll \\min(d,k)"
            },
            {
              "text": "è®­ç»ƒæ—¶ä»…æ›´æ–° $A,B$ï¼Œæ¨ç†é˜¶æ®µå¯å°†å…¶åˆå¹¶å› $W$ æˆ–ä»¥æ¨¡å—å½¢å¼æ³¨å…¥ã€‚",
              "inline": "A,B"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "ç¼©æ”¾å› å­",
          "formulas": [
            {
              "text": "ä¸ºä¿æŒæ¢¯åº¦ç¨³å®šï¼ŒLoRA å¼•å…¥ç¼©æ”¾ $\\alpha/r$ï¼š",
              "inline": "\\alpha/r"
            },
            {
              "display": "y = W_0 x + \\frac{\\alpha}{r} B A x"
            },
            {
              "text": "å…¶ä¸­ $\\alpha$ æ§åˆ¶æ›´æ–°å¹…åº¦ï¼Œå¸¸ä¸ rank åŒé‡çº§ã€‚",
              "inline": "\\alpha"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ PEFT æ„å»º LoRA é€‚é…å™¨",
          "language": "python",
          "code": "from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import LoraConfig, get_peft_model\n\nbase_model = \"meta-llama/Llama-2-13b-hf\"\ntokenizer = AutoTokenizer.from_pretrained(base_model)\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    load_in_4bit=True,\n    device_map=\"auto\"\n)\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n\n# ä¹‹åå³å¯åƒæ™®é€š SFT ä¸€æ ·ä½¿ç”¨ Trainer/Accelerate è¿›è¡Œè®­ç»ƒ"
        }
      ]
    }
  ]
}