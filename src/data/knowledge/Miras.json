{
  "title": "Miras æ·±åº¦å­¦ä¹ æ¶æ„è®¾è®¡æ¡†æ¶",
  "subtitle": "é€šç”¨æ¡†æ¶ï¼Œé‡æ–°æ¦‚å¿µåŒ–ç¥ç»æ¶æ„ä¸ºå…³è”è®°å¿†æ¨¡å—",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "Miras æ˜¯ Google Research æå‡ºçš„æ·±åº¦å­¦ä¹ æ¶æ„è®¾è®¡é€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨è¶…è¶Šç°æœ‰çš„ Transformer æ¨¡å‹ã€‚è¯¥æ¡†æ¶å—äººç±»è®¤çŸ¥ç°è±¡ä¸­çš„æ³¨æ„åŠ›åå·®ï¼ˆAttention Biasï¼‰å¯å‘ï¼Œå°†ç¥ç»æ¶æ„ï¼ˆåŒ…æ‹¬ Transformersã€Titans å’Œç°ä»£çº¿æ€§é€’å½’ç¥ç»ç½‘ç»œï¼‰é‡æ–°æ¦‚å¿µåŒ–ä¸ºå…³è”è®°å¿†æ¨¡å—ï¼ˆAssociative Memory Modulesï¼‰ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "ç»Ÿä¸€æ¡†æ¶ï¼šç»Ÿä¸€ç†è§£ç¥ç»æ¶æ„ä¸ºå…³è”è®°å¿†æ¨¡å—",
            "æ³¨æ„åŠ›åå·®ï¼šé€šè¿‡æ³¨æ„åŠ›åå·®ä¼˜åŒ–ä¿¡æ¯æ£€ç´¢",
            "æ¶æ„æŒ‡å¯¼ï¼šæŒ‡å¯¼æ–°æ¶æ„çš„è®¾è®¡å’Œä¼˜åŒ–",
            "ç†è®ºç»Ÿä¸€ï¼šç»Ÿä¸€ç†è§£Transformersã€Titansç­‰æ¶æ„",
            "æ€§èƒ½æå‡ï¼šåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šç°æœ‰æ¶æ„"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "å…³è”è®°å¿†æ¶æ„ã€æ³¨æ„åŠ›åå·®ã€è®°å¿†ç»„ç»‡ã€ä¿¡æ¯æ£€ç´¢ã€æ¶æ„è®¾è®¡æ¡†æ¶"
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å››ä¸ªå…³é”®é€‰æ‹©",
      "content": [
        {
          "type": "tech-box",
          "content": "1. å…³è”è®°å¿†æ¶æ„ï¼ˆAssociative Memory Architectureï¼‰\n                    å®šä¹‰æ¨¡å‹å¦‚ä½•å­˜å‚¨å’Œæ£€ç´¢ä¿¡æ¯ï¼Œå†³å®šè®°å¿†çš„ç»„ç»‡æ–¹å¼ï¼ˆæ‰å¹³/å±‚æ¬¡/åŠ¨æ€ï¼‰"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "æ¶æ„è®¾è®¡ï¼šæŒ‡å¯¼æ–°æ¶æ„çš„è®¾è®¡ï¼Œç†è§£ç°æœ‰æ¶æ„çš„åŸç†\n                    æ¨¡å‹ä¼˜åŒ–ï¼šä¼˜åŒ–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ”¹è¿›è®°å¿†ç®¡ç†\n                    ä»»åŠ¡é€‚é…ï¼šæ ¹æ®ä»»åŠ¡è®¾è®¡åˆé€‚çš„æ¶æ„ï¼Œé€‰æ‹©æœ€ä¼˜çš„æ³¨æ„åŠ›åå·®\n                    ç†è®ºç ”ç©¶ï¼šç»Ÿä¸€ç†è§£ç¥ç»æ¶æ„ï¼Œæ¢ç´¢è®°å¿†å’Œæ³¨æ„åŠ›çš„æœ¬è´¨"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "MirasDiagram",
              "caption": "Mirasæ¶æ„å›¾",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "Mirasæ¶æ„å›¾"
              }
            },
            {
              "type": "svg-d3",
              "component": "MirasDiagram",
              "caption": "Mirasç»„ä»¶è¯¦è§£",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "Mirasç»„ä»¶è¯¦è§£"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "å…³è”è®°å¿†ç³»ç»Ÿ",
          "formulas": [
            {
              "text": "å…³è”è®°å¿†ç³»ç»Ÿå¯ä»¥è¡¨ç¤ºä¸ºï¼š"
            },
            {
              "display": "M = \\{ (k_i, v_i) \\}_{i=1}^{N}"
            },
            {
              "text": "å…¶ä¸­ï¼š"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "æ£€ç´¢è¿‡ç¨‹",
          "formulas": [
            {
              "text": "æ£€ç´¢è¾“å‡ºï¼š"
            },
            {
              "display": "o = \\sum_{i=1}^{N} \\alpha_i \\cdot v_i"
            },
            {
              "text": "å…¶ä¸­æ³¨æ„åŠ›æƒé‡ï¼š"
            },
            {
              "display": "\\alpha_i = \\text{softmax}(\\text{score}(q, k_i) + \\text{bias}_i)"
            },
            {
              "text": "å…¶ä¸­ $\\text{bias}_i$ æ˜¯æ³¨æ„åŠ›åå·®ï¼Œå¯ä»¥ï¼š",
              "inline": "\\text{bias}_i"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’¡ åŸºäº Miras çš„æ¨¡å‹",
      "content": [
        {
          "type": "tech-box",
          "content": "Monetaï¼šé«˜æ•ˆçš„å…³è”è®°å¿†æ¶æ„ï¼Œä¼˜åŠ¿æ˜¯å¿«é€Ÿæ£€ç´¢å’Œæ›´æ–°ï¼Œåº”ç”¨äºå®æ—¶æ¨ç†ä»»åŠ¡"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ€§èƒ½è¡¨ç°",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "è¯­è¨€å»ºæ¨¡ï¼šè¶…è¶Š Transformers å’Œç°ä»£çº¿æ€§é€’å½’æ¨¡å‹\n                    å¸¸è¯†æ¨ç†ï¼šåˆ©ç”¨å…³è”è®°å¿†è¿›è¡Œæ¨ç†ï¼Œæ›´å¥½çš„ä¿¡æ¯æ£€ç´¢èƒ½åŠ›\n                    é«˜å¬å›ç‡ä»»åŠ¡ï¼šéœ€è¦ç²¾ç¡®æ£€ç´¢çš„ä»»åŠ¡ï¼Œåˆ©ç”¨æ³¨æ„åŠ›åå·®ä¼˜åŒ–æ£€ç´¢"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "å…³è”è®°å¿†æ¨¡å—çš„ç®€åŒ–å®ç°",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass AssociativeMemory(nn.Module):\n    \"\"\"å…³è”è®°å¿†æ¨¡å—\"\"\"\n    def __init__(self, d_model, memory_size):\n        super(AssociativeMemory, self).__init__()\n        self.d_model = d_model\n        self.memory_size = memory_size\n        \n        # è®°å¿†å­˜å‚¨ï¼šé”®å€¼å¯¹\n        self.register_buffer('keys', torch.randn(memory_size, d_model))\n        self.register_buffer('values', torch.randn(memory_size, d_model))\n        \n        # æ³¨æ„åŠ›åå·®ï¼ˆå¯å­¦ä¹ ï¼‰\n        self.bias = nn.Parameter(torch.zeros(memory_size))\n    \n    def forward(self, query):\n        \"\"\"\n        å‚æ•°:\n            query: [batch_size, d_model] æŸ¥è¯¢å‘é‡\n        è¿”å›:\n            output: [batch_size, d_model] æ£€ç´¢ç»“æœ\n        \"\"\"\n        batch_size = query.shape[0]\n        \n        # è®¡ç®—æŸ¥è¯¢ä¸é”®çš„ç›¸ä¼¼åº¦\n        scores = torch.matmul(query, self.keys.t())  # [batch_size, memory_size]\n        \n        # æ·»åŠ æ³¨æ„åŠ›åå·®\n        scores = scores + self.bias.unsqueeze(0)\n        \n        # è®¡ç®—æ³¨æ„åŠ›æƒé‡\n        attention_weights = F.softmax(scores, dim=-1)  # [batch_size, memory_size]\n        \n        # åŠ æƒæ±‚å’Œå€¼\n        output = torch.matmul(attention_weights, self.values)  # [batch_size, d_model]\n        \n        return output\n\n# ä½¿ç”¨ç¤ºä¾‹\nif __name__ == \"__main__\":\n    memory = AssociativeMemory(d_model=512, memory_size=1000)\n    query = torch.randn(2, 512)\n    output = memory(query)\n    print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")  # [2, 512]"
        }
      ]
    }
  ]
}