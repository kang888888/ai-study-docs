{
  "title": "ALiBi (Attention with Linear Biases) 注意力线性偏置",
  "subtitle": "无需额外参数的位置编码方法，通过线性偏置实现位置感知",
  "content": [
    {
      "type": "section",
      "title": "📖 核心概念",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "ALiBi是一种无需学习位置嵌入的位置编码方法，通过在注意力分数中添加线性偏置来实现位置感知。它通过给距离更远的token对添加更大的负偏置，自然地让模型关注更近的token，实现了高效的位置编码。"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "🌟 核心特点",
      "content": [
        {
          "type": "features",
          "items": [
            "零参数：无需额外的位置嵌入参数，节省模型容量",
            "线性偏置：使用简单的线性偏置函数，计算开销极小",
            "外推能力：训练后可直接处理更长序列，无需微调",
            "实现简单：只需在注意力计算中添加偏置项",
            "性能优秀：在多个任务上达到或超越传统位置编码"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "⚙️ 关键技术",
      "content": [
        {
          "type": "tech-box",
          "content": "线性偏置函数、注意力掩码、位置感知机制、外推策略"
        }
      ]
    },
    {
      "type": "section",
      "title": "🚀 应用场景",
      "content": [
        {
          "type": "app-box",
          "content": "长文本生成、代码补全、文档摘要等需要位置感知但希望减少参数量的场景"
        }
      ]
    },
    {
      "type": "section",
      "title": "📐 数学原理",
      "content": [
        {
          "type": "math-box",
          "title": "ALiBi偏置公式",
          "formulas": [
            {
              "text": "在注意力分数计算中添加线性偏置："
            },
            {
              "text": "attention_{i,j} = q_i^T k_j - m \\cdot |i - j|"
            },
            {
              "text": "其中m是偏置斜率，根据注意力头数动态调整，|i-j|是位置距离"
            }
          ]
        }
      ]
    }
  ]
}
