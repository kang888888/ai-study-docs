{
  "title": "Softmaxå‡½æ•°",
  "subtitle": "å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "Softmaxå‡½æ•°å°†ä¸€ç»„å®æ•°ï¼ˆlogitsï¼‰è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—æ‰€æœ‰è¾“å‡ºçš„å’Œä¸º1ï¼Œä¸”æ¯ä¸ªè¾“å‡ºéƒ½åœ¨(0,1)åŒºé—´å†…ã€‚å®ƒæ˜¯å¤šåˆ†ç±»é—®é¢˜ä¸­è¾“å‡ºå±‚çš„æ ‡å‡†æ¿€æ´»å‡½æ•°ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "æ¦‚ç‡å½’ä¸€åŒ–ï¼šå°†è¾“å‡ºè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ",
            "å¤šåˆ†ç±»æ ‡å‡†ï¼šå¤šåˆ†ç±»ä»»åŠ¡çš„è¾“å‡ºå±‚æ ‡å‡†é€‰æ‹©",
            "å¯å¯¼æ€§ï¼šå¤„å¤„å¯å¯¼ï¼Œé€‚åˆåå‘ä¼ æ’­",
            "æ•°å€¼ç¨³å®šæ€§ï¼šéœ€è¦ç‰¹æ®Šå¤„ç†é¿å…æº¢å‡º",
            "æ³¨æ„åŠ›æœºåˆ¶ï¼šTransformeræ³¨æ„åŠ›è®¡ç®—çš„æ ¸å¿ƒ"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦è¡¨è¾¾",
      "content": [
        {
          "type": "math-box",
          "title": "Softmaxå‡½æ•°å®šä¹‰",
          "formulas": [
            {
              "text": "Softmaxå‡½æ•°å®šä¹‰ä¸ºï¼š"
            },
            {
              "display": "\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n}e^{x_j}}"
            },
            {
              "text": "æ•°å€¼ç¨³å®šå®ç°ï¼ˆå‡å»æœ€å¤§å€¼ï¼‰ï¼š"
            },
            {
              "display": "\\text{softmax}(x_i) = \\frac{e^{x_i - \\max(x)}}{\\sum_{j=1}^{n}e^{x_j - \\max(x)}}"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "æ€§è´¨",
          "formulas": [
            {
              "text": "é‡è¦æ€§è´¨ï¼š"
            },
            {
              "text": "- è¾“å‡ºå’Œä¸º1ï¼š$\\sum_{i=1}^{n}\\text{softmax}(x_i) = 1$"
            },
            {
              "text": "- è¾“å‡ºèŒƒå›´ï¼š$(0, 1)$ï¼Œæ¯ä¸ªè¾“å‡ºéƒ½æ˜¯æ­£æ•°"
            },
            {
              "text": "- å•è°ƒæ€§ï¼š$x_i > x_j \\Rightarrow \\text{softmax}(x_i) > \\text{softmax}(x_j)$"
            },
            {
              "text": "- å¹³ç§»ä¸å˜æ€§ï¼š$\\text{softmax}(x + c) = \\text{softmax}(x)$"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "æ¢¯åº¦",
          "formulas": [
            {
              "text": "Softmaxçš„æ¢¯åº¦ï¼ˆç”¨äºäº¤å‰ç†µæŸå¤±ï¼‰ï¼š"
            },
            {
              "display": "\\frac{\\partial \\text{softmax}(x_i)}{\\partial x_j} = \\begin{cases} \\text{softmax}(x_i)(1 - \\text{softmax}(x_i)) & i = j \\\\ -\\text{softmax}(x_i)\\text{softmax}(x_j) & i \\neq j \\end{cases}"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ ç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "æ¦‚ç‡è§£é‡Šï¼šè¾“å‡ºå¯ä»¥è§£é‡Šä¸ºç±»åˆ«æ¦‚ç‡",
            "å½’ä¸€åŒ–ï¼šè‡ªåŠ¨å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ",
            "å¯å¾®æ€§ï¼šå¤„å¤„å¯å¯¼ï¼Œé€‚åˆåå‘ä¼ æ’­",
            "æ•°å€¼ç¨³å®šæ€§ï¼šéœ€è¦å‡å»æœ€å¤§å€¼é¿å…æº¢å‡º",
            "å¤šåˆ†ç±»æ ‡å‡†ï¼šå¤šåˆ†ç±»é—®é¢˜çš„æ ‡å‡†è¾“å‡ºå±‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š å‡½æ•°å¯è§†åŒ–",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "MathFunctionDiagram",
              "caption": "Softmaxå‡½æ•°å¯è§†åŒ–",
              "width": 1000,
              "height": 600,
              "interactive": true,
              "props": {
                "type": "normalization",
                "title": "Softmaxå‡½æ•°å¯è§†åŒ–",
                "function": "softmax"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "æ¦‚ç‡å½’ä¸€åŒ–ã€å¤šåˆ†ç±»è¾“å‡ºã€æ•°å€¼ç¨³å®šæ€§ã€æ³¨æ„åŠ›è®¡ç®—ã€æ¸©åº¦ç¼©æ”¾"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "å¤šåˆ†ç±»è¾“å‡ºå±‚ã€æ³¨æ„åŠ›æœºåˆ¶ã€æ¦‚ç‡åˆ†å¸ƒç”Ÿæˆã€è¯­è¨€æ¨¡å‹çš„è¯æ±‡è¡¨è¾“å‡º"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "Softmaxå®ç°ä¸ä½¿ç”¨",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\n# 1. åŸºç¡€å®ç°ï¼ˆæ•°å€¼ä¸ç¨³å®šï¼‰\ndef softmax_naive(x):\n    exp_x = np.exp(x)\n    return exp_x / np.sum(exp_x)\n\n# 2. æ•°å€¼ç¨³å®šå®ç°\ndef softmax_stable(x):\n    x = x - np.max(x)  # å‡å»æœ€å¤§å€¼\n    exp_x = np.exp(x)\n    return exp_x / np.sum(exp_x)\n\n# 3. PyTorchå®ç°\nlogits = torch.tensor([2.0, 1.0, 0.1])\nprobs = F.softmax(logits, dim=0)\nprint(f\"Logits: {logits}\")\nprint(f\"Probabilities: {probs}\")\nprint(f\"Sum: {probs.sum()}\")  # åº”è¯¥ä¸º1.0\n\n# 4. åœ¨å¤šåˆ†ç±»ç½‘ç»œä¸­ä½¿ç”¨\nclass MultiClassClassifier(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(MultiClassClassifier, self).__init__()\n        self.fc = nn.Linear(input_size, num_classes)\n    \n    def forward(self, x):\n        logits = self.fc(x)\n        probs = F.softmax(logits, dim=1)  # åœ¨ç±»åˆ«ç»´åº¦ä¸Šsoftmax\n        return probs\n\n# 5. ä¸äº¤å‰ç†µæŸå¤±ç»“åˆä½¿ç”¨\nlogits = torch.randn(32, 10)  # [batch_size, num_classes]\ntargets = torch.randint(0, 10, (32,))  # ç±»åˆ«æ ‡ç­¾\n\n# æ–¹æ³•1ï¼šåˆ†åˆ«è®¡ç®—softmaxå’Œäº¤å‰ç†µ\nprobs = F.softmax(logits, dim=1)\nloss1 = F.cross_entropy(logits, targets)  # æ¨èï¼šå†…éƒ¨ä¼šè®¡ç®—softmax\n\n# æ–¹æ³•2ï¼šç›´æ¥ä½¿ç”¨log_softmaxï¼ˆæ•°å€¼æ›´ç¨³å®šï¼‰\nlog_probs = F.log_softmax(logits, dim=1)\nloss2 = F.nll_loss(log_probs, targets)\n\nprint(f\"Loss1: {loss1.item():.4f}\")\nprint(f\"Loss2: {loss2.item():.4f}\")\n\n# 6. æ¸©åº¦ç¼©æ”¾ï¼ˆTemperature Scalingï¼‰\ndef softmax_with_temperature(logits, temperature=1.0):\n    return F.softmax(logits / temperature, dim=-1)\n\n# æ¸©åº¦è¶Šé«˜ï¼Œåˆ†å¸ƒè¶Šå¹³æ»‘\nlogits = torch.tensor([2.0, 1.0, 0.1])\nprobs_t1 = softmax_with_temperature(logits, temperature=1.0)\nprobs_t2 = softmax_with_temperature(logits, temperature=2.0)\nprint(f\"T=1.0: {probs_t1}\")\nprint(f\"T=2.0: {probs_t2}\")"
        }
      ]
    }
  ]
}