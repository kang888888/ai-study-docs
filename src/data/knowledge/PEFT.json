{
  "title": "PEFTï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•æ—",
  "subtitle": "é€šè¿‡ Adapterã€Prefix-Tuningã€LoRAã€IA3ã€BitFit ç­‰æ–¹æ³•å†»ç»“å¤§éƒ¨åˆ†å‚æ•°ï¼Œä»…è®­ç»ƒå°å‹é™„åŠ æ¨¡å—ï¼Œå®ç°â€œä½èµ„æºå¯æ‰©å±•â€ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuningï¼‰æ˜¯ä¸€ç±»åªè®­ç»ƒå°‘é‡å‚æ•°çš„å¾®è°ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬LoRAã€Adapterç­‰ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "å‚æ•°é«˜æ•ˆï¼šåªè®­ç»ƒå°‘é‡å‚æ•°",
            "æ–¹æ³•å¤šæ ·ï¼šLoRAã€Adapterç­‰å¤šç§æ–¹æ³•",
            "çµæ´»é€‰æ‹©ï¼šå¯æ ¹æ®éœ€æ±‚é€‰æ‹©æ–¹æ³•",
            "æˆæœ¬é™ä½ï¼šå‡å°‘è®­ç»ƒå’Œå­˜å‚¨æˆæœ¬",
            "ç”Ÿæ€ä¸°å¯Œï¼šå¤šç§å®ç°å’Œå·¥å…·"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "å‚æ•°é«˜æ•ˆã€LoRAã€Adapterã€Prefix Tuningã€Prompt Tuning"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "å‚æ•°é«˜æ•ˆå¾®è°ƒã€å¤šæ–¹æ³•é€‰æ‹©ã€èµ„æºä¼˜åŒ–ã€å¿«é€Ÿé€‚é…"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æ–¹æ³•å®¶æ—",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "æ–¹æ³•å®¶æ—"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "Adapter ç»“æ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "Adapter ç»“æ„"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "Prompt Tuning",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "Prompt Tuning"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "Adapter",
          "formulas": [
            {
              "text": "Adapter åœ¨å±‚å†…æ·»åŠ ç“¶é¢ˆç»“æ„ï¼š"
            },
            {
              "display": "h' = h + W_{up} \\sigma(W_{down} h)"
            },
            {
              "text": "$W_{down} \\in \\mathbb{R}^{d \\times r}, W_{up} \\in \\mathbb{R}^{r \\times d}$ï¼Œä»…è®­ç»ƒè¿™ä¸¤å±‚ã€‚",
              "inline": "W_{down} \\in \\mathbb{R}^{d \\times r}, W_{up} \\in \\mathbb{R}^{r \\times d}"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "Prefix/Prompt Tuning",
          "formulas": [
            {
              "text": "åœ¨å¤šå¤´æ³¨æ„åŠ›å‰æ³¨å…¥è™šæ‹Ÿ tokenï¼š"
            },
            {
              "display": "\\text{Attention}(Q, K, V) \\Rightarrow \\text{Attention}([Q; Q_p], [K; K_p], [V; V_p])"
            },
            {
              "text": "$Q_p,K_p,V_p$ ä¸ºå¯è®­ç»ƒå‰ç¼€å‘é‡ã€‚",
              "inline": "Q_p,K_p,V_p"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "PEFT ç»Ÿä¸€æ¥å£",
          "language": "python",
          "code": "from peft import (LoraConfig, PrefixTuningConfig, PromptTuningConfig,\n                   get_peft_model, TaskType)\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nbase_model = \"google/flan-t5-large\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(base_model)\n\nlora_cfg = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    target_modules=[\"q\", \"v\"]\n)\nmodel = get_peft_model(model, lora_cfg)\n\n# ä¹Ÿå¯åˆ‡æ¢ä¸º Prefix Tuning\n# prefix_cfg = PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, num_virtual_tokens=30)\n# model = get_peft_model(model, prefix_cfg)"
        }
      ]
    }
  ]
}