{
  "title": "å·¥ç¨‹å®žè·µ",
  "subtitle": "Minimindé¡¹ç›®ä¸­çš„è°ƒè¯•æŠ€å·§ã€æ€§èƒ½åˆ†æžã€æœ€ä½³å®žè·µç­‰å·¥ç¨‹ç»éªŒã€‚",
  "content": [
    {
      "type": "section",
      "title": "ðŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "å·¥ç¨‹å®žè·µæ˜¯å¤§æ¨¡åž‹å¼€å‘ä¸­çš„æœ€ä½³å®žè·µï¼ŒåŒ…æ‹¬ä»£ç è§„èŒƒã€ç‰ˆæœ¬æŽ§åˆ¶ã€æµ‹è¯•ã€éƒ¨ç½²ç­‰ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ðŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "ä»£ç è§„èŒƒï¼šéµå¾ªä»£ç è§„èŒƒ",
            "ç‰ˆæœ¬æŽ§åˆ¶ï¼šä½¿ç”¨ç‰ˆæœ¬æŽ§åˆ¶",
            "æµ‹è¯•å®Œå–„ï¼šå®Œå–„çš„æµ‹è¯•ä½“ç³»",
            "æ–‡æ¡£å®Œå–„ï¼šå®Œå–„çš„æ–‡æ¡£",
            "æŒç»­æ”¹è¿›ï¼šæŒç»­æ”¹è¿›å®žè·µ"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "ä»£ç è§„èŒƒã€ç‰ˆæœ¬æŽ§åˆ¶ã€æµ‹è¯•ã€æ–‡æ¡£ã€CI/CD"
        }
      ]
    },
    {
      "type": "section",
      "title": "ðŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "å¼€å‘è§„èŒƒã€ä»£ç è´¨é‡ã€é¡¹ç›®ç®¡ç†ã€æœ€ä½³å®žè·µ"
        }
      ]
    },
    {
      "type": "section",
      "title": "ðŸ“Š æž¶æž„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "å·¥ç¨‹å®žè·µæµç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "å·¥ç¨‹å®žè·µæµç¨‹"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "è°ƒè¯•ä¸Žä¼˜åŒ–å·¥å…·",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "è°ƒè¯•ä¸Žä¼˜åŒ–å·¥å…·"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ðŸ’» ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "è°ƒè¯•æŠ€å·§",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\n\ndef debug_model(model, input_data):\n    \"\"\"æ¨¡åž‹è°ƒè¯•å·¥å…·\"\"\"\n    # 1. æ£€æŸ¥æ¢¯åº¦\n    def check_gradients(model):\n        for name, param in model.named_parameters():\n            if param.grad is not None:\n                grad_norm = param.grad.norm().item()\n                if grad_norm > 100 or grad_norm < 1e-6:\n                    print(f\"Warning: {name} has abnormal gradient norm: {grad_norm}\")\n    \n    # 2. æ£€æŸ¥æ¿€æ´»å€¼\n    def check_activations(model, input_data):\n        hooks = []\n        def hook_fn(name):\n            def hook(module, input, output):\n                if isinstance(output, torch.Tensor):\n                    if torch.isnan(output).any():\n                        print(f\"NaN detected in {name}\")\n                    if torch.isinf(output).any():\n                        print(f\"Inf detected in {name}\")\n            return hook\n        \n        for name, module in model.named_modules():\n            hooks.append(module.register_forward_hook(hook_fn(name)))\n        \n        _ = model(input_data)\n        \n        for hook in hooks:\n            hook.remove()"
        },
        {
          "type": "code-box",
          "title": "æ€§èƒ½åˆ†æž",
          "language": "python",
          "code": "import torch\nfrom torch.profiler import profile, record_function, ProfilerActivity\n\ndef profile_training(model, dataloader):\n    \"\"\"è®­ç»ƒæ€§èƒ½åˆ†æž\"\"\"\n    with profile(\n        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n        record_shapes=True,\n        profile_memory=True\n    ) as prof:\n        with record_function(\"training_step\"):\n            for batch in dataloader:\n                outputs = model(batch['input_ids'])\n                loss = compute_loss(outputs, batch['labels'])\n                loss.backward()\n                break  # åªåˆ†æžä¸€ä¸ªbatch\n    \n    # æ‰“å°åˆ†æžç»“æžœ\n    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n    \n    # å¯¼å‡ºChrome trace\n    prof.export_chrome_trace(\"trace.json\")"
        }
      ]
    }
  ]
}