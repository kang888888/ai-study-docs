{
  "title": "Unslothï¼šé¢å‘å¼€æºå¤§æ¨¡å‹çš„æè‡´é«˜æ•ˆå¾®è°ƒæ¡†æ¶",
  "subtitle": "é€šè¿‡å®šåˆ¶åŒ– CUDA Kernelã€Flash Attentionã€è‡ªåŠ¨é‡åŒ–ä¸ LoRA é¢„è®¾ï¼Œå°†è®­ç»ƒé€Ÿåº¦æå‡ 2-5 å€ï¼Œæ˜¾å­˜å ç”¨ä¸‹é™ 80%ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "Unslothæ˜¯ä¼˜åŒ–çš„å¾®è°ƒæ¡†æ¶ï¼Œé€šè¿‡å†…å­˜ä¼˜åŒ–å’Œè®¡ç®—ä¼˜åŒ–ï¼Œå®ç°2-5å€çš„è®­ç»ƒåŠ é€Ÿã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "è®­ç»ƒåŠ é€Ÿï¼š2-5å€è®­ç»ƒé€Ÿåº¦æå‡",
            "å†…å­˜ä¼˜åŒ–ï¼šä¼˜åŒ–çš„å†…å­˜ç®¡ç†",
            "æ˜“äºé›†æˆï¼šä¸ç°æœ‰æ¡†æ¶å…¼å®¹",
            "æ€§èƒ½ä¿æŒï¼šä¸æŸå¤±æ¨¡å‹æ€§èƒ½",
            "æŒç»­ä¼˜åŒ–ï¼šä¸æ–­æ”¹è¿›æ€§èƒ½"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "å†…å­˜ä¼˜åŒ–ã€è®¡ç®—ä¼˜åŒ–ã€è®­ç»ƒåŠ é€Ÿã€æ¡†æ¶ä¼˜åŒ–"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "è®­ç»ƒåŠ é€Ÿã€å¿«é€Ÿè¿­ä»£ã€èµ„æºä¼˜åŒ–ã€æ€§èƒ½æå‡"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æ¨¡å—åŒ–æ¶æ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "æ¨¡å—åŒ–æ¶æ„"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æ€§èƒ½åŠ é€Ÿæ•ˆæœ",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "æ€§èƒ½åŠ é€Ÿæ•ˆæœ"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "å·¥ä½œæµ",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "å·¥ä½œæµ"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦/ç®—æ³•è¦ç‚¹",
      "content": [
        {
          "type": "math-box",
          "title": "æ˜¾å­˜åŠ é€Ÿæ¯”ä¼°ç®—",
          "formulas": [
            {
              "text": "Unsloth é€šè¿‡ 4bit é‡åŒ– + LoRA å°†æ˜¾å­˜é™è‡³ï¼š"
            },
            {
              "display": "\\text{VRAM}_{\\text{QLoRA}} \\approx \\frac{n_{\\text{params}} \\times 4}{8} + 2 \\times n_{\\text{LoRA}} \\times bytes_{\\text{fp16}}"
            },
            {
              "text": "å…¶ä¸­ $n_{\\text{LoRA}} = 2 \\cdot d \\cdot r$ï¼Œé€šå¸¸ä»…å åŸæ¨¡å‹ 0.5%~1%ã€‚",
              "inline": "n_{\\text{LoRA}} = 2 \\cdot d \\cdot r"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "ååé‡ä¼°ç®—",
          "formulas": [
            {
              "text": "é…åˆ Flash Attentionï¼Œè®¡ç®—å¤æ‚åº¦è¿‘ä¼¼ï¼š"
            },
            {
              "display": "\\mathcal{O}(n d^2) \\rightarrow \\mathcal{O}\\bigg(\\frac{n d^2}{\\sqrt{B}}\\bigg)"
            },
            {
              "text": "$B$ ä¸ºå¹¶è¡Œ block æ•°ï¼Œä½“ç°å¤šæµæ‰§è¡Œå¸¦æ¥çš„ååæå‡ã€‚",
              "inline": "B"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "Python API ä¸€é”®å¾®è°ƒ",
          "language": "python",
          "code": "from unsloth import FastLanguageModel\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"meta-llama/Llama-3-8b\",\n    max_seq_length=4096,\n    load_in_4bit=True,\n)\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=64,\n    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n    lora_alpha=64,\n    lora_dropout=0.05\n)\n\ntrainer = FastLanguageModel.get_trainer(\n    model=model,\n    tokenizer=tokenizer,\n    dataset=\"unsloth/guanaco-bilingual\",\n    logging_steps=10,\n    learning_rate=2e-4,\n    num_train_epochs=3\n)\n\ntrainer.train()"
        }
      ]
    }
  ]
}