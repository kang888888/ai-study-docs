{
  "title": "FP8 混合精度训练",
  "subtitle": "FP8 混合精度训练技术",
  "content": [
    {
      "type": "section",
      "title": "📖 核心概念",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "FP8 混合精度训练是 DeepSeek-V3 及其 2026 年相关论文中披露的分布式训练协同优化技术。该技术在有限资源（如仅 2048 块 H800）下实现超大规模模型训练，显著降低显存占用。FP8 是 8 位浮点数格式，相比 FP16/BF16 进一步降低显存和计算开销，是软硬一体协同优化的关键组件。"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "🌟 核心特点",
      "content": [
        {
          "type": "features",
          "items": [
            "显存优化：显著降低显存占用，支持更大模型训练",
            "资源受限场景：在有限资源下实现超大规模模型训练",
            "计算效率：相比 FP16/BF16 进一步降低计算开销",
            "8 位精度：使用 FP8 浮点数格式实现高效训练",
            "软硬协同：作为软硬一体协同优化的关键组件"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "⚙️ 关键技术",
      "content": [
        {
          "type": "tech-box",
          "content": "FP8 浮点数格式、混合精度训练、显存优化、有限资源训练、超大规模模型训练、软硬一体优化"
        }
      ]
    },
    {
      "type": "section",
      "title": "🚀 应用场景",
      "content": [
        {
          "type": "app-box",
          "content": "资源受限的大规模模型训练、显存优化需求、超大规模模型训练、有限算力环境、分布式训练协同优化、软硬一体优化场景"
        }
      ]
    }
  ]
}
