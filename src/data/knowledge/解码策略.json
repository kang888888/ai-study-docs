{
  "title": "è§£ç ç­–ç•¥ï¼ˆDecoding Strategiesï¼‰",
  "subtitle": "å¤§è¯­è¨€æ¨¡å‹ä¸­æ–‡æœ¬ç”Ÿæˆçš„å…³é”®æŠ€æœ¯ï¼Œç›´æ¥å½±å“ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ã€å¤šæ ·æ€§å’Œå¯æ§æ€§ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "è§£ç ç­–ç•¥æ˜¯æ§åˆ¶è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬è´ªå¿ƒæœç´¢ã€æŸæœç´¢ã€é‡‡æ ·ç­‰ï¼Œå½±å“ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "å¤šæ ·æ€§æ§åˆ¶ï¼šå¹³è¡¡ç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§",
            "å‚æ•°å¯è°ƒï¼šæ¸©åº¦ã€top-kã€top-pç­‰å‚æ•°",
            "ä»»åŠ¡ç›¸å…³ï¼šä¸åŒä»»åŠ¡é€‚åˆä¸åŒç­–ç•¥",
            "è®¡ç®—å¼€é”€ï¼šä¸åŒç­–ç•¥è®¡ç®—æˆæœ¬ä¸åŒ",
            "æ•ˆæœå½±å“ï¼šç›´æ¥å½±å“ç”Ÿæˆæ–‡æœ¬è´¨é‡"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "è´ªå¿ƒæœç´¢ã€æŸæœç´¢ã€é‡‡æ ·ã€æ¸©åº¦ç¼©æ”¾ã€top-k/top-pé‡‡æ ·"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "æ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿã€åˆ›æ„å†™ä½œã€ä»£ç ç”Ÿæˆã€ä»»åŠ¡ç‰¹å®šç”Ÿæˆ"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "è§£ç ç­–ç•¥å¯¹æ¯”",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "concept",
                "title": "è§£ç ç­–ç•¥å¯¹æ¯”"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "è§£ç ç­–ç•¥æ•ˆæœ",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "concept",
                "title": "è§£ç ç­–ç•¥æ•ˆæœ"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ä¸åŒè§£ç ç­–ç•¥ç”Ÿæˆæ–‡æœ¬",
          "language": "python",
          "code": "from transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"microsoft/DialoGPT-medium\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\nprompt = \"Hello, how are you?\"\n\n# è´ªå¿ƒæœç´¢\noutputs_greedy = model.generate(\n    tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"],\n    max_length=100,\n    do_sample=False,\n    num_beams=1\n)\n\n# æŸæœç´¢\noutputs_beam = model.generate(\n    tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"],\n    max_length=100,\n    do_sample=False,\n    num_beams=4\n)\n\n# æ ¸é‡‡æ ·\noutputs_nucleus = model.generate(\n    tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"],\n    max_length=100,\n    do_sample=True,\n    top_p=0.9,\n    temperature=0.7\n)"
        }
      ]
    }
  ]
}