{
  "title": "HuggingFace Hub",
  "subtitle": "æ¨¡å‹ã€æ•°æ®é›†ç®¡ç†ä¸ Spaces éƒ¨ç½²å¹³å°",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "HuggingFace Hub æ˜¯ä¸€ä¸ªæ¨¡å‹ã€æ•°æ®é›†å’Œæ¼”ç¤ºåº”ç”¨ï¼ˆSpacesï¼‰çš„æ‰˜ç®¡å¹³å°ã€‚å®ƒæä¾›äº†ç‰ˆæœ¬ç®¡ç†ã€åä½œåŠŸèƒ½ã€è‡ªåŠ¨æ¨ç†APIï¼Œè®©AIå¼€å‘è€…å¯ä»¥è½»æ¾åˆ†äº«ã€å‘ç°å’Œä½¿ç”¨æ¨¡å‹å’Œæ•°æ®é›†ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "æ¨¡å‹æ‰˜ç®¡ï¼šå…è´¹æ‰˜ç®¡å’Œåˆ†äº«æ¨¡å‹ï¼Œæ”¯æŒç‰ˆæœ¬ç®¡ç†",
            "æ•°æ®é›†ç®¡ç†ï¼šä¸Šä¼ ã€ç‰ˆæœ¬åŒ–å’Œåˆ†äº«æ•°æ®é›†",
            "Spaceséƒ¨ç½²ï¼šä¸€é”®éƒ¨ç½²äº¤äº’å¼æ¼”ç¤ºåº”ç”¨",
            "è‡ªåŠ¨æ¨ç†APIï¼šä¸ºæ¨¡å‹è‡ªåŠ¨ç”Ÿæˆæ¨ç†API",
            "ç‰ˆæœ¬æ§åˆ¶ï¼šç±»ä¼¼Gitçš„ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿ",
            "åä½œåŠŸèƒ½ï¼šæ”¯æŒå›¢é˜Ÿåä½œå’Œæƒé™ç®¡ç†",
            "æ¨¡å‹å¡ç‰‡ï¼šè‡ªåŠ¨ç”Ÿæˆæ¨¡å‹æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜",
            "ç¤¾åŒºç”Ÿæ€ï¼šåºå¤§çš„æ¨¡å‹å’Œæ•°æ®é›†åº“"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "Git LFSã€ç‰ˆæœ¬ç®¡ç†ã€è‡ªåŠ¨æ¨ç†APIã€Gradio/Streamlité›†æˆã€æ¨¡å‹å¡ç‰‡ã€æƒé™ç®¡ç†"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "æ¨¡å‹åˆ†äº«ï¼šå°†è®­ç»ƒå¥½çš„æ¨¡å‹åˆ†äº«ç»™ç¤¾åŒº\n                    æ¨¡å‹å‘ç°ï¼šæŸ¥æ‰¾å’Œä½¿ç”¨ä»–äººè®­ç»ƒçš„æ¨¡å‹\n                    æ•°æ®é›†å…±äº«ï¼šåˆ†äº«å’Œè·å–æ•°æ®é›†\n                    æ¼”ç¤ºéƒ¨ç½²ï¼šå¿«é€Ÿéƒ¨ç½²æ¨¡å‹æ¼”ç¤ºåº”ç”¨\n                    åä½œå¼€å‘ï¼šå›¢é˜Ÿåä½œå¼€å‘æ¨¡å‹\n                    æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ï¼šç®¡ç†æ¨¡å‹çš„ä¸åŒç‰ˆæœ¬"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "HuggingFace Hubæ¶æ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "HuggingFace Hubæ¶æ„"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "HuggingFace Hubæµç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "HuggingFace Hubæµç¨‹"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä¸Šä¼ æ¨¡å‹åˆ°Hub",
          "language": "python",
          "code": "from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom huggingface_hub import login, HfApi\n\n# ç™»å½•ï¼ˆéœ€è¦tokenï¼‰\nlogin(token=\"your_token_here\")\n\n# ä¿å­˜æ¨¡å‹å’Œåˆ†è¯å™¨\nmodel = AutoModelForCausalLM.from_pretrained(\"./my_model\")\ntokenizer = AutoTokenizer.from_pretrained(\"./my_model\")\n\n# æ¨é€åˆ°Hub\nmodel.push_to_hub(\"username/my-model-name\")\ntokenizer.push_to_hub(\"username/my-model-name\")\n\n# æˆ–è€…ä½¿ç”¨API\napi = HfApi()\napi.upload_folder(\n    folder_path=\"./my_model\",\n    repo_id=\"username/my-model-name\",\n    repo_type=\"model\"\n)"
        },
        {
          "type": "code-box",
          "title": "ä»HubåŠ è½½æ¨¡å‹",
          "language": "python",
          "code": "from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨\nmodel = AutoModelForCausalLM.from_pretrained(\"username/my-model-name\")\ntokenizer = AutoTokenizer.from_pretrained(\"username/my-model-name\")\n\n# ä½¿ç”¨æ¨¡å‹\ntext = \"Hello, how are you?\"\ninputs = tokenizer(text, return_tensors=\"pt\")\noutputs = model.generate(**inputs)\nprint(tokenizer.decode(outputs[0]))"
        },
        {
          "type": "code-box",
          "title": "ä¸Šä¼ æ•°æ®é›†",
          "language": "python",
          "code": "from datasets import load_dataset, Dataset\nfrom huggingface_hub import login\n\n# ç™»å½•\nlogin(token=\"your_token_here\")\n\n# åˆ›å»ºæ•°æ®é›†\ndata = {\"text\": [\"Hello\", \"World\"], \"label\": [0, 1]}\ndataset = Dataset.from_dict(data)\n\n# ä¸Šä¼ åˆ°Hub\ndataset.push_to_hub(\"username/my-dataset-name\")\n\n# ä»HubåŠ è½½æ•°æ®é›†\nloaded_dataset = load_dataset(\"username/my-dataset-name\")"
        },
        {
          "type": "code-box",
          "title": "ä½¿ç”¨æ¨ç†API",
          "language": "python",
          "code": "from huggingface_hub import InferenceClient\n\n# åˆ›å»ºæ¨ç†å®¢æˆ·ç«¯\nclient = InferenceClient(\"username/my-model-name\")\n\n# æ–‡æœ¬ç”Ÿæˆ\nresponse = client.text_generation(\n    \"The future of AI is\",\n    max_new_tokens=50\n)\nprint(response)\n\n# æ–‡æœ¬åˆ†ç±»\nresponse = client.text_classification(\"I love this movie!\")\nprint(response)\n\n# é—®ç­”\nresponse = client.question_answering(\n    question=\"What is AI?\",\n    context=\"Artificial Intelligence is...\"\n)\nprint(response)"
        },
        {
          "type": "code-box",
          "title": "åˆ›å»ºå’Œéƒ¨ç½²Space",
          "language": "python",
          "code": "# 1. åˆ›å»ºSpaceåº”ç”¨ï¼ˆä½¿ç”¨Gradioï¼‰\n# app.py\nimport gradio as gr\nfrom transformers import pipeline\n\n# åŠ è½½æ¨¡å‹\nclassifier = pipeline(\"sentiment-analysis\")\n\ndef predict(text):\n    result = classifier(text)[0]\n    return f\"{result['label']}: {result['score']:.2f}\"\n\n# åˆ›å»ºGradioç•Œé¢\niface = gr.Interface(\n    fn=predict,\n    inputs=gr.Textbox(placeholder=\"Enter text here...\"),\n    outputs=\"text\",\n    title=\"Sentiment Analysis\"\n)\n\niface.launch()\n\n# 2. åˆ›å»ºrequirements.txt\n# transformers\n# torch\n# gradio\n\n# 3. æ¨é€åˆ°Hub\n# git init\n# git add .\n# git commit -m \"Initial commit\"\n# git push https://huggingface.co/spaces/username/my-space\"\n\n# æˆ–è€…ä½¿ç”¨huggingface_hub CLI\n# huggingface-cli upload username/my-space ./app.py"
        },
        {
          "type": "code-box",
          "title": "ç®¡ç†æ¨¡å‹ç‰ˆæœ¬",
          "language": "python",
          "code": "from huggingface_hub import HfApi, create_repo\n\napi = HfApi()\n\n# åˆ›å»ºä»“åº“\ncreate_repo(\"username/my-model\", repo_type=\"model\")\n\n# ä¸Šä¼ æ–‡ä»¶ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºç‰ˆæœ¬ï¼‰\napi.upload_file(\n    path_or_fileobj=\"./model.safetensors\",\n    path_in_repo=\"model.safetensors\",\n    repo_id=\"username/my-model\",\n    repo_type=\"model\"\n)\n\n# æŸ¥çœ‹ç‰ˆæœ¬å†å²\nrevisions = api.list_repo_refs(\"username/my-model\")\nfor rev in revisions.branches:\n    print(f\"Branch: {rev.name}\")\n\nfor rev in revisions.tags:\n    print(f\"Tag: {rev.name}\")\n\n# ä¸‹è½½ç‰¹å®šç‰ˆæœ¬\nfrom transformers import AutoModel\nmodel = AutoModel.from_pretrained(\n    \"username/my-model\",\n    revision=\"v1.0\"  # æŒ‡å®šç‰ˆæœ¬\n)"
        }
      ]
    }
  ]
}