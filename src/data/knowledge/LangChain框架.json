{
  "title": "LangChainæ¡†æ¶",
  "subtitle": "LangChain æ¡†æ¶çš„æ ¸å¿ƒæ¦‚å¿µã€è¿›é˜¶ç‰¹æ€§ã€RAG/æ™ºèƒ½ä½“é›†æˆä¸å®è·µæ¡ˆä¾‹ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "LangChainæ˜¯ç”¨äºæ„å»ºLLMåº”ç”¨çš„æ¡†æ¶ï¼Œæä¾›é“¾å¼è°ƒç”¨ã€å·¥å…·é›†æˆã€è®°å¿†ç®¡ç†ç­‰èƒ½åŠ›ï¼Œç®€åŒ–åº”ç”¨å¼€å‘ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "é“¾å¼è°ƒç”¨ï¼šæ”¯æŒå¤æ‚çš„è°ƒç”¨é“¾",
            "å·¥å…·é›†æˆï¼šè½»æ¾é›†æˆå¤–éƒ¨å·¥å…·",
            "è®°å¿†ç®¡ç†ï¼šæ”¯æŒå¯¹è¯è®°å¿†",
            "æ¨¡å—åŒ–è®¾è®¡ï¼šç»„ä»¶å¯å¤ç”¨",
            "ç”Ÿæ€ä¸°å¯Œï¼šå¤§é‡æ’ä»¶å’Œå·¥å…·"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "é“¾å¼è°ƒç”¨ã€å·¥å…·é›†æˆã€è®°å¿†ç®¡ç†ã€æç¤ºæ¨¡æ¿ã€è¾“å‡ºè§£æ"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "LLMåº”ç”¨å¼€å‘ã€å·¥å…·é›†æˆã€é“¾å¼è°ƒç”¨ã€åº”ç”¨æ¡†æ¶ã€å¿«é€Ÿå¼€å‘"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ å¿«é€Ÿå¼€å§‹",
      "content": [
        {
          "type": "code-box",
          "title": "å®‰è£…ä¸æœ€å°ç¤ºä¾‹",
          "language": "python",
          "code": "from langchain_openai import ChatOpenAI\nfrom langchain.prompts import PromptTemplate\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\nprompt = PromptTemplate(\n    input_variables=[\"topic\"],\n    template=\"å†™ä¸€æ®µå…³äº{topic}çš„ä»‹ç»\"\n)\nchain = prompt | llm\nprint(chain.invoke({\"topic\": \"LangChain\"}).content)"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ§± æ ¸å¿ƒç»„ä»¶",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\nllm = ChatOpenAI(model_name=\"gpt-4\")\nembeddings = OpenAIEmbeddings()"
        },
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.agents import initialize_agent, Tool\n\ntools = [Tool(name=\"Search\", func=search_web, description=\"ç½‘ç»œæœç´¢\")]\nagent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\")\nresponse = agent.run(\"å¸®æˆ‘æŸ¥ä¸€ä¸‹ä»Šå¤©çš„AIæ–°é—»\")"
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ LangChain + RAG",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\n\nloader = TextLoader(\"docs.txt\")\nchunks = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200).split_documents(loader.load())\nvectorstore = Chroma.from_documents(chunks, embeddings)\nqa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\nanswer = qa_chain.run(\"æ–‡æ¡£çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\")"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ¤– LangChain + æ™ºèƒ½ä½“",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.tools import StructuredTool\nfrom pydantic import BaseModel\n\nclass CalculatorInput(BaseModel):\n    expression: str\n\ncalc_tool = StructuredTool.from_function(\n    func=calculate,\n    name=\"Calculator\",\n    description=\"æ‰§è¡Œæ•°å­¦è®¡ç®—\",\n    args_schema=CalculatorInput\n)"
        }
      ]
    },
    {
      "type": "section",
      "title": "âœ¨ é«˜çº§ç‰¹æ€§",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nllm = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()])"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "LangChainæ¡†æ¶æ¶æ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "LangChainæ¡†æ¶æ¶æ„"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "LangChainæ¡†æ¶æµç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "LangChainæ¡†æ¶æµç¨‹"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ§ª å®è·µæ¡ˆä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\n\nprompt = PromptTemplate.from_template(\"é—®é¢˜ï¼š{question}\\nå›ç­”ï¼š\")\nqa_chain = LLMChain(llm=llm, prompt=prompt)\nqa_chain.run(\"ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\")"
        },
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "qa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=\"stuff\",\n    retriever=vectorstore.as_retriever()\n)\nqa_chain.run(\"æ–‡æ¡£ä¸­æåˆ°äº†å“ªäº›å…³é”®æŠ€æœ¯ï¼Ÿ\")"
        },
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.chains import ConversationChain\nfrom langchain.memory import ConversationBufferMemory\n\nconversation = ConversationChain(llm=llm, memory=ConversationBufferMemory())\nconversation.predict(input=\"ä½ å¥½\")\nconversation.predict(input=\"ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\")"
        }
      ]
    }
  ]
}