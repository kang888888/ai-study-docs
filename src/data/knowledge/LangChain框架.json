{
  "title": "LangChainæ¡†æ¶",
  "subtitle": "LangChain æ¡†æ¶çš„æ ¸å¿ƒæ¦‚å¿µã€è¿›é˜¶ç‰¹æ€§ã€RAG/æ™ºèƒ½ä½“é›†æˆä¸å®è·µæ¡ˆä¾‹ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸš€ å¿«é€Ÿå¼€å§‹",
      "content": [
        {
          "type": "code-box",
          "title": "å®‰è£…ä¸æœ€å°ç¤ºä¾‹",
          "language": "python",
          "code": "from langchain_openai import ChatOpenAI\nfrom langchain.prompts import PromptTemplate\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\nprompt = PromptTemplate(\n    input_variables=[\"topic\"],\n    template=\"å†™ä¸€æ®µå…³äº{topic}çš„ä»‹ç»\"\n)\nchain = prompt | llm\nprint(chain.invoke({\"topic\": \"LangChain\"}).content)"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ§± æ ¸å¿ƒç»„ä»¶",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\nllm = ChatOpenAI(model_name=\"gpt-4\")\nembeddings = OpenAIEmbeddings()"
        },
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.agents import initialize_agent, Tool\n\ntools = [Tool(name=\"Search\", func=search_web, description=\"ç½‘ç»œæœç´¢\")]\nagent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\")\nresponse = agent.run(\"å¸®æˆ‘æŸ¥ä¸€ä¸‹ä»Šå¤©çš„AIæ–°é—»\")"
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ LangChain + RAG",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\n\nloader = TextLoader(\"docs.txt\")\nchunks = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200).split_documents(loader.load())\nvectorstore = Chroma.from_documents(chunks, embeddings)\nqa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\nanswer = qa_chain.run(\"æ–‡æ¡£çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\")"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ¤– LangChain + æ™ºèƒ½ä½“",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.tools import StructuredTool\nfrom pydantic import BaseModel\n\nclass CalculatorInput(BaseModel):\n    expression: str\n\ncalc_tool = StructuredTool.from_function(\n    func=calculate,\n    name=\"Calculator\",\n    description=\"æ‰§è¡Œæ•°å­¦è®¡ç®—\",\n    args_schema=CalculatorInput\n)"
        }
      ]
    },
    {
      "type": "section",
      "title": "âœ¨ é«˜çº§ç‰¹æ€§",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nllm = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()])"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "LangChainæ¡†æ¶æ¶æ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "LangChainæ¡†æ¶æ¶æ„",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "LangChainæ¡†æ¶æµç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "LangChainæ¡†æ¶æµç¨‹",
                "data": null
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ§ª å®è·µæ¡ˆä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\n\nprompt = PromptTemplate.from_template(\"é—®é¢˜ï¼š{question}\\nå›ç­”ï¼š\")\nqa_chain = LLMChain(llm=llm, prompt=prompt)\nqa_chain.run(\"ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\")"
        },
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "qa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=\"stuff\",\n    retriever=vectorstore.as_retriever()\n)\nqa_chain.run(\"æ–‡æ¡£ä¸­æåˆ°äº†å“ªäº›å…³é”®æŠ€æœ¯ï¼Ÿ\")"
        },
        {
          "type": "code-box",
          "title": "",
          "language": "python",
          "code": "from langchain.chains import ConversationChain\nfrom langchain.memory import ConversationBufferMemory\n\nconversation = ConversationChain(llm=llm, memory=ConversationBufferMemory())\nconversation.predict(input=\"ä½ å¥½\")\nconversation.predict(input=\"ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\")"
        }
      ]
    }
  ]
}