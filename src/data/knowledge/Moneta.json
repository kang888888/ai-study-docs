{
  "title": "Moneta",
  "subtitle": "åŸºäºMirasæ¡†æ¶çš„é«˜æ•ˆå…³è”è®°å¿†æ¶æ„",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "Moneta æ˜¯åŸºäº Miras æ¡†æ¶æå‡ºçš„é«˜æ•ˆå…³è”è®°å¿†æ¶æ„ï¼Œä¸“æ³¨äºå¿«é€Ÿæ£€ç´¢å’Œæ›´æ–°ï¼Œé€‚ç”¨äºå®æ—¶æ¨ç†ä»»åŠ¡ã€‚Moneta é€šè¿‡ä¼˜åŒ–çš„è®°å¿†ç»„ç»‡æ–¹å¼å’Œæ£€ç´¢æœºåˆ¶ï¼Œå®ç°äº†ä½è®¡ç®—å¼€é”€å’Œé«˜å“åº”é€Ÿåº¦ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "**å¿«é€Ÿæ£€ç´¢å’Œæ›´æ–°**ï¼šä¼˜åŒ–çš„è®°å¿†è®¿é—®æ¨¡å¼ï¼Œå®ç°æ¯«ç§’çº§å“åº”",
            "**ä½è®¡ç®—å¼€é”€**ï¼šé«˜æ•ˆçš„å…³è”è®°å¿†æ¶æ„ï¼Œå‡å°‘è®¡ç®—å¤æ‚åº¦",
            "**å®æ—¶å“åº”**ï¼šä¸“ä¸ºå®æ—¶æ¨ç†ä»»åŠ¡è®¾è®¡ï¼Œæ”¯æŒåœ¨çº¿å­¦ä¹ ",
            "**é«˜æ•ˆè®°å¿†ç®¡ç†**ï¼šæ™ºèƒ½çš„è®°å¿†ç»„ç»‡æ–¹å¼ï¼Œæé«˜æ£€ç´¢æ•ˆç‡"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "é«˜æ•ˆæ£€ç´¢ã€å¿«é€Ÿæ›´æ–°ã€å…³è”è®°å¿†ã€å®æ—¶æ¨ç†ã€KV Cacheä¼˜åŒ–"
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ æŠ€æœ¯æ¶æ„",
      "content": [
        {
          "type": "tech-box",
          "content": "å…³è”è®°å¿†æ¶æ„ï¼šé‡‡ç”¨æ‰å¹³è®°å¿†ç»“æ„ï¼Œæ‰€æœ‰è®°å¿†å¹³ç­‰ï¼Œæ”¯æŒå¿«é€Ÿå…¨å±€æ£€ç´¢"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "å®æ—¶æ¨ç†ä»»åŠ¡ï¼šéœ€è¦å¿«é€Ÿå“åº”çš„åœ¨çº¿æ¨ç†åœºæ™¯\n                    åœ¨çº¿å­¦ä¹ ä»»åŠ¡ï¼šéœ€è¦å®æ—¶æ›´æ–°æ¨¡å‹çš„åŠ¨æ€å­¦ä¹ åœºæ™¯\n                    ä½å»¶è¿Ÿåº”ç”¨ï¼šå¯¹å“åº”æ—¶é—´è¦æ±‚æé«˜çš„åº”ç”¨åœºæ™¯"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "Monetaæ¶æ„å›¾",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "Monetaæ¶æ„å›¾"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "Monetaç»„ä»¶è¯¦è§£",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "Monetaç»„ä»¶è¯¦è§£"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "Moneta å…³è”è®°å¿†æ¨¡å—",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MonetaMemory(nn.Module):\n    \"\"\"Moneta é«˜æ•ˆå…³è”è®°å¿†æ¨¡å—\"\"\"\n    def __init__(self, d_model, memory_size):\n        super(MonetaMemory, self).__init__()\n        self.d_model = d_model\n        self.memory_size = memory_size\n        \n        # æ‰å¹³è®°å¿†ç»“æ„\n        self.memory = nn.Parameter(torch.randn(memory_size, d_model))\n        \n        # å¿«é€Ÿæ£€ç´¢æŠ•å½±\n        self.query_proj = nn.Linear(d_model, d_model)\n        self.key_proj = nn.Linear(d_model, d_model)\n        self.value_proj = nn.Linear(d_model, d_model)\n        \n        # åœ¨çº¿æ›´æ–°é—¨æ§\n        self.update_gate = nn.Linear(d_model, d_model)\n    \n    def forward(self, query, new_info=None):\n        \"\"\"\n        å¿«é€Ÿæ£€ç´¢å’Œæ›´æ–°\n        å‚æ•°:\n            query: [batch_size, d_model] æŸ¥è¯¢å‘é‡\n            new_info: [batch_size, d_model] æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰\n        è¿”å›:\n            retrieved: [batch_size, d_model] æ£€ç´¢ç»“æœ\n        \"\"\"\n        # å¿«é€Ÿæ£€ç´¢\n        q = self.query_proj(query)\n        k = self.key_proj(self.memory)\n        v = self.value_proj(self.memory)\n        \n        # è®¡ç®—æ³¨æ„åŠ›ï¼ˆä¼˜åŒ–åçš„è®¡ç®—ï¼‰\n        scores = torch.matmul(q, k.t()) / (self.d_model ** 0.5)\n        attention = F.softmax(scores, dim=-1)\n        retrieved = torch.matmul(attention, v)\n        \n        # åœ¨çº¿æ›´æ–°ï¼ˆå¦‚æœæä¾›äº†æ–°ä¿¡æ¯ï¼‰\n        if new_info is not None:\n            gate = torch.sigmoid(self.update_gate(new_info))\n            # æ›´æ–°æœ€ç›¸å…³çš„è®°å¿†ä½ç½®\n            top_k_indices = torch.topk(attention, k=min(10, self.memory_size), dim=-1)[1]\n            for i, idx in enumerate(top_k_indices):\n                self.memory.data[idx] = gate[i] * new_info[i] + (1 - gate[i]) * self.memory.data[idx]\n        \n        return retrieved\n\n# ä½¿ç”¨ç¤ºä¾‹\nif __name__ == \"__main__\":\n    memory = MonetaMemory(d_model=512, memory_size=1000)\n    query = torch.randn(2, 512)\n    new_info = torch.randn(2, 512)\n    \n    # æ£€ç´¢\n    result = memory(query, new_info)\n    print(f\"æ£€ç´¢ç»“æœå½¢çŠ¶: {result.shape}\")  # [2, 512]"
        }
      ]
    }
  ]
}