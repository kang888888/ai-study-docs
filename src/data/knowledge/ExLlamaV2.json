{
  "title": "ExLlamaV2ï¼šé¢å‘ 4bit LLaMA çš„æè‡´æ¨ç†æ¡†æ¶",
  "subtitle": "ä¸“ä¸º GPTQ/AWQ æ¨¡å‹æ‰“é€ çš„é«˜æ€§èƒ½åç«¯ï¼Œä½¿ç”¨è‡ªç ” CUDA kernelã€KV cache ä¼˜åŒ–ä¸æµæ°´çº¿å¹¶è¡Œï¼Œæ¨ç†é€Ÿåº¦é¢†å…ˆ vLLM/vCUDAã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“Š å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æ¶æ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "æ¶æ„"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æ€§èƒ½å¯¹æ¯”",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "æ€§èƒ½å¯¹æ¯”"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "ç¼“å­˜ç­–ç•¥",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "ç¼“å­˜ç­–ç•¥"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦/æ€§èƒ½æ¨¡å‹",
      "content": [
        {
          "type": "math-box",
          "title": "ååä¼°ç®—",
          "formulas": [
            {
              "display": "TPS \\approx \\frac{B \\times H \\times d_{model}}{t_{kernel} + t_{io}}"
            },
            {
              "text": "ExLlamaV2 é€šè¿‡å‡å°‘ $t_{io}$ï¼ˆå°‘è§£é‡åŒ–ï¼‰å’Œä¼˜åŒ– $t_{kernel}$ è·å¾—æ›´é«˜ TPSã€‚",
              "inline": "t_{io}"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "KV Cache å†…å­˜",
          "formulas": [
            {
              "display": "\\text{Mem} = 2 \\times L \\times H \\times d_{head} \\times bytes_{dtype}"
            },
            {
              "text": "Paged Cache å°† $L$ åˆ‡å—ï¼Œå¹¶å¤ç”¨é‡Šæ”¾çš„å—å‡å° MEM å³°å€¼ã€‚",
              "inline": "L"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "Python å¿«é€Ÿæ¨ç†",
          "language": "python",
          "code": "from exllamav2 import ExLlamaV2, ExLlamaV2Config, ExLlamaV2Tokenizer\n\nconfig = ExLlamaV2Config(\"./llama-2-13b-gptq\")\nmodel = ExLlamaV2(config)\nmodel.load_autosplit()\n\ntokenizer = ExLlamaV2Tokenizer(config)\nprompt = \"### ç”¨æˆ·: è§£é‡Š ExLlamaV2 çš„ä¼˜åŠ¿\\n### åŠ©æ‰‹:\"\noutput = model.generate(\n    tokenizer.encode(prompt),\n    max_new_tokens=256,\n    temperature=0.7,\n    top_p=0.9\n)\nprint(tokenizer.decode(output))"
        }
      ]
    }
  ]
}