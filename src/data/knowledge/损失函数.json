{
  "title": "æŸå¤±å‡½æ•° (Loss Function)",
  "subtitle": "è¡¡é‡æ¨¡å‹é¢„æµ‹ä¸çœŸå®å€¼å·®å¼‚çš„å‡½æ•°",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "æŸå¤±å‡½æ•°ï¼ˆLoss Functionï¼‰ç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ã€‚è®­ç»ƒè¿‡ç¨‹çš„ç›®æ ‡å°±æ˜¯æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œä½¿æ¨¡å‹çš„é¢„æµ‹å°½å¯èƒ½æ¥è¿‘çœŸå®å€¼ã€‚ä¸åŒçš„ä»»åŠ¡éœ€è¦é€‰æ‹©ä¸åŒçš„æŸå¤±å‡½æ•°ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼šç”¨äºå›å½’ä»»åŠ¡ï¼Œè®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¹³æ–¹å·®",
            "äº¤å‰ç†µæŸå¤±ï¼ˆCross-Entropyï¼‰ï¼šç”¨äºåˆ†ç±»ä»»åŠ¡ï¼Œè¡¡é‡æ¦‚ç‡åˆ†å¸ƒå·®å¼‚",
            "äºŒå…ƒäº¤å‰ç†µï¼ˆBCEï¼‰ï¼šç”¨äºäºŒåˆ†ç±»ä»»åŠ¡",
            "Focal Lossï¼šè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œé™ä½æ˜“åˆ†ç±»æ ·æœ¬æƒé‡",
            "Huber Lossï¼šå¯¹å¼‚å¸¸å€¼æ›´é²æ£’ï¼Œç»“åˆMSEå’ŒMAE",
            "KLæ•£åº¦ï¼šè¡¡é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„å·®å¼‚",
            "Triplet Lossï¼šç”¨äºåº¦é‡å­¦ä¹ ï¼Œæ‹‰è¿‘åŒç±»æ ·æœ¬ï¼Œæ¨è¿œå¼‚ç±»æ ·æœ¬"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "MSEã€MAEã€äº¤å‰ç†µã€Focal Lossã€Huber Lossã€Triplet Lossã€æ ‡ç­¾å¹³æ»‘"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "å›å½’ä»»åŠ¡ï¼ˆMSEï¼‰ã€åˆ†ç±»ä»»åŠ¡ï¼ˆäº¤å‰ç†µï¼‰ã€ç›®æ ‡æ£€æµ‹ï¼ˆFocal Lossï¼‰ã€åº¦é‡å­¦ä¹ ï¼ˆTriplet Lossï¼‰ã€ç”Ÿæˆæ¨¡å‹ï¼ˆKLæ•£åº¦ï¼‰"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "MathFunctionDiagram",
              "caption": "æŸå¤±å‡½æ•°å¯¹æ¯”",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "loss",
                "title": "æŸå¤±å‡½æ•°å¯¹æ¯”"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰",
          "formulas": [
            {
              "text": "MSEè®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¹³æ–¹å·®ï¼š"
            },
            {
              "display": "L_{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2"
            },
            {
              "text": "å…¶ä¸­ $y_i$ æ˜¯çœŸå®å€¼ï¼Œ$\\hat{y}_i$ æ˜¯é¢„æµ‹å€¼ï¼Œ$n$ æ˜¯æ ·æœ¬æ•°"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "äº¤å‰ç†µæŸå¤±",
          "formulas": [
            {
              "text": "å¤šåˆ†ç±»äº¤å‰ç†µï¼š"
            },
            {
              "display": "L_{CE} = -\\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{i,c} \\log(\\hat{y}_{i,c})"
            },
            {
              "text": "å…¶ä¸­ $C$ æ˜¯ç±»åˆ«æ•°ï¼Œ$y_{i,c}$ æ˜¯çœŸå®æ ‡ç­¾ï¼ˆone-hotï¼‰ï¼Œ$\\hat{y}_{i,c}$ æ˜¯é¢„æµ‹æ¦‚ç‡"
            },
            {
              "text": "å¯¹äºå•ä¸ªæ ·æœ¬ï¼Œç®€åŒ–ä¸ºï¼š"
            },
            {
              "display": "L_{CE} = -\\log(\\hat{y}_{true})"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "Focal Loss",
          "formulas": [
            {
              "text": "Focal Lossé€šè¿‡é™ä½æ˜“åˆ†ç±»æ ·æœ¬çš„æƒé‡æ¥è§£å†³ç±»åˆ«ä¸å¹³è¡¡ï¼š"
            },
            {
              "display": "L_{FL} = -\\alpha (1-p_t)^\\gamma \\log(p_t)"
            },
            {
              "text": "å…¶ä¸­ $p_t$ æ˜¯é¢„æµ‹æ¦‚ç‡ï¼Œ$\\alpha$ æ˜¯å¹³è¡¡å› å­ï¼Œ$\\gamma$ æ˜¯èšç„¦å‚æ•°ï¼ˆé€šå¸¸å–2ï¼‰",
              "inline": "p_t, \\alpha, \\gamma"
            },
            {
              "text": "å½“ $\\gamma=0$ æ—¶ï¼ŒFocal Lossé€€åŒ–ä¸ºæ ‡å‡†äº¤å‰ç†µ"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "Huber Loss",
          "formulas": [
            {
              "text": "Huber Losså¯¹å¼‚å¸¸å€¼æ›´é²æ£’ï¼š"
            },
            {
              "display": "L_{\\delta}(y, \\hat{y}) = \\begin{cases} \\frac{1}{2}(y-\\hat{y})^2 & \\text{if } |y-\\hat{y}| \\leq \\delta \\\\ \\delta|y-\\hat{y}| - \\frac{1}{2}\\delta^2 & \\text{otherwise} \\end{cases}"
            },
            {
              "text": "å½“è¯¯å·®å°äº $\\delta$ æ—¶ï¼Œä½¿ç”¨MSEï¼›å¦åˆ™ä½¿ç”¨MAEï¼Œå¯¹å¼‚å¸¸å€¼æ›´é²æ£’"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "PyTorch ä¸­çš„æŸå¤±å‡½æ•°",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# 1. å‡æ–¹è¯¯å·®ï¼ˆå›å½’ä»»åŠ¡ï¼‰\nmse_loss = nn.MSELoss()\npred = torch.tensor([1.0, 2.0, 3.0])\ntarget = torch.tensor([1.5, 2.5, 2.8])\nloss = mse_loss(pred, target)\nprint(f\"MSE Loss: {loss.item()}\")\n\n# 2. äº¤å‰ç†µæŸå¤±ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰\nce_loss = nn.CrossEntropyLoss()\n# é¢„æµ‹å€¼ï¼ˆæœªå½’ä¸€åŒ–ï¼Œlogitsï¼‰\nlogits = torch.randn(32, 10)  # [batch_size, num_classes]\n# çœŸå®æ ‡ç­¾ï¼ˆç±»åˆ«ç´¢å¼•ï¼‰\ntargets = torch.randint(0, 10, (32,))\nloss = ce_loss(logits, targets)\nprint(f\"Cross-Entropy Loss: {loss.item()}\")\n\n# 3. äºŒå…ƒäº¤å‰ç†µï¼ˆäºŒåˆ†ç±»ï¼‰\nbce_loss = nn.BCEWithLogitsLoss()  # åŒ…å«sigmoidï¼Œæ•°å€¼ç¨³å®š\nlogits = torch.randn(32, 1)\ntargets = torch.randint(0, 2, (32, 1)).float()\nloss = bce_loss(logits, targets)\nprint(f\"BCE Loss: {loss.item()}\")\n\n# 4. æ ‡ç­¾å¹³æ»‘çš„äº¤å‰ç†µ\nclass LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self, smoothing=0.1):\n        super().__init__()\n        self.smoothing = smoothing\n    \n    def forward(self, logits, targets):\n        num_classes = logits.size(-1)\n        log_probs = F.log_softmax(logits, dim=-1)\n        \n        # åˆ›å»ºå¹³æ»‘æ ‡ç­¾\n        with torch.no_grad():\n            true_dist = torch.zeros_like(log_probs)\n            true_dist.fill_(self.smoothing / (num_classes - 1))\n            true_dist.scatter_(1, targets.unsqueeze(1), 1.0 - self.smoothing)\n        \n        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n\n# 5. Focal Losså®ç°\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n    \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        return focal_loss.mean()\n\n# 6. Huber Loss\nhuber_loss = nn.HuberLoss(delta=1.0)\npred = torch.tensor([1.0, 2.0, 3.0])\ntarget = torch.tensor([1.5, 2.5, 2.8])\nloss = huber_loss(pred, target)\nprint(f\"Huber Loss: {loss.item()}\")\n\n# 7. å®é™…è®­ç»ƒç¤ºä¾‹\nmodel = nn.Linear(10, 3)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# æ¨¡æ‹Ÿæ•°æ®\nx = torch.randn(32, 10)\ny = torch.randint(0, 3, (32,))\n\n# è®­ç»ƒå¾ªç¯\nfor epoch in range(100):\n    # å‰å‘ä¼ æ’­\n    logits = model(x)\n    loss = criterion(logits, y)\n    \n    # åå‘ä¼ æ’­\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (epoch + 1) % 20 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n\n# 8. å¤šä»»åŠ¡æŸå¤±ï¼ˆç»„åˆå¤šä¸ªæŸå¤±ï¼‰\ndef multi_task_loss(pred1, target1, pred2, target2, weight1=0.5, weight2=0.5):\n    loss1 = nn.MSELoss()(pred1, target1)\n    loss2 = nn.CrossEntropyLoss()(pred2, target2)\n    total_loss = weight1 * loss1 + weight2 * loss2\n    return total_loss, loss1, loss2"
        }
      ]
    }
  ]
}