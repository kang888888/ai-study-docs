{
  "title": "GAN (Generative Adversarial Network) ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ",
  "subtitle": "ç”Ÿæˆå™¨ä¸åˆ¤åˆ«å™¨çš„å¯¹æŠ—åšå¼ˆ",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "ç”±ç”Ÿæˆå™¨ï¼ˆGeneratorï¼‰å’Œåˆ¤åˆ«å™¨ï¼ˆDiscriminatorï¼‰ç»„æˆçš„å¯¹æŠ—ç³»ç»Ÿã€‚ç”Ÿæˆå™¨è¯•å›¾ç”Ÿæˆé€¼çœŸæ•°æ®ï¼Œåˆ¤åˆ«å™¨è¯•å›¾åŒºåˆ†çœŸå‡ï¼Œä¸¤è€…åšå¼ˆæœ€ç»ˆè¾¾åˆ°çº³ä»€å‡è¡¡ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "å¯¹æŠ—è®­ç»ƒï¼šç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ç›¸äº’åšå¼ˆï¼Œäº¤æ›¿è®­ç»ƒ",
            "ç”Ÿæˆé€Ÿåº¦å¿«ï¼šä¸€æ¬¡å‰å‘ä¼ æ’­å³å¯ç”Ÿæˆï¼Œæ— éœ€å¤šæ­¥é‡‡æ ·",
            "è®­ç»ƒä¸ç¨³å®šï¼šå®¹æ˜“å‡ºç°æ¨¡å¼å´©æºƒï¼ˆMode Collapseï¼‰",
            "æ— æ˜¾å¼å¯†åº¦ï¼šä¸å­¦ä¹ æ•°æ®åˆ†å¸ƒçš„æ˜¾å¼å½¢å¼",
            "å¤šç§å˜ä½“ï¼šDCGANã€StyleGANã€CycleGANç­‰"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "å¯¹æŠ—æŸå¤±ã€WGANã€è°±å½’ä¸€åŒ–ï¼ˆSpectral Normalizationï¼‰ã€æ¸è¿›å¼è®­ç»ƒ"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "å›¾åƒç”Ÿæˆã€é£æ ¼è¿ç§»ã€å›¾åƒè¶…åˆ†è¾¨ç‡ã€æ•°æ®å¢å¼ºã€äººè„¸ç”Ÿæˆï¼ˆStyleGANï¼‰"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GANDiagram",
              "caption": "GANæ¶æ„å›¾",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "GANæ¶æ„å›¾",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GANDiagram",
              "caption": "GANè®­ç»ƒè¿‡ç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "GANè®­ç»ƒè¿‡ç¨‹",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GANDiagram",
              "caption": "GANåˆ†å¸ƒæ¼”åŒ–",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "GANåˆ†å¸ƒæ¼”åŒ–",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GANDiagram",
              "caption": "GANå˜ä½“å¯¹æ¯”",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "GANå˜ä½“å¯¹æ¯”",
                "data": null
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "GAN çš„å¯¹æŠ—æŸå¤±å‡½æ•°",
          "formulas": [
            {
              "text": "GAN çš„ä¼˜åŒ–ç›®æ ‡æ˜¯ä¸€ä¸ªæå°æå¤§åšå¼ˆï¼š"
            },
            {
              "display": "\\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z)))]"
            },
            {
              "text": "å…¶ä¸­ï¼š"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "æœ€ä¼˜åˆ¤åˆ«å™¨",
          "formulas": [
            {
              "text": "å¯¹äºå›ºå®šçš„ç”Ÿæˆå™¨ $G$ï¼Œæœ€ä¼˜åˆ¤åˆ«å™¨ä¸ºï¼š",
              "inline": "G"
            },
            {
              "display": "D^*(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_g(x)}"
            },
            {
              "text": "å…¶ä¸­ $p_g(x)$ æ˜¯ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®åˆ†å¸ƒ",
              "inline": "p_g(x)"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "å…¨å±€æœ€ä¼˜è§£",
          "formulas": [
            {
              "text": "å½“ $p_g = p_{data}$ æ—¶è¾¾åˆ°å…¨å±€æœ€ä¼˜ï¼Œæ­¤æ—¶ï¼š",
              "inline": "p_g = p_{data}"
            },
            {
              "display": "D^*(x) = \\frac{1}{2}"
            },
            {
              "text": "åˆ¤åˆ«å™¨æ— æ³•åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆæ•°æ®"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ PyTorch å®ç°ç®€å• GAN",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nclass Generator(nn.Module):\n    \"\"\"ç”Ÿæˆå™¨ç½‘ç»œ\"\"\"\n    def __init__(self, latent_dim, img_shape):\n        super(Generator, self).__init__()\n        self.img_shape = img_shape\n        \n        def block(in_feat, out_feat, normalize=True):\n            layers = [nn.Linear(in_feat, out_feat)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n        \n        self.model = nn.Sequential(\n            *block(latent_dim, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(torch.prod(torch.tensor(img_shape)))),\n            nn.Tanh()\n        )\n    \n    def forward(self, z):\n        img = self.model(z)\n        img = img.view(img.size(0), *self.img_shape)\n        return img\n\nclass Discriminator(nn.Module):\n    \"\"\"åˆ¤åˆ«å™¨ç½‘ç»œ\"\"\"\n    def __init__(self, img_shape):\n        super(Discriminator, self).__init__()\n        \n        self.model = nn.Sequential(\n            nn.Linear(int(torch.prod(torch.tensor(img_shape))), 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1)\n        validity = self.model(img_flat)\n        return validity\n\n# è®­ç»ƒå‡½æ•°\ndef train_gan(generator, discriminator, dataloader, epochs=200, lr=0.0002, latent_dim=100):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    generator = generator.to(device)\n    discriminator = discriminator.to(device)\n    \n    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n    \n    adversarial_loss = nn.BCELoss()\n    \n    for epoch in range(epochs):\n        for i, (imgs, _) in enumerate(dataloader):\n            batch_size = imgs.size(0)\n            real_imgs = imgs.to(device)\n            \n            # è®­ç»ƒåˆ¤åˆ«å™¨\n            optimizer_D.zero_grad()\n            \n            # çœŸå®æ•°æ®\n            real_validity = discriminator(real_imgs)\n            real_loss = adversarial_loss(real_validity, torch.ones(batch_size, 1).to(device))\n            \n            # ç”Ÿæˆæ•°æ®\n            z = torch.randn(batch_size, latent_dim).to(device)\n            fake_imgs = generator(z)\n            fake_validity = discriminator(fake_imgs.detach())\n            fake_loss = adversarial_loss(fake_validity, torch.zeros(batch_size, 1).to(device))\n            \n            d_loss = (real_loss + fake_loss) / 2\n            d_loss.backward()\n            optimizer_D.step()\n            \n            # è®­ç»ƒç”Ÿæˆå™¨\n            optimizer_G.zero_grad()\n            \n            z = torch.randn(batch_size, latent_dim).to(device)\n            gen_imgs = generator(z)\n            validity = discriminator(gen_imgs)\n            g_loss = adversarial_loss(validity, torch.ones(batch_size, 1).to(device))\n            \n            g_loss.backward()\n            optimizer_G.step()\n            \n            if i % 100 == 0:\n                print(f\"[Epoch {epoch}/{epochs}] [Batch {i}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n\n# ä½¿ç”¨ç¤ºä¾‹\nif __name__ == \"__main__\":\n    img_shape = (1, 28, 28)  # MNISTå›¾åƒå½¢çŠ¶\n    latent_dim = 100\n    \n    generator = Generator(latent_dim, img_shape)\n    discriminator = Discriminator(img_shape)\n    \n    print(f\"ç”Ÿæˆå™¨å‚æ•°é‡: {sum(p.numel() for p in generator.parameters()):,}\")\n    print(f\"åˆ¤åˆ«å™¨å‚æ•°é‡: {sum(p.numel() for p in discriminator.parameters()):,}\")"
        }
      ]
    }
  ]
}