{
  "title": "äº¤å‰ç†µæŸå¤± (Cross-Entropy Loss)",
  "subtitle": "åˆ†ç±»ä»»åŠ¡çš„æ ‡å‡†æŸå¤±å‡½æ•°",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "äº¤å‰ç†µæŸå¤±æ˜¯åˆ†ç±»ä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„æŸå¤±å‡½æ•°ã€‚å®ƒè¡¡é‡æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒä¸çœŸå®æ ‡ç­¾åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚å¯¹äºå¤šåˆ†ç±»é—®é¢˜ï¼Œä½¿ç”¨å¤šç±»äº¤å‰ç†µï¼›å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼Œä½¿ç”¨äºŒå…ƒäº¤å‰ç†µï¼ˆBCEï¼‰ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "æ¦‚ç‡åˆ†å¸ƒå·®å¼‚ï¼šè¡¡é‡é¢„æµ‹åˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒçš„å·®å¼‚",
            "åˆ†ç±»ä»»åŠ¡æ ‡å‡†ï¼šå¤šåˆ†ç±»ä»»åŠ¡çš„æ ‡å‡†æŸå¤±å‡½æ•°",
            "æ¢¯åº¦å‹å¥½ï¼šæ¢¯åº¦è®¡ç®—ç®€å•ï¼Œè®­ç»ƒç¨³å®š",
            "ä¿¡æ¯è®ºåŸºç¡€ï¼šåŸºäºä¿¡æ¯ç†µå’ŒKLæ•£åº¦",
            "æ•°å€¼ç¨³å®šæ€§ï¼šéœ€è¦ç‰¹æ®Šå¤„ç†é¿å…æ•°å€¼é—®é¢˜"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦è¡¨è¾¾",
      "content": [
        {
          "type": "math-box",
          "title": "å¤šç±»äº¤å‰ç†µæŸå¤±",
          "formulas": [
            {
              "text": "å¯¹äºå¤šåˆ†ç±»é—®é¢˜ï¼ˆCä¸ªç±»åˆ«ï¼‰ï¼š"
            },
            {
              "display": "L_{\\text{CE}} = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{c=1}^{C}y_{i,c} \\log(\\hat{y}_{i,c})"
            },
            {
              "text": "å…¶ä¸­ï¼š"
            },
            {
              "text": "- $N$ æ˜¯æ ·æœ¬æ•°é‡"
            },
            {
              "text": "- $C$ æ˜¯ç±»åˆ«æ•°é‡"
            },
            {
              "text": "- $y_{i,c}$ æ˜¯çœŸå®æ ‡ç­¾ï¼ˆone-hotç¼–ç ï¼‰"
            },
            {
              "text": "- $\\hat{y}_{i,c}$ æ˜¯æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡ï¼ˆsoftmaxè¾“å‡ºï¼‰"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "äºŒå…ƒäº¤å‰ç†µæŸå¤±",
          "formulas": [
            {
              "text": "å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼š"
            },
            {
              "display": "L_{\\text{BCE}} = -\\frac{1}{N}\\sum_{i=1}^{N}[y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)]"
            },
            {
              "text": "å…¶ä¸­ $y_i \\in \\{0, 1\\}$ æ˜¯çœŸå®æ ‡ç­¾ï¼Œ$\\hat{y}_i \\in (0, 1)$ æ˜¯é¢„æµ‹æ¦‚ç‡"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "æ¢¯åº¦",
          "formulas": [
            {
              "text": "äº¤å‰ç†µæŸå¤±çš„æ¢¯åº¦ï¼ˆä¸softmaxç»“åˆï¼‰ï¼š"
            },
            {
              "display": "\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i"
            },
            {
              "text": "å…¶ä¸­ $z_i$ æ˜¯logitsï¼ˆsoftmaxå‰çš„å€¼ï¼‰ï¼Œè¿™ä¸ªæ¢¯åº¦å½¢å¼éå¸¸ç®€æ´"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ ç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "æ¦‚ç‡è§£é‡Šï¼šç›´æ¥ä¼˜åŒ–æ¦‚ç‡åˆ†å¸ƒ",
            "æ¢¯åº¦ç®€æ´ï¼šä¸softmaxç»“åˆæ—¶æ¢¯åº¦å½¢å¼ç®€å•",
            "æ•°å€¼ç¨³å®šï¼šé€šå¸¸ä½¿ç”¨log_softmaxé¿å…æ•°å€¼é—®é¢˜",
            "å¤šåˆ†ç±»æ ‡å‡†ï¼šå¤šåˆ†ç±»é—®é¢˜çš„æ ‡å‡†æŸå¤±å‡½æ•°",
            "ä¿¡æ¯è®ºåŸºç¡€ï¼šåŸºäºä¿¡æ¯è®ºä¸­çš„äº¤å‰ç†µæ¦‚å¿µ"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æŸå¤±å‡½æ•°å›¾åƒ",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "MathFunctionDiagram",
              "caption": "äº¤å‰ç†µæŸå¤±å‡½æ•°å›¾åƒ",
              "width": 1000,
              "height": 600,
              "interactive": true,
              "props": {
                "type": "loss",
                "title": "äº¤å‰ç†µæŸå¤±å‡½æ•°å›¾åƒ",
                "function": "bce"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "äº¤å‰ç†µã€KLæ•£åº¦ã€ä¿¡æ¯ç†µã€æ¦‚ç‡åˆ†å¸ƒã€æ ‡ç­¾å¹³æ»‘ã€ç±»åˆ«æƒé‡"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "å¤šåˆ†ç±»ä»»åŠ¡ã€äºŒåˆ†ç±»ä»»åŠ¡ã€è¯­è¨€æ¨¡å‹ã€å›¾åƒåˆ†ç±»ã€è‡ªç„¶è¯­è¨€å¤„ç†"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "äº¤å‰ç†µæŸå¤±å®ç°ä¸ä½¿ç”¨",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\n# 1. å¤šç±»äº¤å‰ç†µæŸå¤±\n# æ–¹æ³•1ï¼šä½¿ç”¨logitsï¼ˆæ¨èï¼Œæ•°å€¼ç¨³å®šï¼‰\nlogits = torch.randn(32, 10)  # [batch_size, num_classes]\ntargets = torch.randint(0, 10, (32,))  # ç±»åˆ«ç´¢å¼•\nloss1 = F.cross_entropy(logits, targets)\nprint(f\"Cross Entropy Loss: {loss1.item():.4f}\")\n\n# æ–¹æ³•2ï¼šæ‰‹åŠ¨è®¡ç®—ï¼ˆç”¨äºç†è§£ï¼‰\nprobs = F.softmax(logits, dim=1)\nlog_probs = torch.log(probs + 1e-8)  # é¿å…log(0)\nloss2 = F.nll_loss(log_probs, targets)\nprint(f\"Manual Loss: {loss2.item():.4f}\")\n\n# 2. äºŒå…ƒäº¤å‰ç†µæŸå¤±\n# äºŒåˆ†ç±»ï¼šè¾“å‡ºå•ä¸ªæ¦‚ç‡å€¼\nlogits_binary = torch.randn(32, 1)\ntargets_binary = torch.randint(0, 2, (32, 1)).float()\nprobs_binary = torch.sigmoid(logits_binary)\nloss_bce = F.binary_cross_entropy(probs_binary, targets_binary)\nprint(f\"Binary Cross Entropy: {loss_bce.item():.4f}\")\n\n# ä½¿ç”¨logitsï¼ˆæ¨èï¼‰\nloss_bce_logits = F.binary_cross_entropy_with_logits(logits_binary, targets_binary)\nprint(f\"BCE with Logits: {loss_bce_logits.item():.4f}\")\n\n# 3. åœ¨åˆ†ç±»ç½‘ç»œä¸­ä½¿ç”¨\nclass Classifier(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(Classifier, self).__init__()\n        self.fc = nn.Linear(input_size, num_classes)\n        self.criterion = nn.CrossEntropyLoss()\n    \n    def forward(self, x):\n        logits = self.fc(x)\n        return logits\n    \n    def compute_loss(self, logits, targets):\n        return self.criterion(logits, targets)\n\n# 4. å¸¦æƒé‡çš„äº¤å‰ç†µæŸå¤±ï¼ˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰\nclass_weights = torch.tensor([1.0, 2.0, 0.5, 1.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\ncriterion_weighted = nn.CrossEntropyLoss(weight=class_weights)\nloss_weighted = criterion_weighted(logits, targets)\nprint(f\"Weighted Loss: {loss_weighted.item():.4f}\")\n\n# 5. æ ‡ç­¾å¹³æ»‘ï¼ˆLabel Smoothingï¼‰\ndef label_smoothing_loss(logits, targets, num_classes, smoothing=0.1):\n    \"\"\"æ ‡ç­¾å¹³æ»‘çš„äº¤å‰ç†µæŸå¤±\"\"\"\n    confidence = 1.0 - smoothing\n    log_probs = F.log_softmax(logits, dim=1)\n    nll_loss = F.nll_loss(log_probs, targets, reduction='none')\n    smooth_loss = -log_probs.mean(dim=1)\n    loss = confidence * nll_loss + smoothing * smooth_loss\n    return loss.mean()\n\nloss_smooth = label_smoothing_loss(logits, targets, num_classes=10, smoothing=0.1)\nprint(f\"Label Smoothing Loss: {loss_smooth.item():.4f}\")\n\n# 6. å¯¹æ¯”ä¸åŒæŸå¤±å€¼\n# å®Œç¾é¢„æµ‹ï¼ˆæ¦‚ç‡=1ï¼‰\nperfect_logits = torch.tensor([[10.0, 0.0, 0.0], [0.0, 10.0, 0.0]])\nperfect_targets = torch.tensor([0, 1])\nperfect_loss = F.cross_entropy(perfect_logits, perfect_targets)\nprint(f\"Perfect prediction loss: {perfect_loss.item():.4f}\")\n\n# éšæœºé¢„æµ‹ï¼ˆæ¦‚ç‡å‡åŒ€ï¼‰\nrandom_logits = torch.tensor([[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]])\nrandom_targets = torch.tensor([0, 1])\nrandom_loss = F.cross_entropy(random_logits, random_targets)\nprint(f\"Random prediction loss: {random_loss.item():.4f}\")\n\n# 7. å®é™…è®­ç»ƒç¤ºä¾‹\nmodel = Classifier(input_size=784, num_classes=10)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤\nfor epoch in range(5):\n    # æ¨¡æ‹Ÿæ•°æ®\n    x = torch.randn(32, 784)\n    targets = torch.randint(0, 10, (32,))\n    \n    # å‰å‘ä¼ æ’­\n    logits = model(x)\n    loss = model.compute_loss(logits, targets)\n    \n    # åå‘ä¼ æ’­\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
        }
      ]
    }
  ]
}