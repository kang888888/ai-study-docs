{
  "title": "äºŒé˜¶ä¼˜åŒ–ç®—æ³• (Second-Order Optimization)",
  "subtitle": "åˆ©ç”¨äºŒé˜¶å¯¼æ•°ä¿¡æ¯åŠ é€Ÿä¼˜åŒ–çš„é«˜çº§ä¼˜åŒ–æ–¹æ³•",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "äºŒé˜¶ä¼˜åŒ–ç®—æ³•åˆ©ç”¨æŸå¤±å‡½æ•°çš„äºŒé˜¶å¯¼æ•°ï¼ˆHessiançŸ©é˜µï¼‰ä¿¡æ¯æ¥æŒ‡å¯¼å‚æ•°æ›´æ–°ï¼Œç›¸æ¯”ä¸€é˜¶æ–¹æ³•ï¼ˆå¦‚SGDï¼‰èƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ‰¾åˆ°æœ€ä¼˜è§£ï¼Œæ”¶æ•›é€Ÿåº¦æ›´å¿«ã€‚ä¸»è¦åŒ…æ‹¬ç‰›é¡¿æ³•ã€æ‹Ÿç‰›é¡¿æ³•ã€è‡ªç„¶æ¢¯åº¦ç­‰æ–¹æ³•ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "æ”¶æ•›å¿«é€Ÿï¼šåˆ©ç”¨äºŒé˜¶ä¿¡æ¯ï¼Œæ”¶æ•›é€Ÿåº¦æ˜¾è‘—å¿«äºä¸€é˜¶æ–¹æ³•",
            "ç²¾åº¦æ›´é«˜ï¼šèƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ‰¾åˆ°æœ€ä¼˜è§£",
            "è®¡ç®—å¤æ‚ï¼šéœ€è¦è®¡ç®—å’Œå­˜å‚¨HessiançŸ©é˜µï¼Œè®¡ç®—å¼€é”€å¤§",
            "å†…å­˜éœ€æ±‚ï¼šHessiançŸ©é˜µå­˜å‚¨éœ€è¦å¤§é‡å†…å­˜",
            "é€‚ç”¨åœºæ™¯ï¼šé€‚åˆå°è§„æ¨¡æ¨¡å‹å’Œå‡¸ä¼˜åŒ–é—®é¢˜"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "ç‰›é¡¿æ³•ã€æ‹Ÿç‰›é¡¿æ³•ï¼ˆBFGSã€L-BFGSï¼‰ã€è‡ªç„¶æ¢¯åº¦ã€Hessianè¿‘ä¼¼ã€K-FAC"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "å°è§„æ¨¡æ¨¡å‹è®­ç»ƒã€å‡¸ä¼˜åŒ–é—®é¢˜ã€éœ€è¦å¿«é€Ÿæ”¶æ•›çš„åœºæ™¯ã€å¼ºåŒ–å­¦ä¹ ä¸­çš„ç­–ç•¥ä¼˜åŒ–"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "äºŒé˜¶ä¼˜åŒ–ç®—æ³•åŸç†",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "concept",
                "title": "äºŒé˜¶ä¼˜åŒ–ç®—æ³•"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "ç‰›é¡¿æ³•æ›´æ–°è§„åˆ™",
          "formulas": [
            {
              "text": "ç‰›é¡¿æ³•æ›´æ–°ï¼š"
            },
            {
              "display": "w_{t+1} = w_t - H^{-1} \\nabla L(w_t)"
            },
            {
              "text": "å…¶ä¸­ $H$ æ˜¯HessiançŸ©é˜µï¼Œ$\\nabla L$ æ˜¯æ¢¯åº¦"
            },
            {
              "text": "HessiançŸ©é˜µå®šä¹‰ä¸ºï¼š"
            },
            {
              "display": "H_{ij} = \\frac{\\partial^2 L}{\\partial w_i \\partial w_j}"
            },
            {
              "text": "æ‹Ÿç‰›é¡¿æ³•é€šè¿‡è¿‘ä¼¼HessiançŸ©é˜µé¿å…ç›´æ¥è®¡ç®—ï¼Œå¦‚BFGSä½¿ç”¨ç§©2æ›´æ–°"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "L-BFGSï¼ˆæœ‰é™å†…å­˜BFGSï¼‰",
          "formulas": [
            {
              "text": "L-BFGSåªå­˜å‚¨æœ€è¿‘mæ¬¡è¿­ä»£çš„ä¿¡æ¯ï¼Œå†…å­˜éœ€æ±‚ä¸ºO(mn)è€ŒéO(nÂ²)ï¼š"
            },
            {
              "display": "H_k^{-1} = V_k^T H_{k-1}^{-1} V_k + \\rho_k s_k s_k^T"
            },
            {
              "text": "å…¶ä¸­ $s_k = w_k - w_{k-1}$ï¼Œ$y_k = \\nabla L(w_k) - \\nabla L(w_{k-1})$ï¼Œ$\\rho_k = 1/(y_k^T s_k)$"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "äºŒé˜¶ä¼˜åŒ–ç®—æ³•å®ç°",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport numpy as np\nfrom scipy.optimize import minimize\n\n# 1. ä½¿ç”¨scipyçš„L-BFGS-Bä¼˜åŒ–å™¨\nclass LBFGSOptimizer:\n    def __init__(self, model, criterion):\n        self.model = model\n        self.criterion = criterion\n        self.closure = None\n    \n    def closure_func(self, x):\n        \"\"\"L-BFGSéœ€è¦çš„é—­åŒ…å‡½æ•°\"\"\"\n        # æ¢å¤å‚æ•°\n        self._set_params(x)\n        \n        # è®¡ç®—æŸå¤±å’Œæ¢¯åº¦\n        if self.closure:\n            loss = self.closure()\n        else:\n            # é»˜è®¤å®ç°\n            loss = 0\n        \n        # è·å–æ¢¯åº¦\n        grad = self._get_grad()\n        \n        return loss, grad\n    \n    def _get_params(self):\n        \"\"\"è·å–æ‰€æœ‰å‚æ•°\"\"\"\n        return np.concatenate([p.data.cpu().numpy().flatten() for p in self.model.parameters()])\n    \n    def _set_params(self, x):\n        \"\"\"è®¾ç½®æ‰€æœ‰å‚æ•°\"\"\"\n        idx = 0\n        for p in self.model.parameters():\n            size = p.numel()\n            p.data = torch.from_numpy(x[idx:idx+size]).reshape(p.shape).float()\n            idx += size\n    \n    def _get_grad(self):\n        \"\"\"è·å–æ‰€æœ‰æ¢¯åº¦\"\"\"\n        return np.concatenate([p.grad.data.cpu().numpy().flatten() for p in self.model.parameters()])\n    \n    def step(self, closure):\n        \"\"\"æ‰§è¡Œä¸€æ­¥ä¼˜åŒ–\"\"\"\n        self.closure = closure\n        x0 = self._get_params()\n        \n        result = minimize(\n            self.closure_func,\n            x0,\n            method='L-BFGS-B',\n            jac=True,\n            options={'maxiter': 1}\n        )\n        \n        self._set_params(result.x)\n        return result.fun\n\n# 2. ç®€åŒ–çš„ç‰›é¡¿æ³•å®ç°ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰\ndef newton_method_2d(f, grad, hessian, x0, max_iter=10):\n    \"\"\"äºŒç»´ç‰›é¡¿æ³•ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰\"\"\"\n    x = x0.copy()\n    \n    for i in range(max_iter):\n        g = grad(x)\n        H = hessian(x)\n        \n        # è®¡ç®—Hessiançš„é€†\n        try:\n            H_inv = np.linalg.inv(H)\n            # æ›´æ–°å‚æ•°\n            x = x - H_inv @ g\n            print(f\"Iteration {i+1}: x = {x}, f(x) = {f(x):.4f}\")\n        except np.linalg.LinAlgError:\n            print(f\"HessiançŸ©é˜µä¸å¯é€†ï¼Œåœæ­¢è¿­ä»£\")\n            break\n    \n    return x\n\n# ç¤ºä¾‹ï¼šä¼˜åŒ–äºŒæ¬¡å‡½æ•° f(x) = x^2 + y^2\nf = lambda x: x[0]**2 + x[1]**2\ngrad = lambda x: np.array([2*x[0], 2*x[1]])\nhessian = lambda x: np.array([[2, 0], [0, 2]])\n\nx0 = np.array([3.0, 4.0])\nx_opt = newton_method_2d(f, grad, hessian, x0)\nprint(f\"\\næœ€ä¼˜è§£: {x_opt}\")\n\n# 3. ä½¿ç”¨PyTorchçš„L-BFGSä¼˜åŒ–å™¨\nmodel = nn.Sequential(\n    nn.Linear(10, 50),\n    nn.ReLU(),\n    nn.Linear(50, 1)\n)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.LBFGS(model.parameters(), lr=0.1, max_iter=20)\n\nx_train = torch.randn(32, 10)\ny_train = torch.randn(32, 1)\n\n# L-BFGSéœ€è¦é—­åŒ…å‡½æ•°\nfor epoch in range(10):\n    def closure():\n        optimizer.zero_grad()\n        output = model(x_train)\n        loss = criterion(output, y_train)\n        loss.backward()\n        return loss\n    \n    loss = optimizer.step(closure)\n    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n\n# 4. K-FACï¼ˆKronecker-Factored Approximate Curvatureï¼‰\n# K-FACæ˜¯ç”¨äºæ·±åº¦å­¦ä¹ çš„äºŒé˜¶ä¼˜åŒ–æ–¹æ³•\nclass KFACOptimizer:\n    \"\"\"K-FACä¼˜åŒ–å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰\"\"\"\n    def __init__(self, model, lr=0.001):\n        self.model = model\n        self.lr = lr\n        self.A = {}  # æ¿€æ´»åæ–¹å·®\n        self.G = {}  # æ¢¯åº¦åæ–¹å·®\n    \n    def update_covariances(self, activations, grads):\n        \"\"\"æ›´æ–°åæ–¹å·®çŸ©é˜µ\"\"\"\n        for name, (A, G) in zip(self.model.named_modules(), zip(activations, grads)):\n            if isinstance(A, torch.Tensor) and isinstance(G, torch.Tensor):\n                # æ›´æ–°Aå’ŒGï¼ˆç®€åŒ–å®ç°ï¼‰\n                if name not in self.A:\n                    self.A[name] = torch.eye(A.size(-1))\n                    self.G[name] = torch.eye(G.size(-1))\n                \n                # æŒ‡æ•°ç§»åŠ¨å¹³å‡æ›´æ–°\n                self.A[name] = 0.95 * self.A[name] + 0.05 * torch.mean(A @ A.T, dim=0)\n                self.G[name] = 0.95 * self.G[name] + 0.05 * torch.mean(G @ G.T, dim=0)\n    \n    def step(self, grads):\n        \"\"\"æ‰§è¡Œä¸€æ­¥æ›´æ–°\"\"\"\n        for (name, param), grad in zip(self.model.named_parameters(), grads):\n            if name in self.A and name in self.G:\n                # K-FACæ›´æ–°è§„åˆ™ï¼ˆç®€åŒ–ï¼‰\n                A_inv = torch.inverse(self.A[name] + 1e-8 * torch.eye(self.A[name].size(0)))\n                G_inv = torch.inverse(self.G[name] + 1e-8 * torch.eye(self.G[name].size(0)))\n                \n                # æ›´æ–°å‚æ•°\n                update = A_inv @ grad @ G_inv\n                param.data -= self.lr * update\n\nprint(\"\\n=== äºŒé˜¶ä¼˜åŒ–ç®—æ³•æ€»ç»“ ===\")\nprint(\"1. ç‰›é¡¿æ³•ï¼šæ”¶æ•›å¿«ä½†è®¡ç®—HessiançŸ©é˜µå¼€é”€å¤§\")\nprint(\"2. L-BFGSï¼šå†…å­˜é«˜æ•ˆçš„æ‹Ÿç‰›é¡¿æ³•ï¼Œé€‚åˆå°è§„æ¨¡æ¨¡å‹\")\nprint(\"3. K-FACï¼šä¸“é—¨ç”¨äºæ·±åº¦å­¦ä¹ çš„äºŒé˜¶æ–¹æ³•\")\nprint(\"4. é€‚ç”¨åœºæ™¯ï¼šå°è§„æ¨¡æ¨¡å‹ã€å‡¸ä¼˜åŒ–é—®é¢˜ã€éœ€è¦å¿«é€Ÿæ”¶æ•›\")\nprint(\"5. ä¸é€‚ç”¨ï¼šå¤§è§„æ¨¡æ¨¡å‹ï¼ˆå†…å­˜å’Œè®¡ç®—å¼€é”€è¿‡å¤§ï¼‰\")"
        }
      ]
    }
  ]
}
