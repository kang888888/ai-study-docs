{
  "title": "DPOï¼šæ— éœ€å¥–åŠ±æ¨¡å‹çš„ç›´æ¥åå¥½ä¼˜åŒ–",
  "subtitle": "é€šè¿‡è§£æåå¥½æ•°æ®çš„å¯¹æ•°ä¼¼ç„¶å·®ï¼Œç›´æ¥åœ¨ç­–ç•¥ç©ºé—´ä¸­é€¼è¿‘äººç±»åå¥½ï¼Œé¿å…è®­ç»ƒé¢å¤–å¥–åŠ±æ¨¡å‹å’Œ RL loopã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimizationï¼‰æ˜¯æ— éœ€å¥–åŠ±æ¨¡å‹çš„åå¥½ä¼˜åŒ–æ–¹æ³•ï¼Œç®€åŒ–RLHFæµç¨‹ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "æµç¨‹ç®€åŒ–ï¼šæ— éœ€å¥–åŠ±æ¨¡å‹",
            "è®­ç»ƒé«˜æ•ˆï¼šç›´æ¥ä¼˜åŒ–åå¥½",
            "æ•ˆæœä¼˜å¼‚ï¼šæ¥è¿‘RLHFæ•ˆæœ",
            "æ˜“äºå®ç°ï¼šç®—æ³•ç®€å•æ˜“å®ç°",
            "å¹¿æ³›åº”ç”¨ï¼šå¿«é€Ÿå‘å±•çš„æ–¹æ³•"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "ç›´æ¥åå¥½ä¼˜åŒ–ã€åå¥½æ•°æ®ã€æŸå¤±å‡½æ•°ã€æ— éœ€å¥–åŠ±æ¨¡å‹"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "åå¥½ä¼˜åŒ–ã€æ¨¡å‹å¯¹é½ã€ç®€åŒ–RLHFã€å¿«é€Ÿè®­ç»ƒ"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "è®­ç»ƒæµç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "è®­ç»ƒæµç¨‹"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æŸå¤±æ›²çº¿",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "æŸå¤±æ›²çº¿"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "ä¸ PPO å¯¹æ¯”",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "comparison",
                "title": "ä¸ PPO å¯¹æ¯”"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "åå¥½æŸå¤±",
          "formulas": [
            {
              "text": "DPO å°†åå¥½å»ºæ¨¡ä¸ºï¼š"
            },
            {
              "display": "\\mathcal{L}_{\\text{DPO}} = - \\log \\sigma\\Big( \\beta(\\log \\pi_\\theta(y^{+}|x) - \\log \\pi_\\theta(y^{-}|x)) - (\\log \\pi_{\\text{ref}}(y^{+}|x) - \\log \\pi_{\\text{ref}}(y^{-}|x)) \\Big)"
            },
            {
              "text": "å…¶ä¸­ $\\pi_{\\text{ref}}$ ä¸ºåŸºå‡†æ¨¡å‹ï¼Œ$\\beta$ ä¸ºæ¸©åº¦ç³»æ•°ã€‚",
              "inline": "\\pi_{\\text{ref}}"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "æ¢¯åº¦æ€§è´¨",
          "formulas": [
            {
              "text": "æ¢¯åº¦ä¸åå¥½å·®æˆæ­£æ¯”ï¼š"
            },
            {
              "display": "\\nabla_\\theta \\mathcal{L} \\propto (1 - \\sigma(\\cdot)) \\cdot \\nabla_\\theta \\big( \\log \\pi_\\theta(y^{+}|x) - \\log \\pi_\\theta(y^{-}|x) \\big)"
            },
            {
              "text": "è®­ç»ƒç¨³å®šä¸”å¯ç›´æ¥ä¸å¸¸è§„ä¼˜åŒ–å™¨ç»“åˆã€‚"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ TRL DPOTrainer",
          "language": "python",
          "code": "from trl import DPOTrainer, DPOConfig\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ndpo_config = DPOConfig(\n    model_name_or_path=\"meta-llama/Llama-2-7b-hf\",\n    ref_model_name_or_path=\"meta-llama/Llama-2-7b-hf\",\n    beta=0.1,\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=8,\n    learning_rate=5e-6\n)\n\ntokenizer = AutoTokenizer.from_pretrained(dpo_config.model_name_or_path)\nmodel = AutoModelForCausalLM.from_pretrained(dpo_config.model_name_or_path, load_in_8bit=True, device_map=\"auto\")\nref_model = AutoModelForCausalLM.from_pretrained(dpo_config.ref_model_name_or_path, load_in_8bit=True, device_map=\"auto\")\n\ndpo_trainer = DPOTrainer(\n    model,\n    ref_model,\n    tokenizer=tokenizer,\n    args=dpo_config,\n    beta=dpo_config.beta,\n    train_dataset=preference_dataset\n)\n\ndpo_trainer.train()"
        }
      ]
    }
  ]
}