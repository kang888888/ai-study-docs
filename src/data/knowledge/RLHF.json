{
  "title": "RLHFï¼šåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒ",
  "subtitle": "é€šè¿‡â€œåå¥½æ•°æ® â†’ å¥–åŠ±æ¨¡å‹ â†’ PPO å¾®è°ƒâ€ä¸‰é˜¶æ®µæµç¨‹ï¼Œè®©å¤§æ¨¡å‹åœ¨å®‰å…¨æ€§ã€æœ‰ç”¨æ€§å’Œç¤¼è²Œæ€§ä¸Šä¸äººç±»æœŸæœ›å¯¹é½ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "ä¸‰é˜¶æ®µæµç¨‹",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "ä¸‰é˜¶æ®µæµç¨‹",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "å¥–åŠ±æ¨¡å‹ç»“æ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "å¥–åŠ±æ¨¡å‹ç»“æ„",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "PPO è®­ç»ƒæ›²çº¿",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "PPO è®­ç»ƒæ›²çº¿",
                "data": null
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "å¥–åŠ±æ¨¡å‹",
          "formulas": [
            {
              "text": "ä½¿ç”¨ Bradley-Terry æŸå¤±ï¼š"
            },
            {
              "display": "\\mathcal{L}_{\\text{RM}} = -\\log \\sigma(r_\\phi(x, y^{+}) - r_\\phi(x, y^{-}))"
            },
            {
              "text": "é¼“åŠ±æ¨¡å‹ä¸ºæ›´ä¼˜å›ç­”ç»™å‡ºæ›´é«˜è¯„åˆ†ã€‚"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "PPO ç›®æ ‡",
          "formulas": [
            {
              "text": "ç­–ç•¥æ›´æ–°ç›®æ ‡ï¼š"
            },
            {
              "display": "\\max_\\theta \\mathbb{E}\\left[ \\min\\left( \\rho_t(\\theta) A_t, \\operatorname{clip}(\\rho_t(\\theta), 1-\\epsilon, 1+\\epsilon) A_t \\right) - \\beta \\cdot KL(\\pi_\\theta || \\pi_{\\text{SFT}}) \\right]"
            },
            {
              "text": "å…¶ä¸­ $A_t$ ç”±å¥–åŠ± - åŸºå‡†ç»„æˆï¼Œ$\\beta$ æ§åˆ¶ä¸ SFT æ¨¡å‹çš„åç¦»ç¨‹åº¦ã€‚",
              "inline": "A_t"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ TRL è¿›è¡Œ PPO å¾®è°ƒ",
          "language": "python",
          "code": "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\nfrom transformers import AutoTokenizer\n\nconfig = PPOConfig(\n    model_name=\"meta-llama/Llama-2-7b-hf\",\n    learning_rate=1e-5,\n    batch_size=64,\n    ppo_epochs=4,\n    kl_penalty=0.1\n)\n\ntokenizer = AutoTokenizer.from_pretrained(config.model_name)\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(\n    config.model_name,\n    load_in_4bit=True,\n    device_map=\"auto\"\n)\n\nppo_trainer = PPOTrainer(\n    config,\n    model,\n    tokenizer,\n    dataset=rlhf_dataset  # åŒ…å« prompt / chosen / rejected\n)\n\nfor batch in ppo_trainer.dataloader:\n    query_tensors = batch[\"input_ids\"]\n    response_tensors = ppo_trainer.generate(query_tensors)\n    rewards = reward_model(query_tensors, response_tensors)\n    ppo_trainer.step(query_tensors, response_tensors, rewards)"
        }
      ]
    }
  ]
}