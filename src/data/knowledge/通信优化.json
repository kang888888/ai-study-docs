{
  "title": "é€šä¿¡ä¼˜åŒ–",
  "subtitle": "é€šè¿‡æ¢¯åº¦å‹ç¼©ã€å¼‚æ­¥æ›´æ–°ã€é€šä¿¡ä¸è®¡ç®—é‡å ç­‰æŠ€æœ¯ä¼˜åŒ–åˆ†å¸ƒå¼è®­ç»ƒé€šä¿¡æ•ˆç‡ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "é€šä¿¡ä¼˜åŒ–ç­–ç•¥",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "comparison",
                "title": "é€šä¿¡ä¼˜åŒ–ç­–ç•¥",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "é€šä¿¡ä¸è®¡ç®—é‡å ",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "é€šä¿¡ä¸è®¡ç®—é‡å ",
                "data": null
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "æ¢¯åº¦å‹ç¼©",
          "language": "python",
          "code": "import torch\nimport torch.distributed as dist\n\ndef compress_gradient(grad, compression_ratio=0.1):\n    \"\"\"æ¢¯åº¦å‹ç¼©ï¼šåªä¼ è¾“é‡è¦çš„æ¢¯åº¦å€¼\"\"\"\n    # é€‰æ‹©top-kæ¢¯åº¦\n    k = int(grad.numel() * compression_ratio)\n    topk_values, topk_indices = torch.topk(grad.abs().flatten(), k)\n    \n    # åªä¼ è¾“ç´¢å¼•å’Œå€¼\n    compressed = {\n        'indices': topk_indices,\n        'values': grad.flatten()[topk_indices],\n        'shape': grad.shape\n    }\n    \n    return compressed\n\ndef decompress_gradient(compressed, device):\n    \"\"\"è§£å‹ç¼©æ¢¯åº¦\"\"\"\n    grad = torch.zeros(compressed['shape'], device=device)\n    grad.flatten()[compressed['indices']] = compressed['values']\n    return grad"
        },
        {
          "type": "code-box",
          "title": "é€šä¿¡ä¸è®¡ç®—é‡å ",
          "language": "python",
          "code": "import torch\nimport torch.distributed as dist\nfrom torch.cuda.stream import Stream\n\ndef overlapped_allreduce(model, optimizer, stream):\n    \"\"\"ä½¿ç”¨CUDAæµå®ç°é€šä¿¡ä¸è®¡ç®—é‡å \"\"\"\n    with torch.cuda.stream(stream):\n        # å¼‚æ­¥æ‰§è¡ŒAllReduce\n        for param in model.parameters():\n            if param.grad is not None:\n                dist.all_reduce(param.grad.data, op=dist.ReduceOp.SUM, async_op=True)\n    \n    # ä¸»æµç»§ç»­æ‰§è¡Œå…¶ä»–è®¡ç®—\n    # ...\n    \n    # ç­‰å¾…é€šä¿¡å®Œæˆ\n    stream.synchronize()\n    \n    # æ›´æ–°å‚æ•°\n    optimizer.step()"
        }
      ]
    }
  ]
}
