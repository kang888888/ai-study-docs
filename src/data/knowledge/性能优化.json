{
  "title": "æ€§èƒ½ä¼˜åŒ–",
  "subtitle": "Minimindé¡¹ç›®ä¸­çš„è®­ç»ƒåŠ é€Ÿã€å†…å­˜ä¼˜åŒ–ã€æ”¶æ•›ç­–ç•¥ç­‰æ€§èƒ½ä¼˜åŒ–æŠ€å·§ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æ€§èƒ½ä¼˜åŒ–ç­–ç•¥",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "comparison",
                "title": "æ€§èƒ½ä¼˜åŒ–ç­–ç•¥",
                "data": null
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "å†…å­˜ä¼˜åŒ–æ–¹æ³•",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "å†…å­˜ä¼˜åŒ–æ–¹æ³•",
                "data": null
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "æ··åˆç²¾åº¦è®­ç»ƒ",
          "language": "python",
          "code": "from torch.cuda.amp import autocast, GradScaler\n\ndef train_with_amp(model, dataloader, optimizer):\n    \"\"\"ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒåŠ é€Ÿ\"\"\"\n    scaler = GradScaler()\n    \n    for batch in dataloader:\n        optimizer.zero_grad()\n        \n        # å‰å‘ä¼ æ’­ä½¿ç”¨FP16\n        with autocast():\n            outputs = model(batch['input_ids'])\n            loss = compute_loss(outputs, batch['labels'])\n        \n        # åå‘ä¼ æ’­å’Œæ¢¯åº¦ç¼©æ”¾\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()"
        },
        {
          "type": "code-box",
          "title": "æ¢¯åº¦æ£€æŸ¥ç‚¹",
          "language": "python",
          "code": "from torch.utils.checkpoint import checkpoint\n\ndef apply_gradient_checkpointing(model):\n    \"\"\"åº”ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹èŠ‚çœå†…å­˜\"\"\"\n    def checkpoint_wrapper(module):\n        def forward(*args, **kwargs):\n            return checkpoint(module, *args, **kwargs)\n        return forward\n    \n    # å¯¹Transformerå—åº”ç”¨æ£€æŸ¥ç‚¹\n    for block in model.transformer.blocks:\n        block.forward = checkpoint_wrapper(block)\n    \n    return model\n\n# ä½¿ç”¨ç¤ºä¾‹\nmodel = GPT(config)\nmodel = apply_gradient_checkpointing(model)  # èŠ‚çœçº¦50%å†…å­˜"
        }
      ]
    }
  ]
}
