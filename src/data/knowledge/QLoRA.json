{
  "title": "QLoRAï¼š4bit é‡åŒ– + LoRA çš„åŒé‡æ•ˆç‡æ–¹æ¡ˆ",
  "subtitle": "é€šè¿‡ NF4 éå¯¹ç§°é‡åŒ–ä¿å­˜ä¸»æ¨¡å‹ï¼Œåœ¨é‡åŒ–æƒé‡ä¸Šæ’å…¥ LoRA é€‚é…å™¨ï¼Œå®ç°â€œä½æ˜¾å­˜ + é«˜æ€§èƒ½â€çš„å¾®è°ƒèŒƒå¼ã€‚",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“Š æµç¨‹å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "æ•°æ®åˆ°è®­ç»ƒé“¾è·¯",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "flow",
                "title": "æ•°æ®åˆ°è®­ç»ƒé“¾è·¯"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "NF4 é‡åŒ–ç¤ºæ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "NF4 é‡åŒ–ç¤ºæ„"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "LoRA é€‚é…å™¨åˆå¹¶",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "LoRA é€‚é…å™¨åˆå¹¶"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "NormalFloat4 é‡åŒ–",
          "formulas": [
            {
              "text": "QLoRA å¯¹æƒé‡ $w$ è¿›è¡Œæ­£æ€åˆ†å¸ƒæ„ŸçŸ¥é‡åŒ–ï¼š",
              "inline": "w"
            },
            {
              "display": "q = \\operatorname{clip}\\Bigg( \\Big\\lfloor \\frac{w - \\mu}{\\sigma} \\cdot \\alpha \\Big\\rceil, -8, 7 \\Bigg)"
            },
            {
              "text": "å…¶ä¸­ $\\mu, \\sigma$ æ¥è‡ªé«˜ç²¾åº¦ç»Ÿè®¡ï¼Œ$\\alpha$ ä¸ºç¼©æ”¾å› å­ï¼Œæœ€ç»ˆå­˜å‚¨ä¸º 4bitã€‚",
              "inline": "\\mu, \\sigma"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "LoRA æ³¨å…¥",
          "formulas": [
            {
              "text": "é‡åŒ–åä»å¯æ’å…¥ LoRAï¼š"
            },
            {
              "display": "y = (\\operatorname{Dequant}(q) + \\frac{\\alpha}{r} BA ) x"
            },
            {
              "text": "å…¶ä¸­ $\\operatorname{Dequant}(q)$ ä¸ºè§£é‡åŒ–æƒé‡ï¼Œ$BA$ ä»åœ¨ FP16/32 ç©ºé—´è®­ç»ƒã€‚",
              "inline": "\\operatorname{Dequant}(q)"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ bitsandbytes + PEFT è¿›è¡Œ QLoRA",
          "language": "python",
          "code": "import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"meta-llama/Llama-3-8b\",\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3-8b\", use_fast=False)\n\nlora_config = LoraConfig(\n    r=64,\n    lora_alpha=64,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_dropout=0.05,\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)\n# åç»­å¯ä½¿ç”¨ TRL/Accelerate è¿›è¡Œ SFT æˆ–åå¥½è®­ç»ƒ"
        }
      ]
    }
  ]
}