{
  "title": "RNN (Recurrent Neural Network) å¾ªç¯ç¥ç»ç½‘ç»œ",
  "subtitle": "ä¸“é—¨å¤„ç†åºåˆ—æ•°æ®çš„ç¥ç»ç½‘ç»œ",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "ä¸“é—¨å¤„ç†åºåˆ—æ•°æ®çš„ç¥ç»ç½‘ç»œï¼Œå…·æœ‰è®°å¿†èƒ½åŠ›ã€‚é€šè¿‡éšè—çŠ¶æ€ï¼ˆHidden Stateï¼‰åœ¨æ—¶é—´æ­¥ä¹‹é—´ä¼ é€’ä¿¡æ¯ï¼Œæ•æ‰åºåˆ—ä¸­çš„æ—¶åºä¾èµ–ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "æ—¶åºå»ºæ¨¡ï¼šèƒ½å¤Ÿå¤„ç†å˜é•¿åºåˆ—æ•°æ®",
            "å‚æ•°å…±äº«ï¼šæ‰€æœ‰æ—¶é—´æ­¥å…±äº«åŒä¸€ç»„å‚æ•°",
            "è®°å¿†æœºåˆ¶ï¼šéšè—çŠ¶æ€ h_t åŒ…å«å†å²ä¿¡æ¯",
            "æ¢¯åº¦æ¶ˆå¤±ï¼šé•¿åºåˆ—è®­ç»ƒæ—¶å®¹æ˜“å‡ºç°æ¢¯åº¦æ¶ˆå¤±é—®é¢˜",
            "æ— æ³•å¹¶è¡Œï¼šè®­ç»ƒæ—¶å¿…é¡»æŒ‰æ—¶é—´æ­¥é¡ºåºè®¡ç®—"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "BPTTï¼ˆåå‘ä¼ æ’­ç©¿è¶Šæ—¶é—´ï¼‰ã€æ¢¯åº¦è£å‰ªã€éšè—çŠ¶æ€ä¼ é€’"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "æ—¶é—´åºåˆ—é¢„æµ‹ã€è¯­éŸ³è¯†åˆ«ã€æ–‡æœ¬ç”Ÿæˆã€æœºå™¨ç¿»è¯‘ï¼ˆæ—©æœŸï¼‰"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "RNNDiagram",
              "caption": "RNNæ¶æ„å›¾ï¼ˆå¾ªç¯å½¢å¼ï¼‰",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "RNNæ¶æ„å›¾ï¼ˆå¾ªç¯å½¢å¼ï¼‰"
              }
            },
            {
              "type": "svg-d3",
              "component": "RNNDiagram",
              "caption": "RNNå±•å¼€å½¢å¼",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "unfolded",
                "title": "RNNå±•å¼€å½¢å¼"
              }
            },
            {
              "type": "svg-d3",
              "component": "RNNDiagram",
              "caption": "RNNå•å…ƒå†…éƒ¨ç»“æ„",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "cell",
                "title": "RNNå•å…ƒå†…éƒ¨ç»“æ„"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "RNN å‰å‘ä¼ æ’­",
          "formulas": [
            {
              "text": "åœ¨æ—¶é—´æ­¥ $t$ï¼ŒRNN çš„è®¡ç®—å…¬å¼ï¼š",
              "inline": "t"
            },
            {
              "display": "h_t = \\tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h)"
            },
            {
              "display": "y_t = W_{hy} h_t + b_y"
            },
            {
              "text": "å…¶ä¸­ï¼š"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "BPTTï¼ˆåå‘ä¼ æ’­ç©¿è¶Šæ—¶é—´ï¼‰",
          "formulas": [
            {
              "text": "æ¢¯åº¦é€šè¿‡æ—¶é—´åå‘ä¼ æ’­ï¼š"
            },
            {
              "display": "\\frac{\\partial L}{\\partial W} = \\sum_{t=1}^{T} \\frac{\\partial L_t}{\\partial W}"
            },
            {
              "display": "\\frac{\\partial h_t}{\\partial h_{t-1}} = W_{hh}^T \\cdot \\text{diag}(1 - h_t^2)"
            },
            {
              "text": "é•¿åºåˆ—ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸é—®é¢˜"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ PyTorch å®ç° RNN",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\n\nclass SimpleRNN(nn.Module):\n    \"\"\"ç®€å•çš„ RNN å®ç°\"\"\"\n    def __init__(self, input_size, hidden_size, output_size):\n        super(SimpleRNN, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_len, input_size)\n        out, h_n = self.rnn(x)\n        # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º\n        out = self.fc(out[:, -1, :])\n        return out\n\n# ä½¿ç”¨ç¤ºä¾‹\nif __name__ == \"__main__\":\n    model = SimpleRNN(input_size=10, hidden_size=64, output_size=2)\n    x = torch.randn(32, 50, 10)  # (batch, seq_len, input_size)\n    output = model(x)\n    print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")  # [32, 2]"
        },
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ NumPy æ‰‹åŠ¨å®ç° RNN",
          "language": "python",
          "code": "import numpy as np\n\nclass RNN_Numpy:\n    \"\"\"ä½¿ç”¨ NumPy æ‰‹åŠ¨å®ç° RNN\"\"\"\n    def __init__(self, input_size, hidden_size, output_size):\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        \n        # åˆå§‹åŒ–æƒé‡\n        scale = 0.01\n        self.W_xh = np.random.randn(input_size, hidden_size) * scale\n        self.W_hh = np.random.randn(hidden_size, hidden_size) * scale\n        self.W_hy = np.random.randn(hidden_size, output_size) * scale\n        \n        self.b_h = np.zeros((1, hidden_size))\n        self.b_y = np.zeros((1, output_size))\n    \n    def tanh(self, x):\n        return np.tanh(x)\n    \n    def forward(self, X):\n        \"\"\"å‰å‘ä¼ æ’­\"\"\"\n        batch_size, seq_len, _ = X.shape\n        h = np.zeros((batch_size, self.hidden_size))\n        \n        outputs = []\n        hidden_states = [h]\n        \n        for t in range(seq_len):\n            x_t = X[:, t, :]\n            h = self.tanh(np.dot(x_t, self.W_xh) + np.dot(h, self.W_hh) + self.b_h)\n            y_t = np.dot(h, self.W_hy) + self.b_y\n            \n            hidden_states.append(h)\n            outputs.append(y_t)\n        \n        return np.array(outputs), hidden_states\n\n# ä½¿ç”¨ç¤ºä¾‹\nif __name__ == \"__main__\":\n    rnn = RNN_Numpy(input_size=10, hidden_size=64, output_size=2)\n    X = np.random.randn(5, 20, 10)  # (batch, seq_len, input_size)\n    outputs, hidden_states = rnn.forward(X)\n    print(f\"è¾“å‡ºå½¢çŠ¶: {outputs.shape}\")  # (20, 5, 2)"
        }
      ]
    }
  ]
}