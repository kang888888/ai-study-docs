{
  "title": "MoE (Mixture of Experts) æ··åˆä¸“å®¶æ¨¡å‹",
  "subtitle": "ç¨€ç–æ¿€æ´»çš„è¶…å¤§è§„æ¨¡æ¨¡å‹æ¶æ„",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "å°†å¤§æ¨¡å‹æ‹†åˆ†ä¸ºå¤šä¸ª'ä¸“å®¶'å­ç½‘ç»œï¼ˆé€šå¸¸æ˜¯FFNå±‚ï¼‰ï¼Œé€šè¿‡é—¨æ§ç½‘ç»œï¼ˆRouter/Gating Networkï¼‰åŠ¨æ€é€‰æ‹©æ¿€æ´»å“ªäº›ä¸“å®¶ã€‚å®ç°äº†å‚æ•°æ€»é‡å¤§ä½†è®¡ç®—é‡å°çš„ç¨€ç–æ¿€æ´»ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "ç¨€ç–æ¿€æ´»ï¼šæ¯æ¬¡æ¨ç†åªæ¿€æ´»éƒ¨åˆ†ä¸“å®¶ï¼ˆå¦‚Top-2ï¼‰ï¼Œè®¡ç®—é‡å¤§å¹…é™ä½",
            "å‚æ•°æ•ˆç‡ï¼šæ€»å‚æ•°é‡å¯è¾¾æ•°åƒäº¿ï¼Œä½†æ¿€æ´»å‚æ•°ä»…æ•°åäº¿",
            "é—¨æ§è·¯ç”±ï¼šå¯å­¦ä¹ çš„Routerå†³å®šè¾“å…¥åº”è¯¥äº¤ç»™å“ªäº›ä¸“å®¶å¤„ç†",
            "è´Ÿè½½å‡è¡¡ï¼šé€šè¿‡è¾…åŠ©æŸå¤±å‡½æ•°ç¡®ä¿ä¸“å®¶è´Ÿè½½å‡è¡¡",
            "æè‡´æ€§ä»·æ¯”ï¼šMixtral 8x7Bæ€§èƒ½åª²ç¾LLaMA-70Bï¼Œä½†æ¨ç†æˆæœ¬ä»…ä¸º13B"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "é—¨æ§ç½‘ç»œï¼ˆGating Networkï¼‰ã€Top-Kè·¯ç”±ã€è´Ÿè½½å‡è¡¡æŸå¤±ï¼ˆAuxiliary Lossï¼‰ã€ä¸“å®¶å¹¶è¡Œ"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆDeepSeek-V2/V3ã€Mixtralã€GPT-4æ¨æµ‹ï¼‰ã€å¤šä»»åŠ¡å­¦ä¹ "
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "MoEDiagram",
              "caption": "MoEè·¯ç”±å¯è§†åŒ–",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "MoEè·¯ç”±å¯è§†åŒ–"
              }
            },
            {
              "type": "svg-d3",
              "component": "MoEDiagram",
              "caption": "MoEç»„ä»¶è¯¦è§£",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "MoEç»„ä»¶è¯¦è§£"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "é—¨æ§ç½‘ç»œï¼ˆGating Networkï¼‰",
          "formulas": [
            {
              "text": "é—¨æ§ç½‘ç»œè®¡ç®—æ¯ä¸ªä¸“å®¶çš„æƒé‡ï¼š"
            },
            {
              "display": "G(x) = \\text{softmax}(W_g x + b_g)"
            },
            {
              "text": "å…¶ä¸­ $G(x) \\in \\mathbb{R}^E$ï¼Œ$E$ æ˜¯ä¸“å®¶æ•°é‡",
              "inline": "G(x) \\in \\mathbb{R}^E"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "Top-K è·¯ç”±",
          "formulas": [
            {
              "text": "é€‰æ‹©Top-Kä¸ªä¸“å®¶ï¼š"
            },
            {
              "display": "\\text{TopK}(G(x), k) = \\{i_1, i_2, ..., i_k\\}"
            },
            {
              "text": "è¾“å‡ºä¸ºé€‰ä¸­ä¸“å®¶çš„åŠ æƒå’Œï¼š"
            },
            {
              "display": "y = \\sum_{i \\in \\text{TopK}} G_i(x) \\cdot E_i(x)"
            },
            {
              "text": "å…¶ä¸­ $E_i(x)$ æ˜¯ç¬¬ $i$ ä¸ªä¸“å®¶çš„è¾“å‡º",
              "inline": "E_i(x)"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "è´Ÿè½½å‡è¡¡æŸå¤±",
          "formulas": [
            {
              "text": "ç¡®ä¿ä¸“å®¶è´Ÿè½½å‡è¡¡ï¼š"
            },
            {
              "display": "L_{aux} = \\alpha \\cdot \\sum_{i=1}^{E} f_i \\cdot P_i"
            },
            {
              "text": "å…¶ä¸­ $f_i$ æ˜¯ä¸“å®¶ $i$ è¢«é€‰ä¸­çš„é¢‘ç‡ï¼Œ$P_i$ æ˜¯å¹³å‡è·¯ç”±æ¦‚ç‡",
              "inline": "f_i"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ PyTorch å®ç° MoE å±‚",
          "language": "python",
          "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MoELayer(nn.Module):\n    \"\"\"æ··åˆä¸“å®¶å±‚\"\"\"\n    def __init__(self, d_model, num_experts=8, top_k=2):\n        super(MoELayer, self).__init__()\n        self.num_experts = num_experts\n        self.top_k = top_k\n        \n        # é—¨æ§ç½‘ç»œ\n        self.gate = nn.Linear(d_model, num_experts)\n        \n        # å¤šä¸ªä¸“å®¶ï¼ˆFFNï¼‰\n        self.experts = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(d_model, d_model * 4),\n                nn.ReLU(),\n                nn.Linear(d_model * 4, d_model)\n            ) for _ in range(num_experts)\n        ])\n    \n    def forward(self, x):\n        \"\"\"\n        å‚æ•°:\n            x: [batch_size, seq_length, d_model]\n        è¿”å›:\n            output: [batch_size, seq_length, d_model]\n        \"\"\"\n        batch_size, seq_length, d_model = x.shape\n        \n        # è®¡ç®—é—¨æ§æƒé‡\n        gate_logits = self.gate(x)  # [batch_size, seq_length, num_experts]\n        gate_probs = F.softmax(gate_logits, dim=-1)\n        \n        # Top-K é€‰æ‹©\n        top_k_probs, top_k_indices = torch.topk(gate_probs, self.top_k, dim=-1)\n        top_k_probs = top_k_probs / top_k_probs.sum(dim=-1, keepdim=True)\n        \n        # åˆå§‹åŒ–è¾“å‡º\n        output = torch.zeros_like(x)\n        \n        # å¯¹æ¯ä¸ªä¸“å®¶è®¡ç®—è¾“å‡º\n        for i in range(self.num_experts):\n            # æ‰¾åˆ°ä½¿ç”¨å½“å‰ä¸“å®¶çš„ä½ç½®\n            expert_mask = (top_k_indices == i)\n            \n            if expert_mask.any():\n                # è®¡ç®—ä¸“å®¶è¾“å‡º\n                expert_output = self.experts[i](x)\n                \n                # åŠ æƒç´¯åŠ \n                weights = top_k_probs * expert_mask.float()\n                output += weights.unsqueeze(-1) * expert_output\n        \n        return output\n\n# ä½¿ç”¨ç¤ºä¾‹\nif __name__ == \"__main__\":\n    moe = MoELayer(d_model=512, num_experts=8, top_k=2)\n    x = torch.randn(2, 100, 512)\n    output = moe(x)\n    print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")  # [2, 100, 512]"
        }
      ]
    }
  ]
}