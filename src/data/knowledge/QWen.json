{
  "title": "QWen (é€šä¹‰åƒé—®) é˜¿é‡Œäº‘å¤§æ¨¡å‹",
  "subtitle": "é˜¿é‡Œäº‘å¼€æºçš„å¤§è¯­è¨€æ¨¡å‹ç³»åˆ—",
  "content": [
    {
      "type": "section",
      "title": "ğŸ“– æ ¸å¿ƒæ¦‚å¿µ",
      "content": [
        {
          "type": "desc-box",
          "content": [
            "é˜¿é‡Œäº‘å¼€æºçš„å¤§è¯­è¨€æ¨¡å‹ç³»åˆ—ï¼Œä»0.5Båˆ°72Bå¤šä¸ªè§„æ¨¡ã€‚åœ¨ä¸­æ–‡ã€ä»£ç ã€æ•°å­¦ç­‰ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ”¯æŒ32Ké•¿ä¸Šä¸‹æ–‡ï¼Œå¹¶æä¾›å¤šæ¨¡æ€ç‰ˆæœ¬ã€‚"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸŒŸ æ ¸å¿ƒç‰¹ç‚¹",
      "content": [
        {
          "type": "features",
          "items": [
            "å¤šè§„æ¨¡ï¼šä»0.5Båˆ°72Bï¼Œè¦†ç›–ä¸åŒåœºæ™¯éœ€æ±‚",
            "é•¿ä¸Šä¸‹æ–‡ï¼šæ”¯æŒ32K tokensï¼Œé€‚åˆé•¿æ–‡æ¡£ç†è§£",
            "GQAä¼˜åŒ–ï¼šä½¿ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼Œæå‡æ¨ç†æ•ˆç‡",
            "å¤šæ¨¡æ€ï¼šQWen-VLæ”¯æŒå›¾åƒï¼ŒQWen-Audioæ”¯æŒéŸ³é¢‘",
            "ä»£ç èƒ½åŠ›å¼ºï¼šåœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°çªå‡º"
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "âš™ï¸ å…³é”®æŠ€æœ¯",
      "content": [
        {
          "type": "tech-box",
          "content": "Grouped-Query Attentionã€RoPEã€SwiGLUã€Flash Attention"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸš€ åº”ç”¨åœºæ™¯",
      "content": [
        {
          "type": "app-box",
          "content": "ä¸­æ–‡å¯¹è¯ã€ä»£ç ç”Ÿæˆã€é•¿æ–‡æ¡£ç†è§£ã€å¤šæ¨¡æ€ç†è§£ã€æ•°å­¦æ¨ç†"
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“Š æ¶æ„å›¾è§£",
      "content": [
        {
          "type": "diagram-gallery",
          "images": [
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "QWenæ¶æ„å›¾",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "QWenæ¶æ„å›¾"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "QWenç»„ä»¶è¯¦è§£",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "QWenç»„ä»¶è¯¦è§£"
              }
            },
            {
              "type": "svg-d3",
              "component": "GenericDiagram",
              "caption": "QWenå¯¹æ¯”å›¾",
              "width": 1000,
              "height": 800,
              "interactive": true,
              "props": {
                "type": "architecture",
                "title": "QWenå¯¹æ¯”å›¾"
              }
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ“ æ•°å­¦åŸç†",
      "content": [
        {
          "type": "math-box",
          "title": "Grouped-Query Attention (GQA)",
          "formulas": [
            {
              "text": "GQA å°†å¤šä¸ªæŸ¥è¯¢å¤´åˆ†ç»„å…±äº«é”®å€¼ï¼š"
            },
            {
              "display": "\\text{GQA}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O"
            },
            {
              "display": "\\text{head}_i = \\text{Attention}(Q_i, K_{group}, V_{group})"
            },
            {
              "text": "ç›¸æ¯”MHAï¼ŒGQAå‡å°‘äº†KV Cacheï¼Œæå‡æ¨ç†æ•ˆç‡"
            }
          ]
        },
        {
          "type": "math-box",
          "title": "RoPE ä½ç½®ç¼–ç ",
          "formulas": [
            {
              "text": "QWenä½¿ç”¨æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰ï¼Œä¸LLaMAç›¸åŒï¼š"
            },
            {
              "display": "R_{\\Theta, m}^d = \\text{Rotary}(m, \\theta)"
            },
            {
              "text": "æ”¯æŒé•¿ä¸Šä¸‹æ–‡æ‰©å±•ï¼Œå¯ä»¥å¤„ç†32K tokens"
            }
          ]
        }
      ]
    },
    {
      "type": "section",
      "title": "ğŸ’» Python ä»£ç ç¤ºä¾‹",
      "content": [
        {
          "type": "code-box",
          "title": "ä½¿ç”¨ Transformers åº“åŠ è½½ QWen",
          "language": "python",
          "code": "from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\n# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨\nmodel_path = \"Qwen/Qwen-7B-Chat\"\ntokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    trust_remote_code=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\n# å¯¹è¯\nmessages = [\n    {\"role\": \"user\", \"content\": \"ä½ å¥½\"}\n]\ntext = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\ninputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\nwith torch.no_grad():\n    outputs = model.generate(**inputs, max_new_tokens=100)\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(response)"
        }
      ]
    }
  ]
}