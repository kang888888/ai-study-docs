// 节点详细描述
export const categoryDescriptions = {
  'AI大模型学习': '覆盖从基础理论、数据工程到训练推理、应用开发、安全运营、算力底座的完整学习体系。',
  'AI基础理论': '夯实神经网络与深度学习原理，为后续大模型技术打下基础。',
  '经典架构': 'MLP、CNN、ResNet、YOLO、RNN 等经典网络结构。',
  'LLM核心架构': 'Transformer、LSTM/GRU、BERT、MoE、Mamba、RWKV、ViT、CLIP 等支撑 LLM 的关键架构。',
  '生成式架构': 'Diffusion、VAE、GAN、U-Net、GNN、DQN、DBN 等高级/生成式结构。',
  '大模型实例': 'LLaMA、ChatGLM、Qwen 等具体大模型实例。',
  'MLP': '多层感知机，基础前馈神经网络结构。',
  'CNN': '卷积神经网络，擅长处理图像与空间特征。',
  'ResNet': '残差网络，通过残差连接解决深层退化问题。',
  'YOLO': '单阶段目标检测网络，实现实时检测。',
  'RNN': '循环神经网络，处理序列数据的基础结构。',
  'Transformer': '自注意力架构，LLM 核心基础。',
  'LSTM': '长短期记忆网络，缓解长序列梯度消失。',
  'GRU': '门控循环单元，LSTM 的轻量变体。',
  'BERT': '双向 Transformer 编码器，预训练基础。',
  'MoE': '专家混合模型，通过稀疏路由提升容量。',
  'Mamba': '线性时序模块，兼具效率与长依赖建模。',
  'Miras': '通用架构设计框架，基于关联记忆与注意力偏差。',
  'Titans': '仿生记忆架构，融合短期/长期记忆，突破200万Token上下文。',
  'RWKV': 'RNN-Transformer 混合架构，兼顾并行与长序列。',
  'ViT': '视觉 Transformer，处理图像补丁序列。',
  'CLIP': '图文对齐模型，联合嵌入空间。',
  'Diffusion': '扩散模型，逐步去噪生成图像。',
  'VAE': '变分自编码器，概率生成模型。',
  'GAN': '生成对抗网络，生成逼真样本。',
  'U-Net': '编码器-解码器结构，常用于分割与生成。',
  'GNN': '图神经网络，处理图结构数据。',
  'DQN': '深度 Q 网络，强化学习中的价值网络。',
  'DBN': '深度置信网络，由多层 RBM 组成。',
  'LLaMA': 'Meta 开源大模型系列。',
  'ChatGLM': '清华智谱中文对话大模型。',
  'QWen': '阿里通义千问系列大模型。',
  'Moneta': '基于Miras框架的高效关联记忆架构，快速检索和更新。',
  'Yaad': '基于Miras框架的优化注意力偏差模型，精确检索。',
  'Memora': '基于Miras框架的长期记忆管理模型，长序列建模。',
  '数据工程': '数据采集、清洗、增强、质量评估与管理，是大模型效果的关键前置。',
  '大模型核心技术': '微调、量化、训练、推理与强化学习等核心算法与工程实现。',
  '高级技术': '模型融合、MoE、提示工程、流式生成等进阶主题，延展大模型能力边界。',
  '高级技术': '进阶能力汇总，串联 MoE、模型融合、提示工程等主题。',
  '应用开发与框架': 'RAG、Agent、向量数据库、HuggingFace 工具链，支撑业务落地。',
  '评估与安全': '覆盖模型评测、红队、提示注入、防御策略，确保可靠性。',
  '部署与运维': 'LLMOps、性能分析、版本与监控体系，保障上线与稳定运维。',
  'AI基础设施': '算力、编译器、国产化适配与性能基准，构建底层硬件与系统能力。',
  '神经网络架构': '交互式图谱梳理 CNN、LSTM、Transformer 等主流架构及演化。',
  '数据工程': '数据收集、处理、增强与质量评估的可视化知识图谱。',
  '数据收集': '公开数据、抓取、人工标注与合成数据策略。',
  '数据清洗': '去重、过滤、标准化与数据验证流程。',
  '格式转换': 'JSONL/Parquet/ShareGPT 等格式互转与模板化处理。',
  '数据增强': '回译、同义替换、模板填充、排序等增强技巧。',
  '质量评估': '准确性、相关性、多样性与一致性度量。',
  '数据管理': '版本化、元数据、权限与生命周期管理。',
  '数据处理': '数据清洗、格式转换、增强等流水线能力。',
  '质量保证': '数据质量评估、资产管理与可追溯治理。',
  '模型微调': 'LoRA、QLoRA、DPO/ORPO、SFT 等微调技术的关系网络。',
  'SFT': '监督微调流程、常见数据形式与实现要点。',
  'RLHF': '人类反馈强化学习流程，奖励模型与策略优化。',
  'LoRA': '低秩适配微调，冻结主干仅训练插入层。',
  'QLoRA': '4bit 量化与低秩适配结合，节省显存。',
  'DPO': '直接偏好优化，无需奖励模型的对齐方案。',
  'ORPO': 'Odds Ratio 偏好优化，重建对数似然与偏好约束。',
  'Axolotl': '多模态/多框架适配的微调工具链。',
  'Unsloth': '专注高效/轻量微调的优化框架。',
  'PEFT': '参数高效微调家族，包含 LoRA、Prefix 等方法。',
  '模型量化': 'GPTQ、AWQ、GGUF、INT4/INT8 等量化方案及部署路线。',
  '量化基础': 'PTQ/QAT、位宽选择、误差度量与常见工具链。',
  'GPTQ': '梯度/Hessian 感知的后训练 4bit 权重量化方法。',
  'AWQ': 'Activation-aware 方案，重权重重要性与激活裁剪。',
  'SmoothQuant': '缩放激活/权重，便于在 TensorRT-LLM 中部署 INT8/INT4。',
  'PTQ': '不重新训练的离线量化流程，专注校准与 scale 选择。',
  'GGUF': 'llama.cpp 使用的统一二进制格式，兼容多种量化位宽。',
  'HQQ': '半二次优化驱动的极速零数据量化。',
  'ExLlamaV2': '针对 INT4/NF4 优化的高吞吐推理引擎。',
  '模型训练': '分布式并行、ZeRO、混合精度、梯度检查点等训练技巧。',
  '分布式训练': '数据/模型/管道并行的基本概念与通信模式。',
  '数据并行': 'AllReduce、梯度同步、Gradient Sharding 等实践。',
  '模型并行': '张量并行、专家并行、序列并行等拆分方式。',
  'Pipeline并行': '流水线分段、调度、气泡抑制与 GPipe/DeepSpeed。',
  'ZeRO优化器': 'ZeRO-1/2/3 分阶段状态分片，显存优化。',
  '梯度累积': '小显存场景下的累积策略与 recompute。',
  '混合精度': 'FP16/BF16、Grad Scaling、Master Weights。',
  'Minimind实践': '从零复现 GPT 训练项目的工程经验。',
  '模型推理': 'KV Cache、FlashAttention、Speculative Decoding、批处理策略。',
  '推理': '推理流程、吞吐/时延指标与部署要点。',
  '推理优化': '算子/图优化、量化、剪枝、内存管理。',
  'TensorRT-LLM': 'NVIDIA TensorRT-LLM 引擎、插件与优化案例。',
  'vLLM': '高吞吐推理框架，PagedAttention + Continuous Batching。',
  'KV Cache': '键值缓存结构、共享策略与显存回收。',
  'PagedAttention': '分页注意力，解决长序列 KV 管理。',
  'Speculative Decoding': '草稿模型 + 验证模型的加速推理。',
  'FlashAttention': 'IO 感知注意力算子，降低显存带宽压力。',
  '强化学习与对齐': 'RLHF、DPO、RLAIF、PPO/TRPO 等强化学习与对齐技术。',
  '强化学习': 'MDP、策略、价值函数与 Bellman 方程等基础概念。',
  'PPO': 'Clip-Objective 的策略梯度，兼顾稳定性与样本效率。',
  'TRPO': '通过约束 KL 距离实现的信赖域策略优化。',
  'RLHF': '人类偏好反馈 + PPO 的对齐流程。',
  'DPO': '直接最小化偏好对数比，无需奖励模型。',
  'ORPO': 'Odds Ratio 约束，统一最大似然与偏好优化。',
  'RLAIF': '使用 AI 反馈替代人工标注的对齐方法。',
  'CoT': '组合思维链与搜索/价值函数的推理优化。',
  '逻辑推理': '结构化推理、PRM、Self-Play 等推理强化策略。',
  '文本生成': '解码策略、提示工程、流式生成等专门知识图谱。',
  '提示工程': '提示设计框架、指令模板、思维链等策略。',
  '流式生成': '逐 token 输出、推流架构与体验优化。',
  '解码策略': 'Greedy、Beam、Sampling、Top-k/p、温度等策略比较。',
  '知识增强': 'RAG、知识注入、检索增强等知识增强技术。',
  '向量库': 'Milvus、Pinecone、Weaviate、Qdrant 等向量检索与优化。',
  'LangChain': '模型、Prompt、Chain、Agent、Callback 等组件详解。',
  '智能体': 'ReAct、工具调用、LangGraph、smolagents、CrewAI 等框架。',
  'RAG': '检索、索引、重排、DSPy 等 RAG 优化链路。',
  'Transformers': 'Pipeline、模型加载、Encoder-Decoder 架构与推理示例。',
  'Datasets': '数据加载、处理、创建与切分。',
  'Tokenizers': '分词器训练、编码/解码、批处理与优化。',
  'Accelerate': '分布式训练、混合精度、设备管理。',
  'HuggingFace Hub': '模型/数据集管理与 Spaces 部署。',
  '应用开发与框架': '向量数据库、LangChain、Agent、RAG 的可视化导航。',
  '评估': '指标体系、评估方法、基准测试与工具链。',
  '安全': '提示注入、防御策略、监控与红队实践。',
  '评估与安全': '模型评测与安全防御体系的交互式图谱。',
  'LLMOps': '部署策略、K8s、版本治理、监控与实践案例。',
  '性能分析': 'PyTorch Profiler、Nsight、优化路线与案例。',
  '部署与运维': 'LLMOps、LLM性能分析、知识图谱总览。',
  '硬件集群': '加速卡、集群拓扑、网络通信与算力规划。',
  '编译器': '编译原理、前后端技术、主流框架与案例。',
  '国产化': '昇腾、飞桨及其他国产芯片的迁移方案与性能基准。',
  'AI基础设施': '硬件集群、AI编译器、国产化适配的整合视图。'
};
